{
  "1": {
    "title": "Integrale in Anwendungen",
    "page": 1,
    "sections": {
      "1.1": {
        "title": "Einfache Berechnung von Integralen",
        "page": 1,
        "subsections": {
          "1.1.1": {
            "title": "Lineare Modifikation",
            "page": 1,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 1.1",
                "details": "Integration durch lineare Modifikation Seien f : R →R eine integrierbare Funktion mit Stammfunktion F : R →R und m, q, x0, xE ∈R mit m ̸= 0 und x0 < xE, dann gilt folgendes. (a) Z f(m · x + q) dx = 1 m · F(m · x + q) + c (b) Z xE x0 f(m · x + q) dx = 1 m · \u0010 F(m · xE + q) −F(m · x0 + q) \u0011",
                "page": 1
              },
              {
                "type": "Beweis",
                "text": "Beweis: Übung.",
                "details": "",
                "page": 1
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten ein unbestimmtes Elementarintegral und eine lineare Modifikation. elementar: F(x) = Z cos(x) dx = sin(x) + c linear modifiziert: F(x) = Z cos(2x + 3) dx = 1 2 · sin(2x + 3) + c (1.1) • Wir betrachten das unbestimmte Integral F(x) = Z (7x −2)3 dx = 1 7 · 1 4 · (7x −2)4 + c = 1 28 · (7x −2)4 + c. (1.2) • Wir betrachten das unbestimmte Integral F(x) = Z 32x+9 dx = 1 2 · 1 ln(3) · 32x+9 + c = 1 2 ln(3) · 32x+9 + c. (1.3) I-3",
                "page": 1
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Linear modifizierte Elementar-Integrale machen ca. 90% aller Integrale in Alltag, Natur- wissenschaft, Technik und Wirtschaft aus. ii) Die Methode der linearen Modifikation ist ein einfacher Spezialfall der allgemeineren Me- thode der Substitution. Liste mit den wichtigsten linear modifizierten Standard-Integralen: • Z (m · x + q)p dx = 1 m · (p + 1) · (m · x + q)p+1 + c • Z am·x+q dx = 1 m · ln(a) · am·x+q + c • Z y0 · a x−x0 Σ dx = Σ ln(a) · y0 · a x−x0 Σ + c • Z A · sin(ω · t + φ) dt = −A ω · cos(ω · t + φ) + c",
                "page": 2
              }
            ]
          },
          "1.1.2": {
            "title": "Integration mit Software",
            "page": 2,
            "content": []
          }
        }
      },
      "1.2": {
        "title": "Archimedes-Cauchy-Riemann-Approximationsprozess",
        "page": 3,
        "subsections": {
          "1.2.1": {
            "title": "Einleitung",
            "page": 3,
            "content": []
          },
          "1.2.2": {
            "title": "Historische Methode zur Berechnung von Integralen",
            "page": 3,
            "content": [
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Aus (1.8) lässt sich die Herkunft des “Integral-Hakens” erkennen: Es ist ein grosses “S” für Summe. Analog wurde aus dem Faktor δx das Differentialsymbol dx. ii) Früher berechnete man Integrale im Sinne von (1.8) näherungsweise durch Summen . iii) Heute berechnet man Summen im Sinne von (1.8) durch Integrale mit Hilfe der Newton- Leibniz-Formel.",
                "page": 4
              }
            ]
          },
          "1.2.3": {
            "title": "Konzeption am Urbeispiel",
            "page": 4,
            "content": []
          },
          "1.2.4": {
            "title": "Anwendungen",
            "page": 5,
            "content": []
          }
        }
      }
    }
  },
  "2": {
    "title": "Vektoranalysis",
    "page": 9,
    "sections": {
      "2.1": {
        "title": "Grundlagen",
        "page": 9,
        "subsections": {
          "2.1.1": {
            "title": "Skalarfelder",
            "page": 9,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Wir betrachten die folgende Definition.",
                "page": 9
              },
              {
                "type": "Definition",
                "text": "Definition 2.1",
                "details": "Reellwertige Funktion in mehreren reellen Variablen Seien n ∈N+, A ⊆Rn und B ⊆R. Eine Funktion auf A der Form f : A →B heisst reellwertige Funktion in n reellen Variablen.",
                "page": 9
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die reellen Variablen werden nach dem Funktionsnamen f in runden Klammern aufge- zählt, jeweils durch ein Semicolon getrennt. n = 1 : f(x) = . . . (2.1) n = 2 : f(x; y) = . . . (2.2) n = 3 : f(x; y; z) = . . . (2.3) allg: f(x1; x2; . . . ; xn) = . . . (2.4) ii) Wird die Definitionsmenge A als Teilmenge eines geometrischen Raumes interpretiert, dann wird f als Skalarfeld auf A bezeichnet. iii) Im allgemeinen können die reellen Variablen x1, x2, . . . , xn ∈R und der Funktionswert f(x1; x2; . . . ; xn) bliebige und auch unterschiedliche Masseinheiten tragen. iv) Gilt n ≥2 und enthält die Definitionsmenge A einen auch noch so kleinen Würfel in nD, dann kann f nicht injektiv sein. v) Aus dem Wert von n kann apriori keine Aussage über die Surjektivität der Funktion gemacht werden. vi) Der Begriff Beschränktheit lässt sich direkt von 1D auf nD übertragen. vii) Der Begriff Monotonie lässt sich nicht von 1D auf nD übertragen. I-11",
                "page": 9
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Skalarfeld in 2D: f : R2 →R \u0000x; y \u0001 7→f(x; y) := x · y. (2.5) Es gilt dann f(2; 3) = 2 · 3 = 6 (2.6) f(−3; 5) = −3 · 5 = −15. (2.7) • Abstand zum Ursprung in nD: n = 1 : r(x) := √ x2 = |x| (2.8) n = 2 : r(x; y) := p x2 + y2 (2.9) n = 3 : r(x; y; z) := p x2 + y2 + z2 (2.10) allg: r(x1; x2; . . . ; xn) := q x2 1 + x2 2 + . . . + x2 n (2.11) • Höhe über Meer auf einer topographischen Karte: H : [0, π] × [0, 2π] →R+ 0 [m] \u0000θ ; φ \u0001 7→H(θ; φ) :≡Höhe über Meer an der Position \u0000θ ; φ \u0001 . (2.12) • Volumen eines Kreiskegels als Funktion von Radius und Höhe: V : R+ 0 [m] × R+ 0 [m] →R+ 0 [m3] \u0000r ; h \u0001 7→V (r; h) := 1 3 · π · r2 · h. (2.13) • Gesamtenergie eines Projektils der Masse m: E : R \u0002m s \u0003 × R[m] →R[J] \u0000v ; h \u0001 7→E(v; h) := m 2 · v2 + m · g · h. (2.14) • Zeitunabhängiges Temperaturfeld: T : R3[m] →R+ 0 [K] \u0000x; y ; z \u0001 7→T(x; y; z) :≡Temperatur am Ort \u0000x; y ; z \u0001 . (2.15) • Zeitabhängiges Temperaturfeld: T : R[s] × R3[m] →R+ 0 [K] \u0000t; x; y ; z \u0001 7→T(t; x; y; z) :≡Temperatur zur Zeit t am Ort \u0000x; y ; z \u0001 . (2.16) I-12",
                "page": 10
              },
              {
                "type": "Definition",
                "text": "Definition 2.2",
                "details": "Level-Menge Seien n ∈N+, A ⊆Rn, B ⊆R und f eine reellwertige Funktion der Form f : A →B. Die Level-Menge zu einem Level L ∈R ist das Urbild f −1\u0000{L} \u0001 = \b p ∈A f(p) = L . (2.17)",
                "page": 11
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Level-Menge zum Level L besteht aus allen Elementen der Definitionsmenge, an welchen die Funktion den Wert des Levels L hat. ii) Die Begriffe Level-Menge und Niveau-Menge sind synonym. iii) Für n = 2 sind die Level-Mengen meistens Kurven in der x-y-Ebene, welche als Level- Linien bzw. Niveau-Linien bezeichnet werden. iv) Für n = 3 sind die Level-Mengen meistens Flächen in 3D, welche als Level-Flächen bzw. Niveau-Flächen bezeichnet werden. v) Insbesondere für n ∈{2, 3} ist die Struktur der Level-Mengen sehr nützlich für die Visua- lisierung (Plot) von f.",
                "page": 11
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Die Level-Mengen des Abstandes zum Ursprung sind Sphären mit Mittelpunkt am Ursprung. • Die Level-Linien der Höhe über Meer sind die Höhenlinien auf einer topographischen Karte. I-13",
                "page": 11
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Flächen-Plot.",
                "details": "2. Farb-Plot: Die Funktionswerte werden durch unterschiedliche Farben gekennzeichnet.",
                "page": 12
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Thematische Landkarten, Thermographie.",
                "details": "I-14",
                "page": 12
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Höhenlinien, Äquipotentiallinien, Äquipotentialflächen, Atomorbitale.",
                "details": "",
                "page": 13
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Welche Visualisierung am besten geeignet ist, hängt sowohl von der Dimension als auch vom Verlauf der Funktion ab. ii) Nicht jede Fläche in 3D ist der Graph einer Funktion f : R2 →R. Gegenbeispiel: Alle geschlossenen Flächen, wie z.B. eine Sphäre. iii) Jede Ebene in 3D kann als Graph einer Funktion f : R2 →R beschrieben werden. Dies geschieht mit Hilfe einer Normalen-Gleichung.",
                "page": 13
              }
            ]
          },
          "2.1.2": {
            "title": "Vektorfelder",
            "page": 13,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Wir betrachten die folgende Definition.",
                "page": 13
              },
              {
                "type": "Definition",
                "text": "Definition 2.3",
                "details": "Vektorwertige Funktion in mehreren reellen Variablen Seien n ∈N+ \\ {1}, A, B ⊆Rn. Eine Funktion auf A der Form v : A →B heisst vektorwertige Funktion in n reellen Variablen.",
                "page": 13
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die reellen Variablen werden nach dem Funktionsnamen v in runden Klammern aufge- zählt, jeweils durch ein Semicolon getrennt. n = 2 : v(x; y) = \u0014 vx(x; y) vy(x; y) \u0015 (2.18) n = 3 : v(x; y; z) =   vx(x; y; z) vy(x; y; z) vz(x; y; z)   (2.19) allg: v(x1; x2; . . . ; xn) =   v1(x1; x2; . . . ; xn) v2(x1; x2; . . . ; xn) ... vn(x1; x2; . . . ; xn)   (2.20) ii) Jede Komponente eines Vektorfeldes ist eine reellwertige Funktion in n reellen Variablen. I-15",
                "page": 13
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Strömungsdynamik: Die zentrale Grösse ist das Geschwindigkeitsvektorfeld v(t; x; y; z) ≡Geschwindigkeit des Mediums zur Zeit t am Ort \u0000x; y ; z \u0001 . (2.21) • Elektrodynamik: Um Dichte und Bewegung von elektrischen Ladungen und die Wechselwir- kung mit elektrischen und magnetischen Feldern zu beschreiben, werden mehrere im allge- meinen zeitabhängige Skalarfelder und zeitabhängige Vektorfelder verwendet. ρ(t; x; y; z) :≡Elektrische Ladungsdichte (2.22) v(t; x; y; z) :≡Geschwindigkeitsfeld der elektrischen Ladungsträger (2.23) J(t; x; y; z) := ρ(t; x; y; z) · v(t; x; y; z) ≡Stromdichte-Vektorfeld (2.24) E(t; x; y; z) :≡Elektrisches Feld (2.25) B(t; x; y; z) :≡Magnetisches Feld ≡Magnetische Flussdichte (veraltet) (2.26) P(t; x; y; z) :≡Polarisation (2.27) M(t; x; y; z) :≡Magnetisierung (2.28) D(t; x; y; z) :≡Dielektrische Verschiebung (2.29) H(t; x; y; z) :≡Magnetisches Hilfsfeld ≡Magnetfeld (veraltet) (2.30) S(t; x; y; z) :≡Poynting-Vektorfeld (2.31) ϕ(t; x; y; z) :≡Skalarpotential (2.32) A(t; x; y; z) :≡Vektorpotential (2.33) • Differentialgleichungen ersten Grades: Der Verlauf der verschiedenen Lösungen einer ODE ersten Grades kann durch das Richtungsvektorfeld ˆv(x; y) beschrieben und visualisiert wer- den. I-16",
                "page": 14
              },
              {
                "type": "Definition",
                "text": "Definition 2.4",
                "details": "Einheitsvektorfeld Seien n ∈N+ \\ {1}, A, B ⊆Rn, dann ist ein Vektorfeld v : A →B ein Einheitsvektorfeld, falls für alle p ∈A gilt v(p) = ˆv(p). (2.34)",
                "page": 15
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Bei einem Einheitsvektorfeld wird an jedem Punkt p ∈A ein Einheitsvektor “angehängt”. ii) Wenn ein Vektorfeld als Einheitsvektorfeld identifiziert ist, dann wird es in der Notation sinnvollerweise durch einen Hut gekennzeichnet. iii) Wie alle Einheitsvektoren, tragen auch die Vektoren eines Einheitsvektorfeldes keine Mass- einheit. iv) Die Bezeichnungen Einheitsvektorfeld und Richtungsvektorfeld sind synonym. Wir betrachten folgende Definition.",
                "page": 15
              },
              {
                "type": "Definition",
                "text": "Definition 2.5",
                "details": "Homogenes Vektorfeld Seien n ∈N+ \\ {1}, A, B ⊆Rn, dann ist ein Vektorfeld v : A →B homogen, falls es ein w ∈B gibt, so dass für alle p ∈A gilt v(p) = w. (2.35)",
                "page": 15
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Ein homogenes Vektorfeld ist einfach ein konstantes Vektorfeld. ii) Bei einem homogenen Vektorfeld wird an jedem Punkt p ∈A der gleiche Vektor w “an- gehängt”.",
                "page": 15
              }
            ]
          }
        }
      },
      "2.2": {
        "title": "Parametrisierte Kurven & Linienintegrale",
        "page": 16,
        "subsections": {
          "2.2.1": {
            "title": "Parametrisierte Kurven",
            "page": 16,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Wir betrachten die folgende Definition.",
                "page": 16
              },
              {
                "type": "Definition",
                "text": "Definition 2.6",
                "details": "Parametrisierte Kurve Seien n ∈N+ und τ0, τE ∈R mit τ0 < τE. Eine parametrisierte Kurve ist eine differentierbare Funktion der Form s : [τ0, τE] →Rn τ 7→s(τ) :=   s1(τ) s2(τ) ... sn(τ)  . (2.36) Analog zur Vektor-Kinematik in der Physik definiert man weitere Begriffe, um eine parametri- sierte Kurve zu beschreiben. Wir betrachten dazu die folgende Definition.",
                "page": 16
              },
              {
                "type": "Definition",
                "text": "Definition 2.7",
                "details": "Weitere Begriffe Seien n ∈N+, τ0, τE ∈R mit τ0 < τE und s : [τ0, τE] →Rn eine parametrisierte Kurve. (a) Geschwindigkeitsvektor: v(τ) := ˙s(τ) (b) Bahngeschwindigkeit: v(τ) := |v(τ)| (c) Bahnvektor für v(τ) ̸= 0: ˆe(τ) := ˆv(τ) (d) Beschleunigungsvektor: a(τ) := ˙v(τ) (e) Bahnbeschleunigung: aB(τ) := ⟨a(τ), ˆe(τ)⟩ (f) Bahn: B = s \u0000[τ0, τE] \u0001",
                "page": 16
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Ortsvektor s(τ) zeigt für jedes τ vom Ursprung auf den entsprechenden Punkt der Bahn der parametrisierten Kurve in Rn. ii) Für die Masseinheiten erhalten wir [v] = [v] = [s] [τ ] (2.37) [a] = [aB] = [s] [τ ]2 . (2.38) I-18",
                "page": 16
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten die parametrisierte Kurve s(τ) = \u0014 3 · cos(τ) 3 · sin(τ) \u0015 für τ ∈[0, π]. (2.39) Die Bahn dieser parametrisierten Kurve ist ein Halbkreis mit Mittelpunkt am Ursprung und Radius r = 3. • Wir betrachten die parametrisierte Kurve s(τ) = \u0014 3 · cos(π · τ) 3 · sin(π · τ) \u0015 für τ ∈[0, 1]. (2.40) Die Bahn ist die gleiche wie beim ersten Beispiel. • Wir betrachten die parametrisierte Kurve s(τ) = \" 3 · cos \u0000π · τ 2\u0001 3 · sin \u0000π · τ 2\u0001 # für τ ∈[0, 1]. (2.41) Die Bahn ist die gleiche wie beim ersten Beispiel. • Wir betrachten die parametrisierte Kurve s(τ) = \u0014 3 2 \u0015 + \u0014 −2 1 \u0015 · τ für τ ∈[0, 4]. (2.42) Die Bahn ist eine gerade Strecke zwischen den Punkten \u00003; 2 \u0001 und \u0000−5; 6 \u0001 . I-19",
                "page": 17
              },
              {
                "type": "Definition",
                "text": "Definition 2.8",
                "details": "Bogenlänge Seien n ∈N+, τ0, τE ∈R mit τ0 < τE und s : [τ0, τE] →Rn eine parametrisierte Kurve mit Bahngeschwindigkeit v(τ). Die Bogenlänge der parametrisierten Kurve ist die reelle Zahl ∆s := Z τE τ0 v(τ) dτ. (2.49)",
                "page": 18
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für die Masseinheit erhalten wir [∆s] = [v] · [τ ] = [v] · [τ ] = [s] [τ ] · [τ ] = [s]. (2.50) I-20",
                "page": 18
              }
            ]
          },
          "2.2.2": {
            "title": "Linienintegrale",
            "page": 19,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.9",
                "details": "Linienintegral Seien n ∈N+, τ0, τE ∈R mit τ0 < τE, s : [τ0, τE] →Rn eine parametrisierte Kurve mit Ge- schwindigkeitsvektor v(τ) und w : Rn →Rn ein Vektorfeld. Das Linienintegral des Vektorfeldes w entlang der Kurve s(τ) ist die reelle Zahl I := Z τE τ0 ⟨w, v⟩dτ. (2.53)",
                "page": 19
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Begriffe Linienintegral und Kurvenintegral sind synonym. ii) Für die Masseinheit erhalten wir [I ] = \u0002 ⟨w, v⟩ \u0003 · [τ ] = [w] · [v] · [τ ] = [w] · [s] [τ ] · [τ ] = [w] · [s]. (2.54) I-21",
                "page": 19
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Mechanik: Arbeitsintegral gemäss ∆W = Z sE s0 ⟨F(s), ˆe⟩ds. (2.60) • Elektrodynamik: Elektrische Spannung gemäss U = Z sE s0 ⟨E, ˆe⟩ds. (2.61) Wir betrachten den folgenden Satz.",
                "page": 21
              },
              {
                "type": "Satz",
                "text": "Satz 2.1",
                "details": "Linienintegral bei konstantem Anteil entlang der Bahn Seien n ∈N+, τ0, τE ∈R mit τ0 < τE, s : [τ0, τE] →Rn eine parametrisierte Kurve mit Bahnvektor ˆe(τ) und Bogenlänge ∆s sowie w : Rn →Rn ein Vektorfeld. Gilt entlang der Bahn der Kurve ⟨w, ˆe⟩=: C ≡konst., dann beträgt das Linienintegral von w entlang der Kurve I = C · ∆s. (2.62)",
                "page": 21
              },
              {
                "type": "Beweis",
                "text": "Beweis: Für das Linienintegral von w entlang der Kurve erhalten wir",
                "details": "I = Z τE τ0 ⟨w, v⟩dτ = Z sE s0 ⟨w, ˆe⟩ds = Z sE s0 C ds = C Z sE s0 1 ds = C · h s i sE s0 = C · (sE −s0) = C · ∆s. (2.63) Damit haben wir den Satz bewiesen. I-23",
                "page": 21
              }
            ]
          }
        }
      },
      "2.3": {
        "title": "Mehrfach-Integrale",
        "page": 22,
        "subsections": {
          "2.3.1": {
            "title": "Zweifach-Integrale",
            "page": 22,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Wir betrachten ein Gebiet G ⊂R2 und eine Funktion f : R2 →R. Der Graph von f ist im folgenden x-y-z-Diagramm dargestellt. Wir betrachten die folgende Definition.",
                "page": 22
              },
              {
                "type": "Definition",
                "text": "Definition 2.10",
                "details": "Integration über ein Gebiet Seien G ⊂R2 ein Gebiet und f : R2 →R eine integrierbare Funktion. Das Integral von f über das Gebiet G ist Z G f dA :≡Volumen zwischen G und dem Graphen von f. (2.64)",
                "page": 22
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Wie in 1D lassen sich präzise Bedingungen definieren, die an eine Teilmenge G ⊂R2 und an eine Funktion f gestellt werden müssen, damit das Integral existiert. Ohne im Detail auf diese Voraussetzungen einzugehen, bezeichnen wir eine Teilmenge G ⊂R2 als Gebiet und eine Funktion f : R2 →R als integrierbar, falls alle notwendigen Kriterien erfüllt sind. ii) Für die Masseinheit erhalten wir \u0014 Z G f dA \u0015 = [V ] = [A] · [f ] = [x] · [y] · [f ] = [x] · [y] · [z]. (2.65) iii) Ein Integral über ein Gebiet in 2D wird synonym auch als Zweifach-Integral oder Doppel- Integral bezeichnet. I-24",
                "page": 22
              },
              {
                "type": "Satz",
                "text": "Satz 2.2",
                "details": "Linearität des Integrals in 2D Seien G ⊂R2 ein Gebiet, g, h : R2 →R integrierbare Funktionen und a, b ∈R. Dann gelten die folgenden Rechenregeln. (a) Faktor-Regel: Z G a · g dA = a Z G g dA. (2.69) (b) Summen-Regel: Z G \u0010 g + h \u0011 dA = Z G g dA + Z G h dA. (2.70) (c) Linearität: Z G \u0010 a · g + b · h \u0011 dx = a Z G g dA + b Z G h dA. (2.71) Wie in 1D kann auch in 2D ein Integral in mehrere zerlegt werden. Dazu betrachten wir den folgenden Satz. I-25",
                "page": 23
              },
              {
                "type": "Satz",
                "text": "Satz 2.3",
                "details": "Zerlegungssatz in 2D Seien G, H ⊂R2 Gebiete und f : R2 →R eine integrierbare Funktion, dann gilt Z G∪H f dA = Z G f dA + Z H f dA − Z G∩H f dA. (2.72) Wir betrachten den folgenden Satz.",
                "page": 24
              },
              {
                "type": "Satz",
                "text": "Satz 2.4",
                "details": "Flächensatz Sei G ⊂R2 ein Gebiet mit Flächeninhalt A > 0, dann gilt A = Z G 1 dA. (2.73)",
                "page": 24
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Im Spezialfall, dass der Integrand den konstanten Wert 1 hat, ist das Volumen zwischen dem Gebiet G in der x-y-Ebene und dem Graph des Integranden gerade der Flächeninhalt von G. ii) Man prüft leicht nach, dass der berechnete Flächeninhalt die korrekte Masseinheit hat. Es gilt [A] = \u0014 Z G 1 dA \u0015 = [x] · [y] · [1] = [x] · [y] · 1 = [x] · [y]. (2.74) iii) Der Flächensatz stellt eine fundamentale Verbindung her zwischen dem Begriff Integral aus der Analysis und dem Begriff Flächeninhalt aus der Geometrie.",
                "page": 24
              },
              {
                "type": "Satz",
                "text": "Satz 2.5",
                "details": "Fubini-Satz für Rechtecke Seien x0, xE, y0, yE ∈R mit x0 < xE und y0 < yE, f : R2 →R eine integrierbare Funktion sowie G das Rechteck G := [x0, xE] × [y0, yE]. (2.75) Dann gilt Z G f dA = Z yE y0 Z xE x0 f(x; y) dx dy = Z xE x0 Z yE y0 f(x; y) dy dx. (2.76) I-26",
                "page": 24
              },
              {
                "type": "Beweis",
                "text": "Beweis: Um das Volumen zwischen dem Reckteck G und dem Graphen von f zu berechnen",
                "details": "verwenden wir einen Archimedes-Cauchy-Riemann-Approximationsprozess. Dabei gehen wir nach folgenden Schritten vor. S1 Lokal: Wir betrachten einen kleinen Streifen des Rechtecks G mit Breite δx > 0, wie im folgenden x-y-z-Diagramm dargestellt. Die Querschnittsfläche AQ(x) können wir berechnen durch das bestimmte Integral AQ(x) = Z yE y0 f(x; y) dy. (2.77) Das Volumen zwischen dem kleinen Streifen und dem Graphen von f ist δI ≈AQ(x) · δx. (2.78) S2 Global: Durch Integration über x können wir das gesamte Volumen zwischen dem Rechteck G und dem Graphen von f berechnen. Wir erhalten I = Z xE x0 AQ(x) dx = Z xE x0 Z yE y0 f(x; y) dy dx. (2.79) Durch Vertauschen der Rollen von x und y erhalten wir auf analoge Weise die zweite Version. Damit haben wir den Satz bewiesen.",
                "page": 25
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Durch den Fubini-Satz kann ein Integral über ein Gebiet in 2D auf die Berechnung von 2 verschachtelten Integralen in 1D zurückgeführt werden und umgekehrt. ii) Bei der Anwendung des Fubini-Satzes werden die Zweifach-Integrale in der Reihenfolge von innen nach aussen berechnet. iii) Bei der Integration über ein Rechteck kann die Integrationsreihenfolge vertauscht werden. iv) Der Fubini-Satz ist ein allgemein gültiges Prinzip, dessen Aussage sowohl auf allgemeinere Gebiete als auch auf Gebiete in nD erweitert werden kann. I-27",
                "page": 25
              },
              {
                "type": "Satz",
                "text": "Satz 2.6",
                "details": "Spezialfälle der Integration über ein Rechteck. Seien x0, xE, y0, yE ∈R mit x0 < xE und y0 < yE sowie G das Rechteck G := [x0, xE] × [y0, yE]. (2.80) Dann gilt folgendes. (a) Konstanten-Regel: Für alle C ∈R ist Z G C dA = C · (xE −x0) · (yE −y0). (2.81) (b) Separation-Regel: Für zwei integrierbare Funktionen g, h : R →R ist Z G g(x) · h(y) dA = Z xE x0 g(x) dx · Z yE y0 h(y) dy. (2.82)",
                "page": 26
              },
              {
                "type": "Beweis",
                "text": "Beweis: Gemäss Fubini-Satz und Faktor-Regel gilt",
                "details": "Z G g(x) · h(y) dA = Z yE y0 Z xE x0 g(x) · h(y) dx dy = Z yE y0 h(y) · Z xE x0 g(x) dx dy = Z xE x0 g(x) dx · Z yE y0 h(y) dy. (2.83) Wir zeigen mehrere Varianten, um die Konstanten-Regel zu beweisen. Variante 1: Gemäss Fubini-Satz und Faktor-Regel gilt Z G C dA = Z yE y0 Z xE x0 C dx dy = C Z yE y0 Z xE x0 1 dx dy = C Z yE y0 h x i xE x0 dy = C Z yE y0 (xE −x0) dy = C · (xE −x0) Z yE y0 1 dy = C · (xE −x0) · h y i yE y0 = C · (xE −x0) · (yE −y0). (2.84) Variante 2: Gemäss Faktor-Regel und Separation-Regel gilt Z G C dA = C Z G 1 dA = C Z G 1 · 1 dA = C Z xE x0 1 dx · Z yE y0 1 dy = C · h x i xE x0 · h y i yE y0 = C · (xE −x0) · (yE −y0). (2.85) Variante 3: Gemäss Faktor-Regel und Flächensatz gilt Z G C dA = C Z G 1 dA = C · A = C · ∆x · ∆y = C · (xE −x0) · (yE −y0). (2.86) Damit haben wir den Satz bewiesen. I-28",
                "page": 26
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Bei allen Anwendungen des Fubini-Satzes werden die Zweifach-Integrale in der Reihen- folge von innen nach aussen berechnet. Dabei dürfen die Grenzen des inneren Integrals von der Integrationsvariablen des äusseren Integrals abhängen. ii) Bei der Integration über ein dreieckartiges Gebiet kann die Integrationsreihenfolge auf einfache Weise vertauscht werden. iii) Es gibt eine Analogie zwischen den Grenzen eines Zweifach-Integrals und den Bewegungen des Stifts in einem Plotter. Dabei kann man sich vorstellen, dass der Stift des Plotters das Gebiet auf dem Papier komplett “überstreichen” muss. Inneres Integral schnelle hin und her Bewegungen des Stifts entlang des Balkens Äusseres Integral langsame Bewegung des Balkens entlang des Papiers Beim Vertauschen der Integrationsreihenfolge wird das Papier um einen rechten Winkel gedreht. I-30",
                "page": 28
              }
            ]
          },
          "2.3.2": {
            "title": "Dreifach-Integrale",
            "page": 29,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.7",
                "details": "Fubini-Satz für Quader Seien x0, xE, y0, yE, z0, zE ∈R mit x0 < xE, y0 < yE und z0 < zE, f : R3 →R eine integrierbare Funktion sowie Q der Quader Q := [x0, xE] × [y0, yE] × [z0, zE]. (2.90) Dann gilt Z Q f dV = Z zE z0 Z yE y0 Z xE x0 f(x; y; z) dx dy dz. (2.91)",
                "page": 29
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Durch den Fubini-Satz kann ein Integral über ein Gebiet in 3D auf die Berechnung von 3 verschachtelten Integralen in 1D zurückgeführt werden und umgekehrt. ii) Bei der Anwendung des Fubini-Satzes werden die Dreifach-Integrale in der Reihenfolge von innen nach aussen berechnet. iii) Bei der Integration über einen Quader kann die Integrationsreihenfolge vertauscht werden. Integrale über Gebiete in 3D erhält man aus einem Archimedes-Cauchy-Riemann-Appro- ximationsprozess in 3D gemäss folgenden Schritten. S1 Lokal: Der Beitrag zur Grösse I eines kleinen Volumenstücks δV im x-y-z-Raum ist δI ≈. . . ≈f(x; y; z) · δV. (2.92) S2 Global: Durch Integration über das Gebiet G können wir die gesamte Grösse I berechnen. Wir erhalten I = Z G f dV = . . . . (2.93)",
                "page": 29
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Masse: Wir betrachten einen Körpers K mit Dichte ρ : R3 →R. S1 Lokal: Die Masse eines kleinen Volumenstücks δV im x-y-z-Raum ist δm ≈ρ · δV = ρ(x; y; z) · δV. (2.94) S2 Global: Durch Integration über den Körper K können wir seine gesamte Masse berech- nen. Wir erhalten m = Z K ρ dV. (2.95) I-31",
                "page": 29
              }
            ]
          }
        }
      },
      "2.4": {
        "title": "Parametrisierte Flächen & Flussintegrale",
        "page": 31,
        "subsections": {
          "2.4.1": {
            "title": "Parametrisierte Flächen",
            "page": 31,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Wir betrachten eine allgemeine Fläche M ⊂R3, welche durch zwei Parameter bzw. Koordinaten u und v aus einem Gebiet U ⊆R2 parametrisiert wird. Die Situation ist in der folgenden Skizze dargestellt. u v \u0000u; v\u0001 P(u; v) P(u; v) z y x U M v u",
                "page": 31
              },
              {
                "type": "Definition",
                "text": "Definition 2.11",
                "details": "Parametrisierte Fläche Sei U ⊆R2 ein Gebiet und M ⊂R3 ein Fläche. Eine Parametrisierung von M ist eine Funktion der Form P : U →R3 \u0000u; v \u0001 7→P(u; v) =   x(u; v) y(u; v) z(u; v)  , (2.98) so dass M = P(U).",
                "page": 31
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) In Anlehnung an die Geographie werden U Karten-Gebiet oder Karte und die Parameter u und v auch Koordinaten genannt. ii) Erfahrungsgemäss können viele Rechnungen im Umgang mit der Parametrisierung einfach gehalten werden, wenn man, sofern möglich, für das Karten-Gebiet U ein Rechteck wählt. iii) Weil die Parametrisierung P von einem Gebiet in 2D in den Raum in 3D führt, kann sie als Funktion niemals surjektiv sein. iv) Die Parametrisierung P soll als Funktion so “injektiv wie möglich” gewählt werden. So- lange nur mehrere einzelne Punkte oder Kurvenstücke aus dem Karten-Gebiet auf den gleichen Punkt in M abgebildet werden, ergeben sich in der Regel keine Probleme. v) Die Parameter bzw. Koordinaten u und v können je nach Fläche ganz unterschiedliche Bedeutungen und Masseinheiten haben, z.B. Längen, Winkel, etc.. I-33",
                "page": 31
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Eine Ebene, welche durch den Punkt P0 verläuft und aufgespannt wird durch die beiden Vektoren v und w. Das Karten-Gebiet ist U = R2 und die übliche Parametrisierung lautet P(u; v) = P0 + u · v + v · w. (2.99) Diese Parametrisierung ist eine bijektive Abbildung zwischen der ganzen u-v-Ebene und der zu parametrisierenden Ebene M in 3D. • Eine Sphäre mit Radius R > 0 und Mittelpunkt am Ursprung. Das Karten-Gebiet ist U = [0, π] × [0, 2π[ und die übliche Parametrisierung lautet P(θ; φ) =   x(θ; φ) y(θ; ϕ) z(θ; φ)  =   R · sin(θ) · cos(φ) R · sin(θ) · sin(φ) R · cos(θ)  . (2.100) Diese Parametrisierung ist nicht injektiv, weil die Strecken {0} × [0, 2π[ und {π} × [0, 2π[ jeweils als Ganzes auf den Nord- bzw. Südpol der Sphäre abgebildet werden. I-34",
                "page": 32
              },
              {
                "type": "Definition",
                "text": "Definition 2.12",
                "details": "Koordinatenbasis-Vektorfelder Seien U ⊆R2 und P : U →R3 eine parametrisierte Fläche mit Koordinaten u und v. Die Koordinatenbasis-Vektorfelder sind die Vektorfelder eu : U →R3 \u0000u; v \u0001 7→eu(u; v) := P,u(u; v) und ev : U →R3 \u0000u; v \u0001 7→ev(u; v) := P,v(u; v), (2.101) wobei mit P,u und P,v die Ableitungen von P nach den Koordinaten u bzw. v gemeint sind.",
                "page": 33
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Koordinatenbasis-Vektorfelder sind Funktionen der Koordinaten u und v und in diesem Sinne wirklich Vektorfelder. ii) Die Koordinatenbasis-Vektorfelder werden bezeichnet durch {eu, ev} oder {e1, e2}. iii) An jedem Punkt von M zeigen die Koordinatenbasis-Vektorfelder je in eine tangentiale Richtung. Sie spannen daher die Tangentialebene an M auf.",
                "page": 33
              },
              {
                "type": "Definition",
                "text": "Definition 2.13",
                "details": "Normalen-Vektor Der Normalen-Vektor einer parametrisierten Fläche ist das Grassmann-Vektor-Produkt der Koordinatenbasis-Vektorfelder, d.h. n := eu × ev. (2.102)",
                "page": 33
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Normalen-Vektor steht senkrecht auf der Fläche M. ii) Die Länge des Normalen-Vektors hängt ab von der Parametrisierung. I-35",
                "page": 33
              },
              {
                "type": "Definition",
                "text": "Definition 2.14",
                "details": "Metrik Die Metrik einer parametrisierten Fläche ist die Gram-Matrix der Koordinatenbasis-Vektorfelder, d.h. G := \u0014 g11 g12 g21 g22 \u0015 := \u0014 ⟨e1 , e1⟩ ⟨e1 , e2⟩ ⟨e2 , e1⟩ ⟨e2 , e2⟩ \u0015 . (2.104)",
                "page": 34
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Weil das Skalar-Produkt symmetrisch ist, gilt dies auch für G, d.h. GT = G. (2.105) ii) Weil das Skalar-Produkt positiv definit ist, gilt dies auch für G, d.h. g := det(G) = g11 · g22 −g21 · g12 > 0. (2.106) iii) In vielen Anwendungen stehen die Koordinatenbasis-Vektorfelder senkrecht aufeinander. Allgemein gilt e1 ⊥e2 ⇔G ist diagonal. (2.107)",
                "page": 34
              },
              {
                "type": "Definition",
                "text": "Definition 2.15",
                "details": "Mass-Funktion Seien G die Metrik einer parametrisierten Fläche und g := det(G), (2.108) dann ist die Mass-Funktion die Wurzel √g. Wir betrachten folgenden Satz.",
                "page": 34
              },
              {
                "type": "Satz",
                "text": "Satz 2.8",
                "details": "Normalen-Vektor & Mass-Funktion Seien n der Normalen-Vektor und √g die Mass-Funktion einer parametrisierten Fläche, dann gilt √g = |n|. (2.109) I-36",
                "page": 34
              },
              {
                "type": "Beweis",
                "text": "Beweis: Es seien e1 und e2 die Koordinatenbasis-Vektorfelder der parametrisierten Fläche mit",
                "details": "Zwischenwinkel α := ∡(e1; e2) ∈[0, π]. Somit folgt sin(α) ≥0 und √g = p det(G) = √g11 · g22 −g12 · g21 = p ⟨e1 , e1⟩· ⟨e2 , e2⟩−⟨e1 , e2⟩· ⟨e2 , e1⟩ = q |e1|2 · |e2|2 −⟨e1 , e2⟩2 = q |e1|2 · |e2|2 −|e1|2 · |e2|2 · cos2(α) = q |e1|2 · |e2|2 · \u00001 −cos2(α) \u0001 = q |e1|2 · |e2|2 · sin2(α) = |e1| · |e2| · sin(α) = |e1 × e2| = |n|. (2.110) Damit haben wir den Satz bewiesen.",
                "page": 35
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Wegen g > 0 kann die Wurzel immer in den reellen Zahlen gezogen werden und es gilt √g > 0. (2.111) ii) Für den Einheitsnormalen-Vektor folgt ˆn := ± 1 √g · n. (2.112) I-37",
                "page": 35
              }
            ]
          },
          "2.4.2": {
            "title": "Flächenintegrale",
            "page": 36,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.16",
                "details": "Flächenintegral über eine parametrisierte Fläche Seien U ⊆R2, P : U →R3 eine parametrisierte Fläche mit Mass-Funktion √g und f : M →R, dann ist das Integral von f über M definiert durch Z M f dA := Z U f √g dU. (2.115) Wir betrachten folgenden Satz.",
                "page": 36
              },
              {
                "type": "Satz",
                "text": "Satz 2.9",
                "details": "Flächeninhalt einer parametrisierten Fläche Seien U ⊆R2 und P : U →R3 die Parametrisierung einer parametrisierten Fläche M = P(U) mit Mass-Funktion √g, dann lässt sich der Flächeninhalt von M berechnen durch A = Z M 1 dA = Z U √g dU. (2.116)",
                "page": 36
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für die Masseinheit erhalten wir \u0014 Z M f dA \u0015 = [f ] · [A] = [f ] · [ √g ] · [u] · [v]. (2.117) ii) Ist das Karten-Gebiet U ein Rechteck der Form U = [u0, uE] × [v0, vE], (2.118) dann lässt sich ein Flächenintegral berechnen durch I = Z M f dA := Z U f √g dU = Z uE u0 Z vE v0 f(u; v) p g(u; v) dv du. (2.119) iii) Ein kleines Flächenstück auf M kann im Sinne eines Archimedes-Cauchy-Riemann- Approximationsprozess ausgedrückt werden durch δA ≈√g · δU = √g · δu · δv. (2.120) Die Mass-Funktion ist also gerade der Umrechnungsfaktor für den Flächeninhalt δU eines kleinen Flächenstücks im Kartengebiet U auf das entsprechende kleine Flächenstück δA auf M. I-38",
                "page": 36
              }
            ]
          },
          "2.4.3": {
            "title": "Flussintegrale",
            "page": 37,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.17",
                "details": "Fluss eines Vektorfeldes Seien M eine parametrisierte Fläche mit Einheitsnormalen-Vektor ˆn und v : R3 →R3 ein integrierbares Vektorfeld. Der Fluss des Vektorfeldes v durch die Fläche M ist Φ := Z M ⟨v, ˆn⟩dA. (2.121)",
                "page": 37
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Begriffe Flux, Fluss und Flussintegral sind synonym. ii) Für die Masseinheit erhalten wir [Φ] = \u0002 ⟨v, ˆn⟩ \u0003 · [A] = [v] · [ˆn] · [A] = [v] · 1 · [A] = [v] · [A]. (2.122) iii) Man kann zeigen, dass das Flussintegral Φ bis auf das Vorzeichen nicht von der Wahl der Parametrisierung sondern nur von der Fläche M abhängt (sofern mehrfache Durchläufe auch mehrfach gerechnet werden). iv) Um ein Flussintegral auszurechnen, müssen die Koordinaten der Punkte entlang der para- metrisierten Fläche im Vektorfeld eingesetzt werden. Vollständig ausgeschrieben mit allen Abhängigkeiten ergibt dies Φ = Z uE u0 Z vE v0 v \u0000x(u; v); y(u; v); z(u; v) \u0001 , ˆn(u; v) · p g(u; v) dv du. (2.123) v) In der Literatur findet man für Flussintegrale durch eine Fläche M die Schreibweisen Φ = Z M ⟨v, ˆn⟩dA = Z M v · dA. (2.124) I-39",
                "page": 37
              },
              {
                "type": "Satz",
                "text": "Satz 2.10",
                "details": "Fluss bei konstantem Anteil senkrecht zur Fläche Seien M eine parametrisierte Fläche mit Einheitsnormalen-Vektor ˆn und Flächeninhalt A sowie v : R3 →R3 ein Vektorfeld. Gilt entlang der Fläche ⟨v, ˆn⟩=: C ≡konst., dann beträgt der Fluss von v durch die Fläche Φ = C · A. (2.126)",
                "page": 38
              },
              {
                "type": "Beweis",
                "text": "Beweis: Für den Fluss von v durch die Fläche erhalten wir",
                "details": "Φ = Z M ⟨v, ˆn⟩dA = Z M C dA = C Z M 1 dA = C · A. (2.127) Damit haben wir den Satz bewiesen. Wir betrachten den folgenden Satz.",
                "page": 38
              },
              {
                "type": "Satz",
                "text": "Satz 2.11",
                "details": "Perforation eines homogenen Vektorfeldes Die Perforation eines homogenen Vektorfeldes verschwindet.",
                "page": 38
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Strömungsdynamik: Φv = Z M ⟨v, ˆn⟩dA ≡Volumen-Fluss des Mediums durch die Fläche \u0014 m3 s \u0015 . (2.128) • Elektrodynamik: Wir betrachten die folgenden Fälle getrennt. Fall 1: M ist eine geschlossene Fläche. Dann gilt ΦE = I M ⟨E, ˆn⟩dA = 1 ε0 · Qeg (2.129) ΦB = I M ⟨B, ˆn⟩dA = 0. (2.130) I-40",
                "page": 38
              }
            ]
          }
        }
      },
      "2.5": {
        "title": "Mehrfach-Differentiale",
        "page": 40,
        "subsections": {
          "2.5.1": {
            "title": "Partielle Ableitungen",
            "page": 40,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.18",
                "details": "Partielle Ableitung Seien n ∈N+ und f : Rn →R eine reellwertige Funktion. Die partiellen Ableitungen von f sind die Ableitungen von f nach jeweils einer der n Variablen, wobei die anderen als Konstanten betrachtet werden.",
                "page": 40
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Eine reellwertige Funktion heisst differntierbar, wenn alle partiellen Ableitungen existieren und stetig sind. ii) Wie die Ableitung in 1D können auch die partiellen Ableitungen in nD mit Hilfe des Newton-Differenzenquotienten definiert werden gemäss f,µ(x1; x2; . . . ; xn) := lim δs→0 f(x1; x2; . . . ; xµ + δs; . . . ; xn) −f(x1; x2; . . . ; xn) δs . (2.134) iii) Für die Masseinheit erhalten wir [f,µ] = [f ] [xµ] . (2.135) iv) Die partiellen Ableitungen beschreiben an jedem Punkt die Steigungen des Funktionsgra- phen in Richtung der Koordinatenachsen. v) In der Literatur sind folgende Schreibweisen gebräuchlich f,µ = f,xµ = fxµ = ∂f ∂xµ = ∂ ∂xµ f = ∂µf. (2.136)",
                "page": 40
              }
            ]
          },
          "2.5.2": {
            "title": "Gradient",
            "page": 40,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.19",
                "details": "Gradient Seien n ∈N+ und f : Rn →R eine differentierbare reellwertige Funktion. Der Gradient von f ist das Vektorfeld ∇f :=   f,1 f,2 ... f,n  . (2.137)",
                "page": 40
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Gradient ist eine allgemeine Konstruktion in nD. I-42",
                "page": 40
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten f(x; y) := x2 · y2. (2.138) Der Gradient von f ist ∇f = \u0014 f,1 f,2 \u0015 = \u0014 2x · y2 x2 · 2y \u0015 = \u0014 2xy2 2x2y \u0015 . (2.139) • Wir betrachten f(x; y; z) := x2 · y + z. (2.140) Der Gradient von f ist ∇f =   f,1 f,2 f,3  =   2x · y + 0 x2 · 1 + 0 0 + 1  =   2xy x2 1  . (2.141) Wir betrachten den folgenden Satz.",
                "page": 41
              },
              {
                "type": "Satz",
                "text": "Satz 2.12",
                "details": "Elementare Rechenregeln für Gradienten Seien n ∈N+, g, h : Rn →R differentierbare Funktionen und a, b ∈R, dann gelten die folgenden Rechenregeln. (a) Faktor-Regel: ∇(a · g) = a · ∇g (b) Summen-Regel: ∇(g + h) = ∇g + ∇h (c) Linearität: ∇(a · g + b · h) = a · ∇g + b · ∇h (d) Produkt-Regel: ∇(g · h) = (∇g) · h + g · ∇h Wir betrachten den folgenden Satz.",
                "page": 41
              },
              {
                "type": "Satz",
                "text": "Satz 2.13",
                "details": "Ketten-Regeln für Gradienten Seien n ∈N+, dann gelten folgende Ketten-Regeln. (a) Ketten-Regel A: Für differentierbare g : R →R und h : Rn →R gilt f(x1; . . . ; xn) := g \u0000h(x1; . . . ; xn) \u0001 ⇒∇f = g′\u0000h(x1; . . . ; xn) \u0001 · ∇h. (b) Ketten-Regel B: Für differentierbare g : Rn →R und h : R →Rn gilt f(x) := g \u0000h(x) \u0001 ⇒f ′(x) = ∇g \u0000h(x) \u0001 , h′(x) . I-43",
                "page": 41
              }
            ]
          },
          "2.5.3": {
            "title": "Hesse-Matrix",
            "page": 42,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.20",
                "details": "Hesse-Matrix Seien n ∈N+ und f : Rn →R eine zweifach differentierbare reellwertige Funktion. Die Hesse- Matrix von f ist das Vektorfeld ∇2f :=   f,1,1 f,1,2 . . . f,1,n f,2,1 f,2,2 . . . f,2,n ... ... ... ... f,n,1 f,n,2 . . . f,n,n  . (2.142)",
                "page": 42
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten f(x; y) := x2 · y2. (2.143) Der Gradient von f ist ∇f = \u0014 f,1 f,2 \u0015 = \u0014 2x · y2 x2 · 2y \u0015 = \u0014 2xy2 2x2y \u0015 . (2.144) Die Hesse-Matrix von f ist ∇2f = \u0014 f,1,1 f,1,2 f,2,1 f,2,2 \u0015 = \u0014 2y2 4xy 4xy 2x2 \u0015 . (2.145) Wir betrachten den folgenden Satz.",
                "page": 42
              },
              {
                "type": "Satz",
                "text": "Satz 2.14",
                "details": "Schwarz-Clairaut-Young-Satz Seien n ∈N+ und f : Rn →R eine zweifach differentierbare reellwertige Funktion mit Hesse- Matrix H ∈M(n, n, R), dann gilt HT = H. (2.146)",
                "page": 42
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Symmetrie der Hesse-Matrix gemäss Schwarz-Clairaut-Young-Satz ist äquiva- lent zur Tatsache, dass die partiellen Ableitungen vertauscht werden dürfen, d.h. für alle µ, ν ∈{1, . . . , n} gilt f,ν,µ = f,µ,ν. (2.147) ii) Weil die Hesse-Matrix symmetrisch ist, ist sie diagonalisierbar, d.h. ähnlich zu einer diagonalen Matrix. Wir betrachten die folgende Definition.",
                "page": 42
              },
              {
                "type": "Definition",
                "text": "Definition 2.21",
                "details": "Laplace-Ableitung Seien n ∈N+ und f : Rn →R eine zweifach differentierbare reellwertige Funktion. Die La- place-Ableitung von f ist ∆f := tr \u0000∇2f \u0001 = f,1,1 + f,2,2 + . . . + f,n,n. (2.148) I-44",
                "page": 42
              }
            ]
          },
          "2.5.4": {
            "title": "Divergenz",
            "page": 43,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.22",
                "details": "Divergenz Seien n ∈N+ und v : Rn →Rn ein differentierbares Vektorfeld mit Komponenten v(x1; . . . ; xn) =   v1(x1; . . . ; xn) ... vn(x1; . . . ; xn)  . (2.149) Die Divergenz von v ist div(v) := v1 ,1 + v2 ,2 + . . . + vn ,n. (2.150)",
                "page": 43
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten v(x; y) := \u0014 x · y2 x3 · y3 \u0015 . (2.151) Die Divergenz von v ist div(v) = v1 ,1 + v2 ,2 = \u0000x · y2\u0001 ,x + \u0000x3 · y3\u0001 ,y = 1 · y2 + x3 · 3 · y2 = y2 · \u00001 + 3x3\u0001 . (2.152)",
                "page": 43
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Divergenz eines Vektorfeldes ist eine allgemeine Konstruktion in nD. ii) Die Divergenz eines Vektorfeldes ist ein Skalarfeld. iii) Die Divergenz eines Vektorfeldes ist ein Mass für dessen Quellendichte. iv) Ein Vektorfeld v heisst quellenfrei, falls gilt div(v) = 0. (2.153) Wir betrachten den folgenden Satz.",
                "page": 43
              },
              {
                "type": "Satz",
                "text": "Satz 2.15",
                "details": "Elementare Rechenregeln für Divergenzen Seien n ∈N+, v, w : Rn →Rn differentierbare Vektorfelder, f : Rn →R eine differentierbare Funktion und a, b ∈R, dann gelten die folgenden Rechenregeln. (a) Faktor-Regel: div(a · v) = a · div(v) (b) Summen-Regel: div(v + w) = div(v) + div(w) (c) Linearität: div(a · v + b · w) = a · div(v) + b · div(w) (d) Produkt-Regel: div(f · v) = ⟨∇f , v⟩+ f · div(v) I-45",
                "page": 43
              }
            ]
          },
          "2.5.5": {
            "title": "Rotation",
            "page": 44,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.23",
                "details": "Rotation in 2D Sei v : R2 →R2 ein differentierbares Vektorfeld mit Komponenten v(x1; x2) = \u0014 v1(x1; x2) v2(x1; x2) \u0015 . (2.154) Die Rotation von v ist rot(v) := v2 ,1 −v1 ,2. (2.155) Wir betrachten die folgende Definition.",
                "page": 44
              },
              {
                "type": "Definition",
                "text": "Definition 2.24",
                "details": "Rotation in 3D Sei v : R3 →R3 ein differentierbares Vektorfeld mit Komponenten v(x1; x2; x3) =   v1(x1; x2; x3) v2(x1; x2; x3) v3(x1; x2; x3)  . (2.156) Die Rotation von v ist rot(v) :=   v3,2 −v2,3 v1,3 −v3,1 v2,1 −v1,2  . (2.157)",
                "page": 44
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Rotation eines Vektorfeldes ist eine spezielle Konstruktion in 2D und 3D. ii) Die Rotation eines Vektorfeldes in 2D ist ein Skalarfeld. iii) Die Rotation eines Vektorfeldes in 3D ist ein Vektorfeld in 3D. iv) Die Rotation eines Vektorfeldes ist ein Mass für dessen Wirbeldichte. v) Ein Vektorfeld v heisst wirbelfrei, falls gilt rot(v) = 0. (2.158) vi) In 3D steht rot(v) senkrecht auf der “Wirbel-Ebene” von v, analog zum Drehimpuls einer rotierenden Scheibe. vii) Im Englischen wird die Rotation als curl bezeichnet und entsprechend auch so in Formeln notiert, d.h. durch curl(v). I-46",
                "page": 44
              },
              {
                "type": "Satz",
                "text": "Satz 2.16",
                "details": "Elementare Rechenregeln für Rotationen Seien n ∈{2, 3}, v, w : Rn →Rn differentierbare Vektorfelder, f : Rn →R eine differentierbare Funktion und a, b ∈R, dann gelten die folgenden Rechenregeln. (a) Faktor-Regel: rot(a · v) = a · rot(v) (b) Summen-Regel: rot(v + w) = rot(v) + rot(w) (c) Linearität: rot(a · v + b · w) = a · rot(v) + b · rot(w) (d) Produkt-Regel für n = 3: rot(f · v) = ∇f × v + f · rot(v)",
                "page": 45
              }
            ]
          },
          "2.5.6": {
            "title": "Weiteres zu Gradient, Divergenz und Rotation",
            "page": 45,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.17",
                "details": "Kombinierte Rechenregeln für Gradient, Divergenz & Rotation Seien n ∈N+, v : Rn →Rn ein differentierbares Vektorfeld und f : Rn →R eine differentierbare Funktion, dann gelten die folgenden Rechenregeln. (a) Divergenz eines Gradienten: div(∇f) = ∆f (b) Rotation eines Gradienten für n ∈{2, 3}: rot(∇f) = 0 (c) Divergenz einer Rotation für n = 3: div \u0000rot(v) \u0001 = 0 (d) Rotation einer Rotation für n = 3: rot \u0000rot(v) \u0001 = ∇div(v) −∆v",
                "page": 45
              },
              {
                "type": "Beweis",
                "text": "Beweis: Siehe Übungen.",
                "details": "Wir betrachten den folgenden Satz.",
                "page": 45
              },
              {
                "type": "Satz",
                "text": "Satz 2.18",
                "details": "Rechenregeln für Vektor-Produkte in 3D Seien v, w : R3 →R3 differentierbare Vektorfelder und g, h : R3 →R differentierbare Funktio- nen, dann gelten die folgenden Rechenregeln. (a) Divergenz eines Vektor-Produkts: div(v × w) = ⟨rot(v), w⟩−⟨v, rot(w)⟩ (b) Rotation eines Vektor-Produkts: rot(v × w) = ∇wv −∇vw + div(w) · v −div(v) · w (c) Divergenz eines Vektor-Produkts von Gradienten: div(∇g × ∇h) = 0 I-47",
                "page": 45
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Jeder Gradient ist wirbelfrei. ii) Jede Rotation ist quellenfrei. iii) In kartesischen Koordinaten ist ∆v komponentenweise zu berechnen. iv) Die Terme ∇wv und ∇vw bezeichnen sogenannte Richtungsableitungen (siehe nächste Abschnitte.)",
                "page": 46
              },
              {
                "type": "Definition",
                "text": "Definition 2.25",
                "details": "Nabla-Operator in nD Sei n ∈N+, dann ist der Nabla-Operator in Rn der Differentialoperator ∇:=   ∂1 ... ∂n  . (2.159)",
                "page": 46
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Nabla-Operator ist ein abstrakter Differentialoperator, welcher erst bei seiner Anwen- dung auf eine Funktion bzw. ein Vektorfeld eine sinnvolle mathematische Grösse ergibt. ii) Durch den Nabla-Operator können die Divergenz in nD und die Rotation in 3D durch Vektor-Operationen ausgedrückt werden. Insbesondere in älterer Literatur findet man die Schreibweisen div(v) = ⟨∇, v⟩= ∇· v (2.160) rot(v) = ∇× v. (2.161)",
                "page": 46
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen",
                "details": "Viele wichtige Formeln in der Physik werden durch Divergenz bzw. Rotation von Vektorfeldern ausgedrückt. • Strömungsdynamik: Beschreibt v das Geschwindigkeitsvektorfeld eines inkompressiblen Me- diums (z.B. Wasser), dann ist es quellenfrei, d.h. div(v) = 0. (2.162) • Elektrodynamik: Die Maxwell-Gleichungen beschreiben jeweils Divergenz und Rotation des E-Feldes und B-Feldes. Es gilt div(E) = 1 ε0 · ρ rot(E) = −˙B div(B) = 0 rot(B) = ε0 · µ0 · ˙E + µ0 · J. (2.163) Der Ladungs-Erhaltungssatz kann ausgedrückt werden durch die Kontinuitätsgleichung ˙ρ + div(J) = 0. (2.164) I-48",
                "page": 46
              }
            ]
          }
        }
      },
      "2.6": {
        "title": "Hauptsätze der Vektoranalysis",
        "page": 47,
        "subsections": {
          "2.6.1": {
            "title": "Gauss-Integralsatz",
            "page": 47,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.19",
                "details": "Gauss-Integralsatz in 3D Seien K ⊂R3 ein Körper mit Oberfläche ∂K, äusserem Einheitsnormalen-Vektorfeld ˆn im Bereich eines differentierbaren Vektorfeldes v : R3 →R3, dann gilt I ∂K ⟨v, ˆn⟩dA = Φv = Z K div(v) dV. (2.165)",
                "page": 47
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Gauss-Integralsatz besagt die Gleichheit eines Flussintegrals mit einem Volumenin- tegral. Es gilt Perforation von v ≡Summe aller eingeschlossenen Quellen von v. (2.166) ii) Der Gauss-Integralsatz kann allgemein in nD formuliert werden. iii) Der Gauss-Integralsatz ist eine Verallgemeinerung der Newton-Leibniz-Formel in nD. iv) Der Gauss-Integralsatz lässt sich bezogen auf beide Seiten der Gleichung sinnvoll anwen- den. v) Der Gauss-Integralsatz etabliert die Interpretation der Divergenz als Quellendichte eines Vektorfeldes. vi) Gemäss Gauss-Integralsatz verschwindet offenbar die Perforation jedes quellenfreien Vek- torfeldes durch eine beliebige Oberfläche ∂V . Aus div(v) = 0 folgt Φv = I ∂K ⟨v, ˆn⟩dA = Z K div(v) dV = Z K 0 dV = 0. (2.167) Damit haben wir auch den Spezialfall aus Satz 2.11 bewiesen. I-49",
                "page": 47
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Strömungsdynamik: Aus der Inkompressibilität einer Flüssigkeit folgt die Quellenfreiheit des Geschwindigkeitsvektorfeldes v und somit das Verschwinden der Perforation von v durch eine beliebige Oberfläche ∂V . • Elektrodynamik: Die Maxwell-Gleichungen für die Divergenz des E-Feldes und B-Feldes lauten div(E) = 1 ε0 · ρ (2.168) div(B) = 0. (2.169) Für die Perforation des E-Feldes und B-Feldes durch eine beliebige Oberfläche ∂V folgt aus dem Gauss-Integralsatz ΦE = I ∂V ⟨E, ˆn⟩dA = Z V div(E) dV = Z V 1 ε0 · ρ dV = 1 ε0 Z V ρ dV = 1 ε0 · Qeg (2.170) ΦB = I ∂V ⟨B, ˆn⟩dA = Z V div(B) dV = Z V 0 dV = 0. (2.171) • Erhaltungssätze • Volumen-Berechnungen • Geometrische Analysis",
                "page": 48
              }
            ]
          },
          "2.6.2": {
            "title": "Stokes-Integralsatz",
            "page": 48,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.20",
                "details": "Stokes-Integralsatz in 3D Seien G ⊂R3 ein Gebiet mit Randkurve ∂G, welche das Einheitsnormalen-Vektorfeld ˆn rechts umläuft im Bereich eines Vektorfeldes v : R3 →R3, dann gilt I ∂G ⟨v, ˆe⟩ds = Υv = Z G ⟨rot(v), ˆn⟩dA. (2.172) I-50",
                "page": 48
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Stokes-Integralsatz besagt die Gleichheit eines Linienintegrals mit einem Flussinte- gral. Es gilt Zirkulation von v ≡Summe aller eingeschlossenen Wirbel von v. (2.173) ii) Der Stokes-Integralsatz kann allgemein in 2D und 3D formuliert werden. iii) Der Stokes-Integralsatz ist eine Verallgemeinerung der Newton-Leibniz-Formel in 2D bzw. 3D. iv) Der Stokes-Integralsatz lässt sich bezogen auf beide Seiten der Gleichung sinnvoll an- wenden. v) Der Stokes-Integralsatz etabliert die Interpretation der Rotation als Wirbeldichte eines Vektorfeldes. vi) Gemäss Stokes-Integralsatz verschwindet offenbar die Zirkulation jedes wirbelfreien Vek- torfeldes entlang einer beliebigen Randkurve ∂G. Aus rot(v) = 0 folgt Υv = I ∂G ⟨v, ˆe⟩ds = Z G ⟨rot(v), ˆn⟩dA = Z G ⟨0, ˆn⟩dA = Z G 0 dA = 0. (2.174)",
                "page": 49
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Elektrodynamik: Die Maxwell-Gleichungen für die Rotation des E-Feldes und B-Feldes lauten rot(E) = −˙B (2.175) rot(B) = ε0 · µ0 · ˙E + µ0 · J. (2.176) In einer statischen Situation, d.h. für ˙E = ˙B = 0 vereinfachen sich diese Gleichungen zu rot(E) = 0 (2.177) rot(B) = µ0 · J. (2.178) Für die Zirkulation des E-Feldes und B-Feldes entlang einer beliebigen Randkurve ∂G folgt aus dem Stokes-Integralsatz ΥE = I ∂G ⟨E, ˆe⟩ds = Z G ⟨rot(E), ˆn⟩dA = Z G ⟨0, ˆn⟩dA = Z G 0 dA = 0 (2.179) ΥB = I ∂G ⟨B, ˆe⟩ds = Z G ⟨rot(B), ˆn⟩dA = Z G ⟨µ0 · J, ˆn⟩dA = µ0 Z G ⟨J, ˆn⟩dA = µ0 · Ieg. (2.180) • Erhaltungssätze • Flächen-Berechnungen • Geometrische Analysis I-51",
                "page": 49
              }
            ]
          },
          "2.6.3": {
            "title": "Potential-Sätze",
            "page": 50,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.21",
                "details": "Skalarpotential in 3D Seien n ∈{2, 3} und v : Rn →Rn ein differentierbares, wirbelfreies Vektorfeld, dann gibt es ein Skalarfeld ϕ : Rn →R, so dass gilt v = ∇ϕ. (2.181)",
                "page": 50
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Jedes wirbelfreie Vektorfeld ist ein Gradientenfeld. ii) Das Skalarfeld ϕ heisst Skalarpotential oder Potential des Vektorfeldes v. iii) Das Skalarpotential ist eine Verallgemeinerung der Stammfunktion auf wirbelfreie Vektor- felder in 2D und 3D. iv) Für jedes wirbelfreie Vektorfeld v gibt es unendlich viele Möglichkeiten ein Skalarpotential zu wählen. Wir betrachten den folgenden Satz.",
                "page": 50
              },
              {
                "type": "Satz",
                "text": "Satz 2.22",
                "details": "Vektorpotential in 3D Sei v : R3 →R3 ein differentierbares, quellenfreies Vektorfeld, dann gibt es ein Vektorfeld A : R3 →R3, so dass gilt v = rot(A). (2.182)",
                "page": 50
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Jedes quellenfrei Vektorfeld ist ein Rotationsfeld. ii) Das Vektorfeld A heisst Vektorpotential des Vektorfeldes v. iii) Das Vektorpotential ist eine Verallgemeinerung der Stammfunktion auf quellenfreie Vek- torfelder in 3D. iv) Für jedes quellenfreie Vektorfeld v gibt es unendlich viele Möglichkeiten ein Vektorpoten- tial zu wählen.",
                "page": 50
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Elektrodynamik: Die Maxwell-Gleichungen beschreiben jeweils Divergenz und Rotation des E-Feldes und B-Feldes. Es gilt div(E) = 1 ε0 · ρ rot(E) = −˙B div(B) = 0 rot(B) = ε0 · µ0 · ˙E + µ0 · J. (2.183) In einer statischen Situation, d.h. für ˙E = ˙B = 0 vereinfachen sich diese Gleichungen zu div(E) = 1 ε0 · ρ rot(E) = 0 div(B) = 0 rot(B) = µ0 · J. (2.184) Weil also das E-Feld wirbelfrei und das B-Feld quellenfrei ist, gibt es entsprechend ein Ska- larpotential ϕ und ein Vektorpotential A, so dass E = −∇ϕ und B = rot(A). (2.185) I-52",
                "page": 50
              }
            ]
          },
          "2.6.4": {
            "title": "Zerlegungssatz",
            "page": 51,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.23",
                "details": "Zerlegungssatz für Vektorfelder in 3D Jedes differentierbare Vektorfeld v : R3 →R3 lässt sich zerlegen in eine Summe aus einem wirbelfreien Vektorfeld q : R3 →R3, einem quellenfreien Vektorfeld w : R3 →R3 und einem homogenen Vektorfeld h : R3 →R3 gemäss v = w + q + h. (2.186)",
                "page": 51
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Bei einer solchen Zerlegung ist w ein reines Wirbelfeld und q ein reines Quellenfeld. ii) Für jedes differentierbare Vektorfeld gibt es unendlich viele Möglichkeiten eine Zerlegung der Form (2.186) zu wählen. iii) Gemäss den Potential-Sätzen hat q ein Skalarpotential ϕ und w ein Vektorpotential A, so dass gilt q = ∇ϕ und w = rot(A). (2.187) Mit Hilfe dieser Potentiale lässt sich die Zerlegung (2.186) schreiben gemäss v = w + q + h = rot(A) + ∇ϕ + h. (2.188) I-53",
                "page": 51
              }
            ]
          }
        }
      },
      "2.7": {
        "title": "Funktionsdiskussion in mehreren Variablen",
        "page": 52,
        "subsections": {
          "2.7.1": {
            "title": "Erste Richtungsableitung",
            "page": 52,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.24",
                "details": "Steigung entlang eines Funktionsgraphen in 2D Seien f : R2 →R differentierbar, P0 = \u0000x0 ; y0 ; f(x0; y0) \u0001 ∈R3 und ˆe ∈R2 ein Einheitsvektor, dann hat ein Weg auf dem Funktionsgraph von f mit horizontaler Richtung ˆe am Punkt P0 die Steigung m = ⟨ˆe, ∇f(x0; y0)⟩. (2.189)",
                "page": 52
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wir betrachten Fuktionsgraphen den von f als parametrisierte Fläche mit Parametri-",
                "details": "sierung Q(x; y) :=   x y f(x; y)  . (2.190) Für die Koordinatenbasis-Vektorfelder erhalten wir e1 = Q,x =   1 0 f,x   und e2 = Q,y =   0 1 f,y  . (2.191) Daraus erhalten wir den Normalen-Vektor n = e1 × e2 =   1 0 f,x  ×   0 1 f,y  =   0 · f,y −f,x · 1 f,x · 0 −1 · f,y 1 · 1 −0 · 0  =   −f,x −f,y 1  . (2.192) I-54",
                "page": 52
              },
              {
                "type": "Definition",
                "text": "Definition 2.26",
                "details": "Richtungsableitung in nD Seien n ∈N+, f : Rn →R differentierbar und ˆe ∈Rn ein Einheitsvektor, dann ist die Rich- tungsableitung von f in Richtung ˆe die reelle Zahl ∇ˆef := ⟨ˆe, ∇f ⟩. (2.198) Wir betrachten die Situation in der x-y-Ebene gemäss folgende Skizze. I-55",
                "page": 53
              },
              {
                "type": "Satz",
                "text": "Satz 2.25",
                "details": "Eigenschaften des Gradienten in 2D Seien f : R2 →R differentierbar, ˆe ∈R2 ein Einheitsvektor und α = ∡(∇f; ˆe), dann gilt folgendes. (a) ∇ˆef ∈ \u0002 −|∇f |, +|∇f | \u0003 (b) α = 0 ⇔ˆe ∥+∇f ⇔∇ˆef = +|∇f | maximal (c) α = π ⇔ˆe ∥−∇f ⇔∇ˆef = −|∇f | minimal (d) α = π 2 ⇔ˆe ⊥∇f ⇔∇ˆef = 0 (e) ∇f = 0 ⇔Tangentialebene an den Graphen von f verläuft horizontal",
                "page": 54
              },
              {
                "type": "Beweis",
                "text": "Beweis: Für die Richtungsableitung von f in Richtung ˆe erhalten wir",
                "details": "∇ˆef = ⟨ˆe, ∇f ⟩= |ˆe| · |∇f | · cos(α) = 1 · |∇f | · cos(α) = cos(α) · |∇f |. (2.199) Daraus folgen unmittelbar alle Aussagen und wir haben den Satz bewiesen.",
                "page": 54
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Gradient ∇f zeigt an jedem Punkt der x-y-Ebene gerade in die Richtung, in welcher die Steigung des Graphen von f maximal ist. ii) Die Länge |∇f | des Gradienten ist an jedem Punkt der x-y-Ebene gerade die maximale Steigung des Graphen von f. iii) Der Gradient steht an jedem Punkt der x-y-Ebene senkrecht auf der Level-Linie von f durch diesen Punkt. iv) Dort wo der Gradient verschwindet verläuft die Tangentialebene an den Graphen von f horizontal. Entsprechend hat f dort einen Hoch-Punkt, Tief-Punkt oder Sattel-Punkt. v) Definition und Eigenschaften sowohl des Gradienten als auch der Richtungsableitung gel- ten ganz analog auch in nD. Zeichnet man den Gradienten und die Level-Linien von f in der x-y-Ebene ein, dann ergibt sich ein Bild wie im folgenden Beispiel. I-56",
                "page": 54
              }
            ]
          },
          "2.7.2": {
            "title": "Zweite Richtungsableitung",
            "page": 55,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.26",
                "details": "Hesse-Formel in nD Seien n ∈N+, f : Rn →R eine zweifach differentierbare Funktion mit Hesse-Matrix H := ∇2f und ˆv, ˆw ∈Rn zwei Einheitsvektoren, dann gilt ∇2 ˆwˆvf = ∇ˆw \u0000∇ˆvf \u0001 = ⟨ˆw, H · ˆv⟩. (2.200)",
                "page": 55
              },
              {
                "type": "Beweis",
                "text": "Beweis: Siehe Übungen.",
                "details": "",
                "page": 55
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für ˆw = ˆv folgt ∇2 ˆvˆvf = ⟨ˆv, H · ˆv⟩. (2.201) Dies ist eine quadratische Form in ˆv mit H als Matrix. ii) Wegen der Symmetrien von H und des Skalar-Produkts kommutieren die zweiten Rich- tungsableiten, d.h. es gilt ∇2 ˆvˆwf = ∇2 ˆwˆvf. (2.202) iii) Für die Standard-Einheitsvektoren ˆe1, . . . ,ˆen ∈Rn entlang der Koordinatenachsen gilt ∇2 ˆeµˆeνf = f,ν,µ = Hνµ. (2.203) iv) Die zweiten Richtungsableitungen verschwinden genau dann für alle Richtungen, wenn gilt H = 0.",
                "page": 55
              }
            ]
          },
          "2.7.3": {
            "title": "Lokale Extrema",
            "page": 55,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 2.27",
                "details": "Kritische Stelle Seien n ∈N+ und f : Rn →R differentierbar, dann heisst ein Punkt P ∈Rn kritische Stelle von f, wenn gilt ∇f(P) = 0. (2.204)",
                "page": 55
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Zur Bestimmung der kritischen Stellen von f muss das Gleichungssystem (2.204) gelöst werden. ii) An einer kritischen Stelle einer Funktion kann sich ein Tief-Punkt, ein Hoch-Punkt oder ein Sattel-Punkt befinden. iii) Für n = 2 verläuft die Tangentialebene an den Graphen von f an einer kritischen Stelle horizontal. I-57",
                "page": 55
              },
              {
                "type": "Satz",
                "text": "Satz 2.27",
                "details": "Lokale Extrema in nD Seien n ∈N+, f : Rn →R zweifach differentierbar, P ∈Rn eine kritische Stelle von f und H = ∇2f(P) mit Spektrum spec(H) = {λ1, . . . , λn} ⊂R, dann gilt folgendes. (a) Falls λ1, . . . , λn < 0, dann hat f bei P einen Hoch-Punkt. (b) Falls λ1, . . . , λn > 0, dann hat f bei P einen Tief-Punkt. (c) Falls λ1, . . . , λn ̸= 0 mit unterschiedlichen Vorzeichen, dann hat f bei P einen Sattel-Punkt. Wir betrachten den folgenden Satz.",
                "page": 56
              },
              {
                "type": "Satz",
                "text": "Satz 2.28",
                "details": "Lokale Extrema in 2D Seien f : R2 →R zweifach differentierbar, \u0000x0 ; y0 \u0001 ∈R2 eine kritische Stelle von f und H = ∇2f(x0; y0), dann gilt folgendes. (a) Falls det(H) > 0 und H11, H22 < 0, dann hat f bei \u0000x0 ; y0 \u0001 einen Hoch-Punkt. (b) Falls det(H) > 0 und H11, H22 > 0, dann hat f bei \u0000x0 ; y0 \u0001 einen Tief-Punkt. (c) Falls det(H) < 0, dann hat f bei \u0000x0 ; y0 \u0001 einen Sattel-Punkt.",
                "page": 56
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wir betrachten die Richtungsvektoren",
                "details": "ˆe(t) = 1 √ 1 + t2 · \u0014 ±1 t \u0015 für t ∈R. (2.205) Durch die Richtungen gemäss (2.205) in Kombination mit den Richtungen die aus (2.205) durch einen Tausch der Komponenten hervorgehen, können offensichtlich alle möglichen Richtungen in 2D überlappend beschrieben werden. Für die zweite Richtungsableitung von f in die Richtungen ˆe(t) erhalten wir ∇2 ˆeˆef = ⟨ˆe, H · ˆe⟩= ˆeT · H · ˆe = 1 √ 1 + t2 · \u0014 ±1 t \u0015T · \u0014 H11 H12 H21 H22 \u0015 · 1 √ 1 + t2 · \u0014 ±1 t \u0015 = 1 1 + t2 · \u0002 ±1 t \u0003 · \u0014 H11 H12 H21 H22 \u0015 · \u0014 ±1 t \u0015 = 1 1 + t2 · \u0002 ±1 t \u0003 · \u0014 H11 · (±1) + H12 · t H21 · (±1) + H22 · t \u0015 = 1 1 + t2 · \u0010 ±1 · \u0000H11 · (±1) + H12 · t \u0001 + t · \u0000H21 · (±1) + H22 · t \u0001\u0011 = 1 1 + t2 · \u0010 H11 ± H12 · t ± H21 · t + H22 · t2\u0011 = 1 1 + t2 · \u0010 H22 · t2 ± 2 · H12 · t + H11 \u0011 =: 1 1 + t2 · g(t) (2.206) mit der quadratischen Funktion g(t) = H22 · t2 ± 2 · H12 · t + H11. (2.207) Die Diskriminante von g ist D = \u0000±2 · H12 \u00012 −4 · H22 · H11 = 4 · H2 12 −4 · H11 · H22 = −4 · \u0000H11 · H22 −H21 · H12 \u0001 I-58",
                "page": 56
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Ob an einer kritischen Stelle ein Hoch-Punkt, Tief-Punkt oder Sattel-Punkt vorliegt, lässt sich also genau dann mit Hilfe von H entscheiden, wenn H regulär ist. Ist H singulär, dann lassen sich aus H keine Schlüsse über den Typ der kritischen Stelle ziehen. ii) In nD lässt sich anhand der Vorzeichen der Eigenwerte von H ablesen, ob ∇2 ˆeˆef für alle Richtungen ˆe das gleiche Vorzeichen hat. iii) In 2D lässt sich anhand des Vorzeichens von det(H) ablesen, ob ∇2 ˆeˆef für alle Richtungen ˆe das gleiche Vorzeichen hat, denn H ist symmetrisch und somit gilt det(H) = λ1 · λ2. (2.210) iv) In 2D müssen im Fall det(H) > 0 die Komponenten H11 und H22 das gleiche Vorzei- chen haben. Anhand dieses Vorzeichens kann dann zwischen Hoch-Punkt und Tief-Punkt unterschieden werden. Um die lokalen Extrema einer Funktion in 2D zu bestimmen, kann nach den folgenden Schritten vorgegangen werden. S1 Die kritische Stellen von f sind zu bestimmen als Lösungen des Gleichungssystems ∇f(x; y) = 0. (2.211) I-59",
                "page": 57
              }
            ]
          },
          "2.7.4": {
            "title": "Globale Extrema",
            "page": 58,
            "content": []
          },
          "2.7.5": {
            "title": "Extrema unter Nebenbedingungen in 2D",
            "page": 59,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 2.29",
                "details": "Extrema unter Nebenbedingungen in 2D Seien f, g : R2 →R zwei differentierbare Funktionen und \u0000x; y \u0001 ∈R2 ein Extremum von f unter der Nebenbedingung g(x; y) = 0. (2.217) Dann gibt es einen Lagrange-Multiplikator λ ∈R, so dass an der Stelle \u0000x; y \u0001 gilt ∇f = λ · ∇g. (2.218)",
                "page": 59
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wir betrachten die Level-Linie von g zum Level L = 0. Liegt ein Extrema von f",
                "details": "entlang dieser Level-Linie am Punkt \u0000x; y \u0001 und zeigt ˆe tangential zur Level-Linie, dann muss gelten 0 = ∇ˆef = ⟨ˆe, ∇f ⟩. (2.219) Bei \u0000x; y \u0001 steht der Gradient von f also senkrecht auf der Level-Linie von g und somit parallel oder antiparallel zum Gradienten von g. Es gibt daher einen Lagrange-Multiplikator λ ∈R, so dass (2.218) erfüllt ist. Damit haben wir den Satz bewiesen. Um die Extrema einer Funktion in 2D unter Nebenbedingungen zu bestimmen, kann nach den folgenden Schritten vorgegangen werden. S1 Es sind die Kandidaten als Lösungen des Gleichungssystems zu bestimmen gemäss ( ∇f = λ · ∇g g(x; y) = 0. (2.220) S2 Die Funktionswerte der Kandidaten sind in einer Ergebnistabelle zu vergleichen.",
                "page": 59
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Das Gleichungssystem ist äquivalent zu den Bedingungen für die kritischen Punkte in 3D der Lagrange-Erweiterung w(x; y; λ) = f(x; y) −λ · g(x; y). (2.221) ii) Das Verfahren lässt sich durch mehrere Lagrange-Multiplikatoren auf nD erweitern. I-61",
                "page": 59
              }
            ]
          }
        }
      }
    }
  },
  "3": {
    "title": "Integralrechnung",
    "page": 61,
    "sections": {
      "3.1": {
        "title": "Integrationsmethoden",
        "page": 61,
        "subsections": {
          "3.1.1": {
            "title": "Substitution",
            "page": 61,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 3.1",
                "details": "Integration durch Substitution Seien f : R →R eine integrierbare Funktion mit Stammfunktion F : R →R, u : R →R eine differentierbare Funktion und x0, xE ∈R mit x0 < xE, dann gilt folgendes. (a) Z f \u0000u(x) \u0001 · u′(x) dx = Z f(u) du = F \u0000u(x) \u0001 + c (b) Z xE x0 f \u0000u(x) \u0001 · u′(x) dx = Z u(xE) u(x0) f(u) du = F \u0000u(xE) \u0001 −F \u0000u(x0) \u0001",
                "page": 61
              },
              {
                "type": "Beweis",
                "text": "Beweis: Durch Anwenden der Summen-Regel und Ketten-Regel und weil F ′ = f erhalten wir",
                "details": "\u0010 F \u0000u(x) \u0001 + c \u0011′ = F ′\u0000u(x) \u0001 · u′(x) + 0 = f \u0000u(x) \u0001 · u′(x). (3.1) Aus der Newton-Leibniz-Formel folgt sofort (a) und durch Einsetzen der Integrationsgren- zen erhalten wir (b). Damit haben wir den Satz bewiesen.",
                "page": 61
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten das unbestimmte Integral F(x) = Z x · cos \u0000x2\u0001 dx. (3.2) Als Substitution wählen wir u(x) := x2 ⇒u′(x) = 2x. (3.3) Wir zeigen mehrere Varianten, um das unbestimmte Integral zu berechnen. I-63",
                "page": 61
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Idee hinter der Integration durch Substitution ist die Umkehrung der Ketten-Regel aus der Differentialrechnung. ii) Durch Anwenden der Substitution kann eine schwierige Integration auf eine einfachere Integration zurückgeführt werden. iii) Der Begriff Substitution bedeutet “Ersetzung”. iv) Bei der Substitution wird die unabhängige Variable gewechselt gemäss x 7→u oder u 7→x. (3.15) v) Das Kalkulieren mit den Differentialsymbolen ist analog zu den Berechnungsschritten in einem Archimedes-Cauchy-Riemann-Approximationsprozess gemäss δI ≈f \u0000u(x) \u0001 · u′(x) · δx ≈f \u0000u(x) \u0001 · δu δx · δx = f(u) · δu. (3.16) vi) Eine häufige Fehlerquelle bei der Berechnung von bestimmten Integralen durch Substitu- tion ist das Anpassen der Integrationsgrenzen. vii) In den meisten Fällen aus der Praxis (ca. 90%) ist die Substitution u eine lineare Funktion der Form u(x) = m · x + q ⇒du dx = u′(x) = m ⇔dx = 1 m du. (3.17) Erkennt man dies vorweg, dann kann das einfachere Verfahren der linearen Modifikation durchgeführt werden. Die Methode der Substitution hat nicht nur praktische Bedeutung bei der Berechnung von kon- kreten Integralen sondern auch bei der Herleitung von Integralformeln. Ein Standard-Beispiel ist die Formel für die kinetische Energie aus der Physik. Dazu betrachten wir einen Körper der Masse m, welcher von der Anfangsgeschwindigkeit v0 auf die Endgeschwindigkeit vE beschleunigt wird. Die Situation ist in der folgenden Skizze dargestellt. m m v0 vE Wir betrachten dazu den folgenden Satz. I-65",
                "page": 63
              },
              {
                "type": "Satz",
                "text": "Satz 3.2",
                "details": "Beschleunigungsarbeit Um einen Körper der Masse m von der Anfangsgeschwindigkeit v0 auf die Endgeschwindigkeit vE zu beschleunigen, muss am Körper eine Beschleunigungsarbeit geleistet werden von ∆W = m 2 · v2 E −m 2 · v2 0. (3.18)",
                "page": 64
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wir zeigen mehrere Varianten um die Beschleunigungsarbeit zu berechnen.",
                "details": "Variante 1: Mit Hilfe des Arbeitsintegrals und mehrfacher Substitution erhalten wir ∆W = Z sE s0 F(s) ds = Z tE t0 F \u0000s(t) \u0001 · ˙s(t) dt = Z tE t0 m · a(t) · v(t) dt = m Z tE t0 v(t) · ˙v(t) dt = m Z vE v0 v dv = m · 1 2 · h v2 i vE v0 = m 2 · \u0010 v2 E −v2 0 \u0011 = m 2 · v2 E −m 2 · v2 0. (3.19) Variante 2: Wir verwenden einen Archimedes-Cauchy-Riemann-Approximationsprozess. Dabei gehen wir nach folgenden Schritten vor. S1 Lokal: Wir betrachten ein kleines Wegstück δs. Die Beschleunigungsarbeit entlang δs ist δW ≈F(s) · δs ≈m · a(t) · δs δt · δt ≈m · δv δt · v · δt = m · v · δv. (3.20) S2 Global: Durch Integration über v erhalten wir die Beschleunigungsarbeit ∆W = m Z vE v0 v dv = m · 1 2 · h v2 i vE v0 = m 2 · \u0010 v2 E −v2 0 \u0011 = m 2 · v2 E −m 2 · v2 0. (3.21) Damit haben wir den Satz bewiesen.",
                "page": 64
              }
            ]
          },
          "3.1.2": {
            "title": "Partielle Integration",
            "page": 64,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 3.3",
                "details": "Partielle Integration Seien g, h : R →R differentierbare und integrierbare Funktionen und x0, xE ∈R mit x0 < xE, dann gilt folgendes. (a) Z ↓ g(x) · ↑ h′(x) dx = g(x) · h(x) − Z g′(x) · h(x) dx (b) Z xE x0 ↓ g(x) · ↑ h′(x) dx = h g(x) · h(x) i xE x0 − Z xE x0 g′(x) · h(x) dx",
                "page": 64
              },
              {
                "type": "Beweis",
                "text": "Beweis: Übung.",
                "details": "I-66",
                "page": 64
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Durch partielle Integration erhalten wir F(x) = Z ↓ x · ↑ ex dx = x ex − Z 1 · ex dx = x ex −ex + c = (x −1) ex + c. (3.22) • Durch partielle Integration und mit Hilfe des Pythagoras-Satzes für trigonometrische Funktionen finden wir die Gleichung F(x) = Z sin2(x) dx = Z ↓ sin(x) · ↑ sin(x) dx = sin(x) · \u0000−cos(x) \u0001 − Z cos(x) · \u0000−cos(x) \u0001 dx = −sin(x) cos(x) + Z cos2(x) dx = −sin(x) cos(x) + Z \u00001 −sin2(x) \u0001 dx = −sin(x) cos(x) + Z 1 dx − Z sin2(x) dx = −sin(x) cos(x) + x + b −F(x). (3.23) Es gilt also F(x) = −sin(x) cos(x) + x + b −F(x) + F(x) (3.24) 2 · F(x) = −sin(x) cos(x) + x + b : 2. (3.25) Daraus erhalten wir F(x) = −sin(x) cos(x) + x + b 2 = x −sin(x) cos(x) 2 + c. (3.26) • Durch partielle Integration erhalten wir F(x) = Z ln(x) dx = Z ↓ ln(x) · ↑ 1 dx = ln(x) · x − Z ln′(x) · x dx = x · ln(x) − Z 1 x · x dx = x · ln(x) − Z 1 dx = x · ln(x) −x + c = x · \u0000ln(x) −1 \u0001 + c. (3.27)",
                "page": 65
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Idee hinter der partiellen Integration ist die Umkehrung der Produkt-Regel aus der Differentialrechnung. ii) Durch Anwenden der partiellen Integration kann eine schwierige Integration auf eine ein- fachere Integration zurückgeführt werden. iii) Der Begriff partielle Integration bedeutet “teilweise Integration”. iv) Eine häufige Fehlerquelle bei der Anwendung der partiellen Integration ist das negative Vorzeichen vor dem Integral auf der rechten Seite. I-67",
                "page": 65
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen:",
                "details": "• Berechnung von Integralen • Taylor-Entwicklungen • Differentialgleichungen • Variationsrechnung • Fourier- und Laplace-Transformation • FEM-Simulationen I-68",
                "page": 66
              }
            ]
          }
        }
      },
      "3.2": {
        "title": "Uneigentliche Integrale",
        "page": 67,
        "subsections": {
          "3.2.1": {
            "title": "Integration über unendliche Intervalle",
            "page": 67,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 3.1",
                "details": "Uneigentliches Integral mit einer unendlichen Grenze. Seien x0, xE ∈R und f : R →R eine integrierbare Funktion. Die uneigentlichen Integrale von f Richtung ±∞sind (a) Z ∞ x0 f(x) dx := lim s→∞ Z s x0 f(x) dx, (b) Z xE −∞ f(x) dx := lim s→∞ Z xE −s f(x) dx, falls die betreffenden Grenzwerte jeweils konvergieren.",
                "page": 67
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten das uneigentliche Integral I = Z ∞ 2 1 x2 dx = lim s→∞ Z s 2 1 x2 dx = lim s→∞ \u0014 −1 x \u0015 s 2 = lim s→∞ \u0012 −1 s + 1 2 \u0013 = 0 + 1 2 = 1 2 . (3.30) • Wir betrachten das uneigentliche Integral I = Z ∞ 2 1 x dx = lim s→∞ Z s 2 1 x dx = lim s→∞ln \u0010s 2 \u0011 = ∞. (3.31) Dieses uneigentliche Integral ist divergent und existiert daher nicht. • Wir betrachten das uneigentliche Integral I = Z ∞ ln(2) e−x dx = lim s→∞ Z s ln(2) e−x dx = lim s→∞ h −e−x i s ln(2) = lim s→∞ \u0010 −e−s + e−ln(2)\u0011 = 0 + e−ln(2) = e−ln(2) = 1 eln(2) = 1 2 . (3.32) I-69",
                "page": 67
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Uneigentliche Integrale sind als Grenzwerte definiert und existieren nur, wenn die betref- fenden Grenzwerte konvergieren. ii) Bei der Berechnung eines uneigentlichen Integrals ist die Reihenfolge der Rechenschritte sehr wichtig. Zuerst muss eine Stammfunktion F von f gefunden und an den Grenzen x0 und s bzw. −s und xE ausgewertet werden. Erst dann wird der Grenzwert s →∞ betrachtet. Dieses Vorgehen führt zu Rechnungen der Form I = Z ∞ x0 f(x) dx = lim s→∞ Z s x0 f(x) dx = lim s→∞ h F(x) i s x0 = lim s→∞ \u0010 F(s) −F(x0) \u0011 = . . . (3.33) iii) Das uneigentliche Integral kann nur existieren, wenn sich der Integrand der x-Achse asym- ptotisch annähert, d.h. es muss gelten lim x→∞f(x) = 0 bzw. lim x→−∞f(x) = 0. (3.34) iv) Allein die Tatsache, dass sich der Integrand der x-Achse asymptotisch annähert reicht für die Existenz des uneigentlichen Integrals jedoch nicht aus! Es kommt vielmehr darauf an, wie “schnell” diese asymptotische Annäherung stattfindet. v) Beispiel-Codes zur Berechnung von uneigentlichen Integralen mit gängiger Software. Mathematica/WolframAlpha Integrate[1/x^2,{x,2,Infinity}] Python/Sympy import sympy as sp; sp.integrate(1/x**2,(x,2,sp.oo)); Wir betrachten den folgenden Satz.",
                "page": 68
              },
              {
                "type": "Satz",
                "text": "Satz 3.4",
                "details": "Uneigentliches Integral von reziproken Potenzen Seien p, x0 ∈R mit x0 > 0, dann gilt Z ∞ x0 1 xp dx =      1 p −1 · 1 xp−1 0 p > 1 divergent p ≤1. (3.35)",
                "page": 68
              },
              {
                "type": "Beweis",
                "text": "Beweis: Übung.",
                "details": "I-70",
                "page": 68
              },
              {
                "type": "Definition",
                "text": "Definition 3.2",
                "details": "Uneigentliches Integral mit zwei unendlichen Grenzen. Seien f : R →R eine integrierbare Funktion und x0 ∈R. Das uneigentliche Integral von f über die reellen Zahlen ist Z ∞ −∞ f(x) dx := lim r→∞ Z x0 −r f(x) dx + lim s→∞ Z s x0 f(x) dx, (3.36) falls beide Grenzwerte konvergieren.",
                "page": 69
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Das uneigentliche Integral wird als Summe von zwei Grenzwerten berechnet und existiert somit nur dann, wenn beide einzeln konvergieren. ii) Für die Aufteilung kann ein beliebiges x0 ∈R gewählt werden. iii) Falls das uneigentliche Integral existiert, dann konvergiert auch der zweiseitige Grenzwert und es gilt I = Z ∞ −∞ f(x) dx = lim s→∞ Z s −s f(x) dx. (3.37) iv) Aus der Konvergenz des zweiseitigen Grenzwertes folgt jedoch nicht die Existenz des unei- gentlichen Integrals! In solchen Fällen führt das Verwenden des zweiseitigen Grenzwertes zu Fehlschlüssen und falschen Ergebnissen, wie die folgenden Beispiele zeigen. I = Z ∞ −∞ x dx = lim s→∞ Z s −s x dx = lim s→∞ 1 2 · h x2 i s −s = lim s→∞ 1 2 · \u0010 s2 −(−s)2\u0011 = 1 2 · lim s→∞0 = 0 konvergent! (3.38) I = Z ∞ −∞ x dx = lim s→∞ Z s+1 −s x dx = lim s→∞ 1 2 · h x2 i s+1 −s = lim s→∞ 1 2 · \u0010 (s + 1)2 −(−s)2\u0011 = 1 2 · lim s→∞ \u0000s2 + 2s + 1 −s2\u0001 = 1 2 · lim s→∞(2s + 1) = ∞ divergent! (3.39) I-71",
                "page": 69
              }
            ]
          },
          "3.2.2": {
            "title": "Integration über Polstellen",
            "page": 70,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 3.3",
                "details": "Uneigentliches Integral über eine Polstelle. Seien x0, xp, xE ∈R mit x0 ≤xp ≤xE und f : R \\ {xp} →R eine integrierbare Funktion. Das uneigentliche Integral von f über die Polstelle xp ist Z xE x0 f(x) dx := lim r↗xp Z r x0 f(x) dx + lim s↘xp Z xE s f(x) dx, (3.40) falls beide Grenzwerte konvergieren.",
                "page": 70
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Das uneigentliche Integral wird als Summe von zwei Grenzwerten berechnet und existiert somit nur dann, wenn beide einzeln konvergieren. ii) Falls xp ∈{x0, xE}, dann fällt einer der beiden Grenzwerte weg. Es gilt xp = x0 ⇒ Z xE x0 f(x) dx = Z xE xp f(x) dx = lim s↘xp Z xE s f(x) dx (3.41) xp = xE ⇒ Z xE x0 f(x) dx = Z xp x0 f(x) dx = lim r↗xp Z r x0 f(x) dx. (3.42) iii) Befinden sich mehr als eine Polstelle im Intervall [x0, xE], dann muss das Integral in Teilabschnitte unterteilt und weitere Grenzwerte eingeführt werden. iv) In der Praxis ist aus Integrand und Integrationsgrenzen nicht immer auf den ersten Blick ersichtlich, ob es sich um ein uneigentliches Integral mit Polstellen handelt, wie z.B. bei I = Z 3 0 2x −4 1 −e 2−x 3 dx (3.43) mit einem Pol bei x = 2. I-72",
                "page": 70
              }
            ]
          }
        }
      }
    }
  },
  "4": {
    "title": "Taylor-Entwicklungen",
    "page": 71,
    "sections": {
      "4.1": {
        "title": "Maclaurin-Entwicklungen",
        "page": 71,
        "subsections": {
          "4.1.1": {
            "title": "Maclaurin-Formel",
            "page": 71,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 4.1",
                "details": "Maclaurin-Entwicklung Seien n ∈N, x ∈R und f : R →R unendlich oft differentierbar. Dann gilt f(x) = Tn(x) + Rn(x), (4.1) mit dem Maclaurin-Polynom Tn(x) und Restglied Rn(x) gemäss Tn(x) = n X k=0 f (k)(0) k! · xk = f(0) + f ′(0) · x + f ′′(0) 2! · x2 + . . . + f (n)(0) n! · xn Rn(x) = (−1)n n! Z x 0 f (n+1)(s) · (s −x)n ds. (4.2)",
                "page": 71
              },
              {
                "type": "Beweis",
                "text": "Beweis: Zunächst bemerken wir, dass gilt",
                "details": "f(x) −f(0) = h f(s) i x 0 = Z x 0 f ′(s) ds + f(0). (4.3) Daraus und durch n-fache partielle Integration folgt f(x) = f(0) + Z x 0 f ′(s) ds = f(0) + Z x 0 ↓ f ′(s) · ↑ 1 ds = f(0) + h f ′(s) · (s −x) i x 0 − Z x 0 ↓ f ′′(s) · ↑ (s −x) ds = f(0) + f ′(0) · x − \u0014 f ′′(s) · (s −x)2 2 \u0015 x 0 + Z x 0 ↓ f ′′′(s) · ↑ (s −x)2 2 ds = f(0) + f ′(0) · x + f ′′(0) 2 · x2 + \u0014 f ′′′(s) · (s −x)3 2 · 3 \u0015 x 0 − Z x 0 ↓ f (4)(s) · ↑ (s −x)3 2 · 3 ds I-73",
                "page": 71
              },
              {
                "type": "Definition",
                "text": "Definition 4.1",
                "details": "Analytische Funktion Seien I ⊆R ein Intervall mit 0 ∈I und f : I →R eine unendlich oft differentierbare Funktion. Die Funktion f heisst analytisch auf I, falls für alle x ∈I gilt lim n→∞Rn(x) = 0. (4.5)",
                "page": 72
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Das Maclaurin-Polynom Tn(x) ist ein Polynom vom Grad n. ii) Um das Maclaurin-Polynom Tn(x) aufzustellen, müssen die Funktionswerte von f und ihren Ableitungen nur an der Stelle x = 0 bekannt sein. iii) Eine analytische Funktion lässt sich durch ihre Maclaurin-Reihe vollständig darstellen, d.h. für alle x ∈I gilt f(x) = lim n→∞Tn(x) = ∞ X k=0 f (k)(0) k! · xk. (4.6) iv) In jedem Fall, d.h. auch für nicht analytische Funktionen kann das Maclaurin-Polynom in der Nähe von x = 0 als Näherung für f verwendet werden, d.h. für x nahe genug bei 0 und n gross genug gilt zumindest f(x) = Tn(x) + Rn(x) ≈Tn(x). (4.7) v) Hat f eine Parität, dann hat das Maclaurin-Polynom die gleiche Parität. In jedem Fall gilt f hat positive Parität ⇔Tn(x) enthält nur gerade Potenzen von x, (4.8) f hat negative Parität ⇔Tn(x) enthält nur ungerade Potenzen von x. (4.9) vi) Ist f selbst ein Polynom vom Grad p ∈N, dann ist f auf ganz R analytisch und es gilt Tn(x) = f(x) für alle n ≥p. (4.10) vii) Beispiel-Codes zur Berechnung von Maclaurin-Entwicklungen mit gängiger Software. Mathematica/WolframAlpha Series[Exp[x],{x,0,n}] Python/Sympy import sympy as sp; sp.series(sp.exp(x),x,0,n+1); I-74",
                "page": 72
              }
            ]
          },
          "4.1.2": {
            "title": "Maclaurin-Reihen der Elementarfunktionen",
            "page": 73,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 4.2",
                "details": "Maclaurin-Reihen der Elementarfunktionen Die folgenden Elementarfunktionen sind auf ganz R analytisch und für alle x ∈R gelten die folgenden Darstellungen durch Maclaurin-Reihen. exp(x) = ∞ X k=0 xk k! = 1 + x + x2 2! + x3 3! + x4 4! + x5 5! + . . . sin(x) = ∞ X k=0 (−1)kx2k+1 (2k + 1)! = x −x3 3! + x5 5! −x7 7! + x9 9! −. . . cos(x) = ∞ X k=0 (−1)kx2k (2k)! = 1 −x2 2! + x4 4! −x6 6! + x8 8! −. . . sinh(x) = ∞ X k=0 x2k+1 (2k + 1)! = x + x3 3! + x5 5! + x7 7! + x9 9! + . . . cosh(x) = ∞ X k=0 x2k (2k)! = 1 + x2 2! + x4 4! + x6 6! + x8 8! + . . . . (4.11)",
                "page": 73
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wir berechnen die Ableitungen von f(x) := exp(x) = ex sowie deren Werte an der",
                "details": "Stelle x0 = 0 und stellen die Resultate in der folgenden Tabelle zusammen. k 0 1 2 3 4 5 6 . . . f (k)(x) exp(x) exp(x) exp(x) exp(x) exp(x) exp(x) exp(x) . . . f (k)(0) 1 1 1 1 1 1 1 . . . (4.12) Durch Einsetzen in die Formel der Maclaurin-Entwicklung für ein n ∈N und ein x ∈R erhalten wir f(x) = f(0) + f (1)(0) 1! · x + f (2)(0) 2! · x2 + f (3)(0) 3! · x3 + . . . + f (n)(0) n! · xn + Rn(x) = 1 + 1 1! · x + 1 2! · x2 + 1 3! · x3 + 1 4! · x4 + 1 5! · x5 + 1 6! · x6 + 1 7! · x7 + . . . + Rn(x) = n X k=0 xk k! + Rn(x). (4.13) Es sei p := sgn(x), dann finden wir für das Restglied die Abschätzung Rn(x) = (−1)n n! Z x 0 f (n+1)(s) · (s −x)n ds = (−1)n n! Z x 0 es · (s −x)n ds = 1 n! · Z x 0 es · (s −x)n ds ≤p n! Z x 0 es · (s −x)n\f\f ds = p n! Z x 0 es\f\f · (s −x)n\f\f ds I-75",
                "page": 73
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Es ist heute allgemein üblich, diese Elementarfunktionen durch ihre Maclaurin-Reihen zu definieren. ii) Die Maclaurin-Entwicklungen dieser Elementarfunktionen sind in modernen Taschen- rechnern, PCs und auch Grossrechnern hardwareseitig implementiert. iii) Die Maclaurin-Reihe der natürlichen Exponentialfunktion wird Exponentialreihe ge- nannt. Durch Einsetzen von x = 1 erhält man für die Euler-Zahl die bekannte Reihen- darstellung e = exp(1) = ∞ X k=0 1 k! = 1 + 1 + 1 2! + 1 3! + 1 4! + 1 5! + . . . . (4.16) iv) Die Maclaurin-Entwicklungen dürfen Termweise abgeleitet werden, wordurch die be- kannten Ableitungsregeln offensichtlich werden. v) Die Maclaurin-Entwicklungen zeigen deutlich die Verwandtschaft zwischen trigonome- trischen und hyperbolischen Funktionen.",
                "page": 74
              }
            ]
          },
          "4.1.3": {
            "title": "Anwendungen",
            "page": 74,
            "content": []
          }
        }
      },
      "4.2": {
        "title": "Taylor-Entwicklungen allgemein",
        "page": 75,
        "subsections": {
          "4.2.1": {
            "title": "Taylor-Formel",
            "page": 75,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 4.3",
                "details": "Taylor-Entwicklung Seien n ∈N, x, x0 ∈R und f : R →R unendlich oft differentierbar. Dann gilt f(x) = Tn(x) + Rn(x), (4.17) mit dem Taylor-Polynom Tn(x) und Restglied Rn(x) gemäss Tn(x) = n X k=0 f (k)(x0) k! · (x −x0)k = f(x0) + f ′(x0) · (x −x0) + f ′′(x0) 2! · (x −x0)2 + . . . + f (n)(x0) n! · (x −x0)n Rn(x) = (−1)n n! Z x x0 f (n+1)(s) · (s −x)n ds. (4.18)",
                "page": 75
              },
              {
                "type": "Beweis",
                "text": "Beweis: Analog zum Beweis der Maclaurin-Entwicklung.",
                "details": "Besonders interessant ist die Situation, wenn das Restglied für grosse n immer kleiner wird. Dazu betrachten wir die folgende Definition.",
                "page": 75
              },
              {
                "type": "Definition",
                "text": "Definition 4.2",
                "details": "Analytische Funktion Seien I ⊆R ein Intervall mit x0 ∈I und f : I →R eine unendlich oft differentierbare Funktion. Die Funktion f heisst analytisch auf I, falls für alle x ∈I gilt lim n→∞Rn(x) = 0. (4.19)",
                "page": 75
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Taylor-Entwicklung für x0 = 0 ist gerade die Maclaurin-Entwicklung. ii) Das Taylor-Polynom Tn(x) ist ein Polynom vom Grad n. iii) Um das Taylor-Polynom Tn(x) aufzustellen, müssen die Funktionswerte von f und ihren Ableitungen nur an der Stelle x0 bekannt sein. iv) Eine analytische Funktion lässt sich durch ihre Taylor-Reihe vollständig darstellen, d.h. für alle x ∈I gilt f(x) = lim n→∞Tn(x) = ∞ X k=0 f (k)(x0) k! · (x −x0)k. (4.20) v) In jedem Fall, d.h. auch für nicht analytische Funktionen kann das Taylor-Polynom in der Nähe von x = x0 als Näherung für f verwendet werden, d.h. für x nahe genug bei x0 und n gross genug gilt zumindest f(x) = Tn(x) + Rn(x) ≈Tn(x). (4.21) I-77",
                "page": 75
              }
            ]
          },
          "4.2.2": {
            "title": "Anwendung lokale Extrema",
            "page": 76,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 4.4",
                "details": "Lokale Extrema - erweiterte Kriterien Seien f : R →R eine genügend of differentierbare, reelle Funktion, xk ∈R und m ∈N+ \\ {1}, so dass 0 = f ′(xk) = f ′′(xk) = . . . = f (m−1)(xk) (4.24) 0 ̸= f (m)(xk). (4.25) Dann gilt folgendes. (a) Falls m gerade und f (m)(xk) < 0, dann hat f bei xk einen Hoch-Punkt. (b) Falls m gerade und f (m)(xk) > 0, dann hat f bei xk einen Tief-Punkt. (c) Falls m ungerade, dann hat f bei xk einen Sattel-Punkt.",
                "page": 76
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wir betrachten die Taylor-Entwicklung von f der Ordnung m an der Stelle xk. Für",
                "details": "alle x ∈R nahe genug bei xk gilt f(x) = Tm(x) + Rm(x) ≈Tm(x) = f(xk) + f (m)(xk) m! · (x −xk)m. (4.26) Wir betrachten die Fälle m gerade und m ungerade getrennt. Fall 1: m gerade. In diesem Fall hat Tm und somit auch f bei xk ein lokales Extremum. Aus dem Vorzeichen des Faktors vor der Potenz (x −xk)m lässt sich der Typ des lokalen Extremums ablesen. Es gilt f (m)(xk) < 0 ⇒Tm und somit auch f hat bei xk einen Hoch-Punkt, (4.27) f (m)(xk) > 0 ⇒Tm und somit auch f hat bei xk einen Tief-Punkt. (4.28) Fall 2: m ungerade. In diesem Fall hat Tm und somit auch f bei xk einen Sattel-Punkt. Damit haben wir den Satz bewiesen. I-78",
                "page": 76
              }
            ]
          }
        }
      }
    }
  },
  "5": {
    "title": "Komplexe Zahlen",
    "page": 79,
    "sections": {
      "5.1": {
        "title": "Grundlagen",
        "page": 79,
        "subsections": {
          "5.1.1": {
            "title": "Einleitung",
            "page": 79,
            "content": []
          },
          "5.1.2": {
            "title": "Konstruktion",
            "page": 79,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 5.1",
                "details": "Komplexe Zahlen Die komplexen Zahlen C sind die kleinste Menge, welche die folgenden Eigenschaften erfüllt. A1 R ⊆C. A2 (C; +; ·) bildet einen Zahlenkörper. A3 Es gibt ein i ∈C mit i2 = −1.",
                "page": 79
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Zahl i heisst imaginäre Einheit. ii) Weil in der Elektrotechnik i schon die elektrische Stromstärke bezeichnet, wird in der Literatur oft auch ein j verwendet. iii) Alle Elemente von C lassen sich durch reelle Zahlen und i beschreiben. iv) Man kann zeigen, dass C der grösstmögliche Zahlenkörper ist. v) Man kann zeigen, dass C algebraisch abgeschlossen ist und somit kein Bedarf für eine noch grössere Zahlenmenge besteht. II-3",
                "page": 79
              }
            ]
          },
          "5.1.3": {
            "title": "Zahlenumfang",
            "page": 80,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 5.1",
                "details": "Arithmetische Form Für jedes z ∈C gibt es eindeutige x, y ∈R, so dass gilt z = x + y · i. (5.2)",
                "page": 80
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Jede komplexe Zahl lässt sich darstellen durch 2 reelle Zahlen. Somit muss C eine ähnliche Struktur haben wie R2. ii) Für y = 0 erhält man gerade alle reellen Zahlen. iii) Die reellen Vielfachen von i sind die gesuchten neuen Zahlen, deren Quadrate einen nega- tiven reellen Wert haben. Beispiele: z = 2 · i ⇒z2 = (2 · i)2 = 22 · i2 = 4 · (−1) = −4 (5.3) z = √ 3 · i ⇒z2 = \u0010√ 3 · i \u00112 = 3 · (−1) = −3 (5.4) z = y · i ⇒z2 = (y · i)2 = y2 · (−1) = −y2. (5.5) Wir betrachten folgende Definition.",
                "page": 80
              },
              {
                "type": "Definition",
                "text": "Definition 5.2",
                "details": "Weitere Bezeichnungen Seien z ∈C und x, y ∈R mit z = x + y · i. (5.6) Es werden die folgenden Bezeichnungen verwendet. (a) Realteil von z Re(z) := x. (b) Imaginärteil von z Im(z) := y. (c) Betrag von z |z| := p x2 + y2 . (d) Komplex-Konjugierte von z z∗:= x −y · i. II-4",
                "page": 80
              }
            ]
          },
          "5.1.4": {
            "title": "Grundoperationen",
            "page": 81,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 5.2",
                "details": "Betrag & Konjugation Sei z ∈C, dann gilt z · z∗= |z|2. (5.12)",
                "page": 81
              },
              {
                "type": "Beweis",
                "text": "Beweis: Es gibt x, y ∈R, so dass gilt",
                "details": "z = x + y · i und z∗= x −y · i. (5.13) Daraus erhalten wir z · z∗= (x + y · i) · (x −y · i) = x2 + y · i · x −x · y · i −y2 · i2 = x2 + y2 = |z|2. (5.14) Damit haben wir den Satz bewiesen. II-5",
                "page": 81
              }
            ]
          }
        }
      },
      "5.2": {
        "title": "Gauss-Ebene",
        "page": 82,
        "subsections": {
          "5.2.1": {
            "title": "Elementare Entsprechungen",
            "page": 82,
            "content": [
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Re-Achse entspricht den reellen Zahlen. ii) Die Gauss-Ebene entspricht den komplexen Zahlen gemäss x + y · i ←→ \u0014 x y \u0015 . (5.15) iii) Es gibt die folgenden weiteren Entsprechungen zwischen C und R2: Addition in C Addition in R2 Betrag in C Betrag in R2 Konjugation in C Spiegelung an Re-Achse in R2 (5.16)",
                "page": 82
              }
            ]
          },
          "5.2.2": {
            "title": "Trigonometrische Form",
            "page": 82,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 5.3",
                "details": "Argument Sei z ∈C \\ {0}. Das Argument von arg(z) ist der Winkel in der Gauss-Ebene zwischen der x-Achse und der Verbindungslinie vom Ursprung zu z nach folgenden Varianten. (a) Basler-Variante: φ ∈[0, 2π[ . (b) Zürcher-Variante: φ ∈]−π, π]. II-6",
                "page": 82
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für z = 0 exisitiert in beiden Varianten kein eindeutiges Argument. Meistens wählt man arg(0) = 0. ii) Für fast alle Anwendungen kann sowohl die Basler-Variante als auch die Zürcher-Variante verwendet werden. iii) Die Formeln zur Berechnung von arg(z) aus Real- und Imaginärteil sind bei der Zürcher- Variante etwas einfacher. iv) Beispiel-Codes zur Berechnung des Argumentes mit gängiger Software. MATLAB/Octave phi=angle(z) Mathematica/WolframAlpha phi=Arg[z] Python/Numpy import numpy as np; phi=np.angle(z) Python/Sympy import sympy as sp; phi=sp.arg(z) Wir betrachten den folgenden Satz.",
                "page": 83
              },
              {
                "type": "Satz",
                "text": "Satz 5.3",
                "details": "Trigonometrische Form Seien x, y ∈R, r ∈R+ und φ ∈[0, 2π[ oder φ ∈]−π, π] sowie cis(φ) := cos(φ) + i · sin(φ), (5.17) dann gibt es ein eindeutiges z ∈C \\ {0} mit z = x + y · i = r · cis(φ). (5.18) Ferner gelten die folgenden Umrechnungsformeln. (a) x = r · cos(φ) ∧y = r · sin(φ) (b) r = |z| = p x2 + y2 ∧φ = arg(z)",
                "page": 83
              },
              {
                "type": "Beweis",
                "text": "Beweis: Die Aussage folgt sofort durch Anwenden der Trigonometrie in der Gauss-Ebene.",
                "details": "",
                "page": 83
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Jede komplexe Zahl z ∈C lässt sich auf zwei Arten darstellen, nämlich z = x + y · i | {z } arithmetische Form = r · cis(φ) | {z } trigonometrische Form . (5.19) ii) Man bezeichnet die Schreibweise z = r · cis(φ) nur dann als trigonometrische Form, wenn gilt r = |z| ≥0. Der Winkel φ ∈R darf jedoch beliebig gewählt werden, d.h. φ muss nicht unbedingt das Argument gemäss einer der beiden Varianten sein. II-7",
                "page": 83
              }
            ]
          }
        }
      },
      "5.3": {
        "title": "Quadratische Gleichungen",
        "page": 84,
        "subsections": {},
        "content": [
          {
            "type": "Bemerkungen",
            "text": "Bemerkungen:",
            "details": "i) Jede quadratische Gleichung mit reellen Koeffizienten hat demnach in C mindestens 1 Lösung und höchstens 2 Lösungen. ii) Im Fall D < 0 gilt Re(z1) = Re(z2) = xs = −b 2 · a (5.25) Im(z1) = −Im(z2). (5.26) Daraus folgt, dass die beiden Lösungen zueinander komplex konjugiert sind, d.h. z2 = z∗ 1. (5.27) iii) Quadratische Gleichungen mit nichtreellen Koeffizienten haben so gut wie keine Anwen- dungen in der Praxis. II-8",
            "page": 84
          }
        ]
      },
      "5.4": {
        "title": "Potenzen",
        "page": 85,
        "subsections": {
          "5.4.1": {
            "title": "Euler-Formel",
            "page": 85,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 5.4",
                "details": "Euler-Formel Sei φ ∈R, dann gilt ei·φ = cis(φ) = cos(φ) + i · sin(φ). (5.28)",
                "page": 85
              },
              {
                "type": "Beweis",
                "text": "Beweis: Übung mit Hilfe von Maclaurin-Entwicklungen.",
                "details": "Wir betrachten den folgenden Satz.",
                "page": 85
              },
              {
                "type": "Satz",
                "text": "Satz 5.5",
                "details": "Umkehrungen der Euler-Formel Sei φ ∈R, dann gilt folgendes. (a) sin(φ) = ei·φ −e−i·φ 2 · i = −i · sinh(i · φ) (b) cos(φ) = ei·φ + e−i·φ 2 = cosh(i · φ)",
                "page": 85
              },
              {
                "type": "Beweis",
                "text": "Beweis: Übung.",
                "details": "",
                "page": 85
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Euler-Formel beschreibt die fundamentalen Zusammenhänge zwischen der natürli- chen Exponentialfunktion und den trigonometrischen bzw. hyperbolischen Funktionen. ii) Aus der Euler-Formel lässt sich eine einfache algebraische Beziehung zwischen den fun- damentalen Zahlen in {0, 1, e, π, i} herleiten. Es gilt ei·π + 1 = 0. (5.29)",
                "page": 85
              }
            ]
          },
          "5.4.2": {
            "title": "Exponentielle Form",
            "page": 85,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 5.6",
                "details": "Exponentielle Form Seien x, y ∈R, r ∈R+ und φ ∈[0, 2π[ oder φ ∈]−π, π] dann gibt es ein eindeutiges z ∈C\\{0} mit z = x + y · i = r · ei·φ. (5.30) Ferner gelten die folgenden Umrechnungsformeln. (a) x = r · cos(φ) ∧y = r · sin(φ) (b) r = |z| = p x2 + y2 ∧φ = arg(z) II-9",
                "page": 85
              },
              {
                "type": "Beweis",
                "text": "Beweis: Die Aussage folgt sofort aus der Euler-Formel.",
                "details": "",
                "page": 86
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Jede komplexe Zahl z ∈C lässt sich auf drei Arten darstellen, nämlich z = x + y · i | {z } arithmetische Form = r · cis(φ) | {z } trigonometrische Form = r · ei·φ | {z } exponentielle Form . (5.31) ii) Man bezeichnet die Schreibweise z = r · ei·φ nur dann als exponentielle Form, wenn gilt r = |z| ≥0. Der Winkel φ ∈R darf jedoch beliebig gewählt werden, d.h. φ muss nicht unbedingt das Argument gemäss einer der beiden Varianten sein. iii) In exponentieller Form lässt sich die Multiplikation von zwei komplexen Zahlen auf einfa- che Weise in der Gauss-Ebene geometrisch interpretieren. Es gilt z1 · z2 = r1 · ei·φ1 · r2 · ei·φ2 = r1 · r2 · ei·φ1+i·φ2 = r1 · r2 · ei·(φ1+φ2). (5.32) iv) In exponentieller Form lässt sich das Potenzieren einer komplexen Zahl mit einem strikt positiven Exponenten p > 0 auf einfache Weise in der Gauss-Ebene geometrisch interpre- tieren. Es gilt zp = (r · ei·φ) p = rp · (ei·φ) p = rp · ei·p·φ. (5.33)",
                "page": 86
              }
            ]
          },
          "5.4.3": {
            "title": "Potenz-Gleichungen",
            "page": 86,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 5.7",
                "details": "Lösungen von Potenz-Gleichungen Seien w, z ∈C, n ∈N+, r, φ ∈R mit r > 0 und z erfülle die Potenz-Gleichung zn = w = r · ei·φ. (5.42) Dann gilt folgendes. (a) Für w = 0 hat (5.42) genau eine Lösung für z, nämlich z = 0. (5.43) (b) Für w ̸= 0 hat (5.42) genau n Lösungen für z, nämlich zk = n√r · ei· φ+(k−1)·2π n für k ∈{1, . . . , n}. (5.44)",
                "page": 87
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Tatsache, dass (5.42) ausser für w = 0 genau n Lösungen hat, wird als algebraische Vollständigkeit oder algebraische Abgeschlossenheit von C bezeichnet. ii) Für alle Lösungen von (5.42) gilt |zk| = n√r = np |w| . (5.45) Die Lösungen liegen in der Gauss-Ebene daher auf dem Kreis um den Ursprung mit Radius np |w|. iii) Zwischen zwei benachbarten Lösungen von (5.42) liegt jeweils ein Winkel von ∆φ = 2π n . (5.46) iv) Die Lösungen von (5.42) bilden ein reguläres n-Eck in der Gauss-Ebene. II-11",
                "page": 87
              }
            ]
          },
          "5.4.4": {
            "title": "Wurzeln",
            "page": 88,
            "content": []
          }
        }
      }
    }
  },
  "6": {
    "title": "Matrizen & Lineare Abbildungen",
    "page": 89,
    "sections": {
      "6.1": {
        "title": "Matrix-Algebra",
        "page": 89,
        "subsections": {
          "6.1.1": {
            "title": "Definition",
            "page": 89,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.1",
                "details": "Matrix Seien m, n ∈N+. Eine reelle m×n-Matrix A ist eine Zahlentabelle mit m Zeilen und n Spalten der Form A =   A11 A12 . . . A1n A21 A22 . . . A2n ... ... ... ... Am1 Am2 . . . Amn   , (6.1) wobei alle Aij ∈R.",
                "page": 89
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Zahlen m und n heissen Dimensionen der Matrix A. ii) Die reellen Zahlen Aij heissen Komponenten der Matrix A. Eine m × n-Matrix besteht offensichtlich aus m · n Komponenten. iii) Wir werden später sehen, dass es sinnvoll ist, den Zeilen-Index i oben und den Spalten- Index j unten zu schreiben. iv) Für die Menge aller reellen m × n-Matrizen gibt es verschiedene Bezeichnungen. Wir verwenden M(m, n, R) = Rm×n. (6.2) v) Wir betrachten die Matrix M = \u0014 1 2 3 4 5 6 \u0015 . (6.3) II-13",
                "page": 89
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Eine 2 × 3-Matrix: A = \u0014 2 −1 3 7 5 −4 \u0015 • Eine 2 × 2-Matrix: B = \u0014 2 −1 7 5 \u0015 • Eine 1 × 3-Matrix: C = \u0002 2 −1 3 \u0003 • Eine 2 × 1-Matrix: D = \u0014 2 7 \u0015",
                "page": 90
              }
            ]
          },
          "6.1.2": {
            "title": "Operationen",
            "page": 90,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.2",
                "details": "Addition & Subtraktion Seien m, n ∈N+ und A, B ∈M(m, n, R), dann ist A + B :=   A11 + B11 A12 + B12 . . . A1n + B1n A21 + B21 A22 + B22 . . . A2n + B2n ... ... ... ... Am1 + Bm1 Am2 + Bm2 . . . Amn + Bmn   . (6.4) und A −B :=   A11 −B11 A12 −B12 . . . A1n −B1n A21 −B21 A22 −B22 . . . A2n −B2n ... ... ... ... Am1 −Bm1 Am2 −Bm2 . . . Amn −Bmn   . (6.5)",
                "page": 90
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für alle A, B ∈M(m, n, R) gilt A ± B ∈M(m, n, R). II-14",
                "page": 90
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0014 2 −1 7 5 \u0015 + \u0014 1 −2 6 −5 \u0015 = \u0014 3 −3 13 0 \u0015 • \u0014 2 −1 7 5 \u0015 − \u0014 1 −2 6 −5 \u0015 = \u0014 1 1 1 10 \u0015 • \u0002 0 1 \u0003 + \u0002 −1 −1 \u0003 = \u0002 −1 0 \u0003",
                "page": 91
              },
              {
                "type": "Definition",
                "text": "Definition 6.3",
                "details": "Multiplikation mit einem Skalar Seien m, n ∈N+, a ∈R und A ∈M(m, n, R), dann ist a · A :=   a · A11 a · A12 . . . a · A1n a · A21 a · A22 . . . a · A2n ... ... ... ... a · Am1 a · Am2 . . . a · Amn   . (6.6)",
                "page": 91
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für alle a ∈R und A ∈M(m, n, R) gilt a · A ∈M(m, n, R). ii) Multipliziert man eine reelle Matrix mit einem Skalar, dann multipliziert man ihre Kom- ponenten mit dem Skalar. iii) Es soll keine Rolle spielen, ob der Skalar links oder rechts der reellen Matrix geschrieben wird. Man definiert A · a := a · A. (6.7) iv) Aus der Multiplikation mit einem Skalar ergibt sich auf natürliche Weise eine Division. Es soll gelten A a := 1 a · A. (6.8) II-15",
                "page": 91
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• 2 · \u0014 2 −1 7 5 \u0015 = \u0014 4 −2 14 10 \u0015 • 1 3 · \u0014 9 −12 3 0 \u0015 = \u0014 3 −4 1 0 \u0015 • (−1) · \u0002 3 −3 \u0003 = \u0002 −3 3 \u0003",
                "page": 92
              },
              {
                "type": "Definition",
                "text": "Definition 6.4",
                "details": "Transposition Seien m, n ∈N+ und A ∈M(m, n, R), dann ist AT :=   A11 A21 . . . Am1 A12 A22 . . . Am2 ... ... ... ... A1n A2n . . . Amn   . (6.9)",
                "page": 92
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Beim Transponieren einer reellen Matrix werden die Spalten mit den Zeilen vertauscht. ii) Ist A ∈M(m, n, R), dann gilt AT ∈M(n, m, R). iii) Die Transposition ist eine Involution, d.h. für jede Matrix A gilt \u0000AT\u0001T = A. (6.10) iv) Beispiel-Codes zur Berechnung von Matrix-Transpositionen mit gängiger Software. MATLAB/Octave M=A’ Mathematica/WolframAlpha M=Transpose[A] Python/Numpy M=A.T Python/Sympy M=A.T II-16",
                "page": 92
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0014 2 −1 3 7 5 −4 \u0015T =   2 7 −1 5 3 −4   • \u0014 2 −1 7 5 \u0015T = \u0014 2 7 −1 5 \u0015 • \u0002 2 −1 \u0003T = \u0014 2 −1 \u0015",
                "page": 93
              },
              {
                "type": "Definition",
                "text": "Definition 6.5",
                "details": "Matrix-Produkt Seien l, m, n ∈N+, A ∈M(l, m, R) und B ∈M(m, n, R), dann ist das Matrix-Produkt C = A · B definiert durch Ci j := m X s=1 Ai s · Bs j. (6.11)",
                "page": 93
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Das Matrix-Produkt A · B ist also genau dann definiert, wenn A so viele Spalten wie B Zeilen hat. ii) Für A ∈M(l, m, R) und B ∈M(m, n, R) gilt A · B ∈M(l, n, R). iii) Die Komponenten des Matrix-Produkts A · B sind gerade die Kontraktionen (“Skalar- Produkte”) der Zeilen von A mit den Spalten von B. iv) Die Berechnung eines Matrix-Produkts ist im allgemeinen recht aufwändig. v) Beispiel-Codes zur Berechnung von Matrix-Produkten mit gängiger Software. MATLAB/Octave M=A*B Mathematica/WolframAlpha M=A.B Python/Numpy M=A@B Python/Sympy M=A*B",
                "page": 93
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0014 1 2 3 4 \u0015 · \u0014 5 6 7 8 \u0015 = \u0014 1 · 5 + 2 · 7 1 · 6 + 2 · 8 3 · 5 + 4 · 7 3 · 6 + 4 · 8 \u0015 = \u0014 19 22 43 50 \u0015 • \u0014 5 6 7 8 \u0015 · \u0014 1 2 3 4 \u0015 = \u0014 5 · 1 + 6 · 3 5 · 2 + 6 · 4 7 · 1 + 8 · 3 7 · 2 + 8 · 4 \u0015 = \u0014 23 34 31 46 \u0015 II-17",
                "page": 93
              },
              {
                "type": "Satz",
                "text": "Satz 6.1",
                "details": "Rechenregeln für Matrizen Es seien A, B, C reelle Matrizen und a, b ∈R. Sofern alle Operationen gemäss den Dimensionen definiert sind, gelten die folgenden Rechenregeln. (a) A + B = B + A (b) (A + B) + C = A + (B + C) (c) a · (A + B) = a · A + a · B (d) (a + b) · A = a · A + b · A (e) (a · A) · B = a · (A · B) = A · (a · B) (f) (A · B) · C = A · (B · C) (g) A · (B + C) = A · B + A · C (h) (A + B) · C = A · C + B · C (i) \u0000AT\u0001T = A (j) (A + B)T = AT + BT (k) (a · A)T = a · AT (l) (A · B)T = BT · AT",
                "page": 94
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Matrix-Addition ist also assoziativ und kommutativ und es gilt das Distributivgesetz sowohl bei der Multiplikation mit einem Skalar als auch mit einer reellen Matrix. ii) Die Matrix-Multiplikation ist im allgemeinen nicht kommutativ. Es gibt Matrizen A und B, für welche gilt A · B = B · A aber auch solche für die wir A · B ̸= B · A finden. iii) Das Transponierte eines Matrix-Produkts ist das umgekehrte Matrix-Produkt der Trans- ponierten Faktoren. II-18",
                "page": 94
              }
            ]
          },
          "6.1.3": {
            "title": "Spezielle Matrizen",
            "page": 95,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.6",
                "details": "Quadratische Matrix Sei n ∈N+. Eine reelle Matrix A ∈M(n, n, R) heisst quadratische Matrix.",
                "page": 95
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Quadratische Matrizen haben genau n2 Komponenten. ii) Das Produkt von zwei quadratischen Matrizen ist wieder eine quadratische Matrix, d.h. A, B ∈M(n, n, R) ⇒A · B ∈M(n, n, R). iii) Quadratische Matrizen können mit sich selbst multipliziert werden. So lassen sich Potenzen bilden. Für n, p ∈N+ und A ∈M(n, n, R) ist Ap : = A · . . . · A | {z } p Faktoren . (6.12) Die Potenz ist dann wieder eine quadratische Matrix, d.h. Ap ∈M(n, n, R).",
                "page": 95
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0002 2 \u0003 • \u0014 2 −1 7 5 \u0015 •   3 −6 7 1 0 −2 1 8 9   Von zwei quadratischen Matrizen gleicher Dimension können beide Produkt, d.h. sowohl A · B als auch B · A gebildet werden. Die Differenz ist in vielen Anwendungen von Interesse.",
                "page": 95
              },
              {
                "type": "Definition",
                "text": "Definition 6.7",
                "details": "Kommutator Seien n ∈N+ und A, B ∈M(n, n, R). Der Kommutator von A und B ist die Matrix [A, B] := A · B −B · A. (6.13)",
                "page": 95
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Kommutator von zwei quadratischen Matrizen ist wieder eine quadratische Matrix, d.h. A, B ∈M(n, n, R) ⇒[A, B] ∈M(n, n, R). ii) Der Kommutator verschwindet genau dann, wenn die Matrizen kommutieren, d.h. wenn gilt A · B = B · A. iii) Der Kommutator ist als Operation schiefsymmetrisch, d.h. es gilt [A, B] = −[B, A]. (6.14) II-19",
                "page": 95
              },
              {
                "type": "Definition",
                "text": "Definition 6.8",
                "details": "Symmetrische & schiefsymmetrische Matrix Seien n ∈N+ und A ∈M(n, n, R). (a) A ist symmetrisch, genau falls AT = A. (b) A ist schiefsymmetrisch, genau falls AT = −A.",
                "page": 96
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Komponenten auf der Hauptdiagonalen einer schiefsymmetrischen Matrix müssen zwingend verschwinden. ii) Eine symmetrische Matrix A ∈M(n, n, R) hat die Anzahl unabhängiger Komponenten von n+ = n · (n + 1) 2 . (6.15) iii) Eine schiefsymmetrische Matrix A ∈M(n, n, R) hat die Anzahl unabhängiger Komponen- ten von n−= n · (n −1) 2 . (6.16)",
                "page": 96
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0014 1 2 2 3 \u0015 ist symmetrisch • \u0014 0 −2 2 0 \u0015 ist schiefsymmetrisch •   0 −1 2 1 0 −3 −2 3 0  ist schiefsymmetrisch II-20",
                "page": 96
              },
              {
                "type": "Definition",
                "text": "Definition 6.9",
                "details": "Nullmatrix Seien m, n ∈N+. Die Matrix 0 ∈M(m, n, R) mit 0 =   0 0 . . . 0 0 0 . . . 0 ... ... ... ... 0 0 . . . 0   (6.17) heisst Nullmatrix.",
                "page": 97
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Alle Nullmatrizen werden unabhängig von ihren Dimensionen identifiziert und mit 0 bezeichnet. Es gilt also 0 = \u0002 0 \u0003 = \u0002 0 0 \u0003 = \u0014 0 0 \u0015 = \u0014 0 0 0 0 \u0015 = \u0014 0 0 0 0 0 0 \u0015 =   0 0 0 0 0 0  = . . . . (6.18) ii) Die Nullmatrix hat die gleichen algebraischen Eigenschaften wie die Zahl Null. Für jede Matrix A gilt A + 0 = A und 0 · A = 0. (6.19) iii) Die quadratischen Nullmatrizen sind die einzigen Matrizen die sowohl symmetrisch als auch schiefsymmetrisch sind. iv) Beispiel-Codes zum Erzeugen von Nullmatrizen mit gängiger Software. MATLAB/Octave M=zeros(3) M=zeros(2,3) Mathematica/WolframAlpha M=ConstantArray[0,{3,3}] M=ConstantArray[0,{2,3}] Python/Numpy import numpy as np; M=np.zeros((3,3)) M=np.zeros((2,3)) Python/Sympy import sympy as sp; M=sp.zeros(3) M=sp.zeros(2,3) II-21",
                "page": 97
              },
              {
                "type": "Definition",
                "text": "Definition 6.10",
                "details": "Einheitsmatrix Sei n ∈N+. Die Matrix 1 ∈M(n, n, R) mit 1 =   1 0 . . . 0 0 1 . . . 0 ... ... ... ... 0 0 . . . 1   (6.20) heisst Einheitsmatrix.",
                "page": 98
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Alle Einheitsmatrizen werden unabhängig von ihrer Dimension identifiziert und mit 1 bezeichnet. Es gilt also 1 = \u0002 1 \u0003 = \u0014 1 0 0 1 \u0015 =   1 0 0 0 1 0 0 0 1  =   1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1  = . . . . (6.21) ii) Die Einheitsmatrix hat die gleichen algebraischen Eigenschaften wie die Zahl Eins. Für jede Matrix A gilt 1 · A = A · 1 = A. (6.22) iii) Ist A eine quadratische Matrix, dann folgt der Kommutator [A, 1] = A · 1 −1 · A = A −A = 0. (6.23) Das heisst, die Einheitsmatrix kommutiert mit jeder quadratischen Matrix. iv) Die Einheitsmatrix ist offensichtlich symmetrisch. v) Beispiel-Codes zum Erzeugen von Einheitsmatrizen mit gängiger Software. MATLAB/Octave M=eye(3) M=eye(2,3) Mathematica/WolframAlpha M=IdentityMatrix[3] Python/Numpy import numpy as np; M=np.eye(3) M=np.eye(2,3) Python/Sympy import sympy as sp; M=sp.eye(3) M=sp.eye(2,3) II-22",
                "page": 98
              },
              {
                "type": "Definition",
                "text": "Definition 6.11",
                "details": "Invertierbare Matrix Sei n ∈N+. Eine quadratische Matrix A ∈M(n, n, R) heisst invertierbar, falls es eine quadrati- sche Matrix A−1 ∈M(n, n, R) gibt, so dass A−1 · A = 1. (6.24)",
                "page": 99
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Invertierbare Matrizen werden auch regulär genannt, während nicht invertierbare Matri- zen als singulär bezeichnet werden. ii) Die quadratische Matrix A−1, falls es die denn gibt, wird Inverse Matrix von A genannt. iii) Obwohl die Matrix-Multiplikation im allgemeinen nicht kommutativ ist, lässt sich die Reihenfolge in (6.24) immer vertauschen. Ist A invertierbar, dann gilt A−1 · A = A · A−1 = 1. (6.25) Daraus erhält man den Kommutator [A, A−1] = A · A−1 −A−1 · A = 1 −1 = 0. (6.26) iv) Die Einheitsmatrix ist offensichtlich invertierbar und ihre eigene Inverse, es gilt also 1−1 = 1. (6.27) v) Die Nullmatrix ist offensichtlich singulär, d.h. nicht invertierbar. vi) Die Inversion einer reellen Matrix ist offensichtlich eine Involution. Für jede invertierbare Matrix gilt \u0000A−1\u0001−1 = A. (6.28) vii) Beispiel-Codes zur Berechnung von inversen Matrizen mit gängiger Software. MATLAB/Octave M=inv(A) Mathematica/WolframAlpha M=Inverse[A] Python/Numpy import numpy as np; M=np.linalg.inv(A) Python/Sympy M=A.inv()",
                "page": 99
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0002 2 \u0003−1 = \u0002 1 2 \u0003 • \u0014 2 1 5 3 \u0015−1 = \u0014 3 −1 −5 2 \u0015 II-23",
                "page": 99
              },
              {
                "type": "Satz",
                "text": "Satz 6.2",
                "details": "Elementare Rechenregeln der Inversion Es seien A, B invertierbare Matrizen und a ∈R \\ {0}. Dann gelten folgende Rechenregeln. (a) (a · A)−1 = 1 a · A−1 (b) (A · B)−1 = B−1 · A−1 (c) \u0000AT\u0001−1 = \u0000A−1\u0001T (d) \u0000A−1\u0001−1 = A",
                "page": 100
              },
              {
                "type": "Definition",
                "text": "Definition 6.12",
                "details": "Diagonal-Matrix Sei n ∈N+ und λ1, . . . , λn ∈R. Eine Matrix D ∈M(n, n, R) der Form D =   λ1 0 · · · 0 0 λ2 ... ... ... ... ... 0 0 · · · 0 λn  . (6.29) heisst diagonal.",
                "page": 100
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die reellen Zahlen λ1, . . . , λn auf der Hauptdiagonalen heissen Eigenwerte der Matrix D. ii) Die Einheitsmatrix sowie jede quadratische Nullmatrix sind offensichtlich diagonal. iii) Jede diagonale Matrix ist offensichtlich symmetrisch. iv) Zwei beliebige diagonalen Matrizen kommutieren, d.h. es gilt [D, ˜D] = 0. (6.30) Aber: Diagonale Matrizen kommutieren nicht mit allen Matrizen! v) Sind alle Eigenwerte einer diagonalen Matrix von Null verschieden, dann ist die Matrix invertierbar. Die Inverse ist ebenfalls diagonal und es gilt D−1 =   1 λ1 0 . . . 0 0 1 λ2 . . . 0 ... ... ... ... 0 0 . . . 1 λn   . (6.31) II-24",
                "page": 100
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0002 3 \u0003 • \u0014 1 0 0 2 \u0015 •   −7 0 0 0 3 0 0 0 −1   II-25",
                "page": 101
              }
            ]
          }
        }
      },
      "6.2": {
        "title": "Lineare Abbildungen",
        "page": 102,
        "subsections": {
          "6.2.1": {
            "title": "Definition",
            "page": 102,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.13",
                "details": "Lineare Abbildung - Version 1 Seien m, n ∈N+ und A ∈M(n, m, R). Eine Abbildung der Form a : Rm →Rn x 7→a(x) := A · x (6.32) heisst lineare Abbildung.",
                "page": 102
              },
              {
                "type": "Definition",
                "text": "Definition 6.14",
                "details": "Lineare Abbildung - Version 2 Seien m, n ∈N+. Eine lineare Abbildung ist eine Abbildung des Typs a : Rm →Rn mit der Eigenschaft, dass für alle v, w ∈Rm und x, y ∈R gilt a(x · v + y · w) = x · a(v) + y · a(w). (6.33)",
                "page": 102
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die beiden Definitionen sind äquivalent. Es ist leicht einzusehen, dass die linearen Abbil- dungen gemäss Definition 6.13 die Haupteigenschaft (6.33) aus Definition 6.14 erfüllen. Es gilt a(x · v + y · w) = A · (x · v + y · w) = A · x · v + A · y · w = x · A · v + y · A · w = x · a(v) + y · a(w). (6.34) ii) Die Matrix A, welche gemäss Definition 6.13 eine lineare Abbildung a beschreibt, wird Abbildungsmatrix genannt. iii) Ist die Abbildungsmatrix A quadratisch, d.h. m = n, dann ist a eine Selbstabbildung des Typs a : Rn →Rn. iv) Bekannte geometrische Abbildungen wie Streckungen, Projektionen, Spiegelungen und Ro- tationen sind lineare Abbildungen, welche jeweils durch eine Abbildungsmatrix ausgedrückt werden können. v) Für alle linearen Abbildungen gilt offensichtlich a(0) = A · 0 = 0. (6.35) vi) Für n = m = 1 gibt es eine historisch bedingte Begriffskollision zwischen einer linearen Funktion in der Analysis und einer linearen Abbildung in der linearen Algebra. Analysis: f(x) = m · x + q Lineare Algebra: a(x) = A · x. (6.36) II-26",
                "page": 102
              }
            ]
          },
          "6.2.2": {
            "title": "Eigenschaften",
            "page": 103,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 6.3",
                "details": "Verknüpfungssatz Seien m, n, l ∈N+ und a : Rm →Rn sowie b : Rn →Rl zwei lineare Abbildungen mit Abbil- dungsmatrizen A ∈M(n, m, R) bzw. B ∈M(l, n, R). Dann ist die Verknüpfung c : Rm →Rl x 7→c(x) := b \u0000a(x) \u0001 (6.37) ebenfalls eine lineare Abbildung mit Abbildungsmatrix C = B · A. (6.38)",
                "page": 103
              },
              {
                "type": "Beweis",
                "text": "Beweis: Wegen der Assoziativität des Matrix-Produkts finden wir für alle x ∈Rm",
                "details": "c(x) = b \u0000a(x) \u0001 = b(A · x) = B · (A · x) = (B · A) · x =: C · x, (6.39) wobei gelten muss C = B · A. (6.40) Damit haben wir den Satz bewiesen. Ist eine lineare Abbildung bijektiv, dann ist auch die Umkehrabbildung wieder eine lineare Ab- bildung, deren Abbildungsmatrix gerade die Inverse der ursprünglichen Abbildungsmatrix ist.",
                "page": 103
              },
              {
                "type": "Satz",
                "text": "Satz 6.4",
                "details": "Inversionssatz Seien m, n ∈N+ und a : Rm →Rn eine lineare Abbildung mit Abbildungsmatrix A ∈M(n, m, R). Dann gilt folgendes. (a) a bijektiv ⇒n = m (b) a bijektiv ⇔A regulär (c) a bijektiv ⇒a−1(y) = A−1 · y.",
                "page": 103
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Verknüpfung von zwei linearen Abbildungen geschieht durch Matrix-Multiplikation der Abbildungsmatrizen. Dabei muss die Reihenfolge beachtet werden, d.h. a(x) := aN \u0010 . . . a2 \u0000a1(x) \u0001\u0011 ⇒A = AN · . . . · A2 · A1. (6.41) ii) Die Umkehrung einer bijektiven linearen Abbildung geschieht durch Inversion der Abbil- dungsmatrix. II-27",
                "page": 103
              }
            ]
          },
          "6.2.3": {
            "title": "Spalten-Vektor-Konstruktionsverfahren",
            "page": 104,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 6.5",
                "details": "Spalten-Vektor-Satz Seien m, n ∈N+, a : Rm →Rn eine lineare Abbildung mit Abbildungsmatrix A ∈M(n, m, R) und ˆe1 =   1 0 0 ... 0   , ˆe2 =   0 1 0 ... 0   , . . . , ˆem =   0 0 ... 0 1   . (6.45) Dann gilt A = \u0002 a(ˆe1) a(ˆe2) . . . a(ˆem) \u0003 . (6.46)",
                "page": 104
              },
              {
                "type": "Beweis",
                "text": "Beweis: Die Bilder der Einheitsvektoren aus (6.45) unter der linearen Abbildung a sind",
                "details": "a(ˆe1) = A · ˆe1 =   A11 A12 . . . A1m A21 A22 . . . A2m A31 A32 . . . A3m ... ... ... ... An1 An2 . . . Anm   ·   1 0 0 ... 0   =   A11 A21 A31 ... An1   (6.47) a(ˆe2) = A · ˆe2 =   A11 A12 . . . A1m A21 A22 . . . A2m A31 A32 . . . A3m ... ... ... ... An1 An2 . . . Anm   ·   0 1 0 ... 0   =   A12 A22 A32 ... An2   (6.48) II-28",
                "page": 104
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Um die Abbildungsmatrix einer linearen Abbildung zu bestimmen, braucht man also nur ihre geometrische Wirkung auf die Standard-Einheitsvektoren zu kennen. ii) Um den Spalten-Vektor-Satz auf eine geometrische Abbildung anwenden zu können, muss man jedoch schon wissen bzw. mit Hilfe der Haupteigenschaft (6.33) zuerst prüfen, dass die Abbildung auch wirklich linear ist.",
                "page": 105
              }
            ]
          },
          "6.2.4": {
            "title": "Beispiele",
            "page": 105,
            "content": []
          }
        }
      },
      "6.3": {
        "title": "Orthogonale Matrizen",
        "page": 107,
        "subsections": {
          "6.3.1": {
            "title": "Definition",
            "page": 107,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.15",
                "details": "Orthogonale Matrix Sei n ∈N+. Eine reguläre Matrix A ∈M(n, n, R) heisst orthogonal, falls A−1 = AT. (6.52) Ferner definieren wir die Menge aller orthogonalen n × n-Matrizen.",
                "page": 107
              },
              {
                "type": "Definition",
                "text": "Definition 6.16",
                "details": "Orthogonale Gruppe Sei n ∈N+. Die orthogonale Gruppe in nD ist die Menge O(n) := \b A ∈M(n, n, R) A−1 = AT . (6.53) Wir betrachten den folgenden Satz.",
                "page": 107
              },
              {
                "type": "Satz",
                "text": "Satz 6.6",
                "details": "Orthogonale Gruppe Sei n ∈N+, dann bildet O(n) eine algebraische Gruppe, d.h. für alle A, B, C ∈O(n) gilt folgendes. (a) Endogenität: A · B ∈O(n) (b) Assoziativität: (A · B) · C = A · (B · C) (c) Neutrales Element: 1 ∈O(n) (d) Inverse Elemente: A−1 ∈O(n)",
                "page": 107
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Offensichtlich gilt 1 ∈O(n) für alle n ∈N+, denn es gilt 1−1 = 1 = 1T. (6.54) ii) Ist eine Matrix orthogonal und symmetrisch, dann folgt A−1 = AT = A ⇒A2 = A · A = A−1 · A = 1. (6.55) Die orthogonalen symmetrischen Matrizen verhalten sich wie Wurzeln der Einheitsmatrix. iii) Ist eine Matrix orthogonal und schiefsymmetrisch, dann folgt A−1 = AT = −A ⇒A2 = −A−1 · A = −1. (6.56) Die orthogonalen schiefsymmetrischen Matrizen verhalten sich ähnlich wie die imaginäre Einheit i ∈C. II-31",
                "page": 107
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• \u0014 0 1 1 0 \u0015 • 1 √ 13 · \u0014 −2 3 3 2 \u0015 • 1 5 ·   3 −4 0 4 3 0 0 0 5  ",
                "page": 108
              }
            ]
          },
          "6.3.2": {
            "title": "Geometrische Eigenschaften",
            "page": 108,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 6.7",
                "details": "Orthonormalität der Spalten-Vektoren Seien n ∈N+ und A ∈O(n) mit Spaltenvektoren a1, . . . , an ∈Rn, d.h. A = \u0002 a1 a2 . . . an \u0003 . (6.61) Dann gilt ⟨ai , aj ⟩= δij = ( 1 i = j 0 i ̸= j. (6.62)",
                "page": 108
              },
              {
                "type": "Beweis",
                "text": "Beweis: Weil A orthogonal ist, gilt",
                "details": "1 = A−1 · A = AT · A =   aT 1 aT 2 ... aT n   · \u0002 a1 a2 . . . an \u0003 =   aT 1 · a1 aT 1 · a2 . . . aT 1 · an aT 2 · a1 aT 2 · a2 . . . aT 2 · an ... ... ... ... aT n · a1 aT n · a2 . . . aT n · an   II-32",
                "page": 108
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Spalten-Vektoren einer orthogonalen Matrix sind Einheitsvektoren, die paarweise senk- recht aufeinander stehen. ii) Gemäss Spalten-Vektor-Konstruktionsverfahren werden durch eine orthogonale Abbildung die Standard-Einheitsvektoren ˆe1, . . . ,ˆen ∈Rn auf paarweise aufeinander senkrecht ste- hende Einheitsvektoren abgebildet. iii) Die Schreibweise der Komponenten der Einheitsmatrix als Koeffizienten δij wird auch Kronecker-Symbol genannt. Bevor wir die geometrischen Eigenschaften von orthogonalen Abbildungen weiter untersuchen können, benötigen wir eine Rechenregel.",
                "page": 109
              },
              {
                "type": "Satz",
                "text": "Satz 6.8",
                "details": "Metrische Adjunktion Seien n ∈N+, A ∈M(n, n, R) und v, w ∈Rn, dann gilt ⟨v, A · w⟩= AT · v, w . (6.64)",
                "page": 109
              },
              {
                "type": "Beweis",
                "text": "Beweis: Weil das Skalar-Produkt von zwei Vektoren eine reelle Zahl ist, die als 1 × 1-Matrix",
                "details": "aufgefasst werden kann und alle 1 × 1-Matrizen symmetrisch sind, erhalten wir ⟨v, A · w⟩= ⟨v, A · w⟩T = \u0000vT · A · w \u0001T = wT · AT · v = w, AT · v = AT · v, w . (6.65) Damit haben (6.64) und den Satz bewiesen.",
                "page": 109
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Rechenregel (6.64) hat nichts mit Orthogonalität zu tun, sie gilt für alle quadratischen Matrizen. ii) Weil die Transposition eine Involution ist, gilt auch v, AT · w = D\u0000AT \u0001T · v, w E = ⟨A · v, w⟩. (6.66) iii) Gemäss (6.64) darf man eine Matrix vor einem Vektor in einem Skalar-Produkt auf die andere Seite “schieben”, wenn man sie transponiert. II-33",
                "page": 109
              },
              {
                "type": "Satz",
                "text": "Satz 6.9",
                "details": "Invarianzen von orthogonalen Abbildungen Seien n ∈N+ und A ∈O(n). Dann gilt für alle Vektoren v, w ∈Rn folgendes. (a) Skalar-Produkt-Invarianz: ⟨A · v, A · w⟩= ⟨v, w⟩ (6.67) (b) Längen-Invarianz: |A · v| = |v| (6.68) (c) Winkel-Invarianz: ∡(A · v, A · w) = ∡(v, w) (6.69)",
                "page": 110
              },
              {
                "type": "Beweis",
                "text": "Beweis: Mit Hilfe der Rechenregel (6.64) und weil A orthogonal ist, finden wir",
                "details": "⟨A · v, A · w⟩= AT · A · v, w = A−1 · A · v, w = ⟨v, w⟩. (6.70) Daraus folgt sofort auch |A · v| = p ⟨A · v, A · v⟩= p ⟨v, v⟩= |v|. (6.71) Wir betrachten die Fälle 0 ∈{v, w} und 0 ̸∈{v, w} getrennt. Fall 1: Es sei 0 ∈{v, w}. In diesem Fall gilt auch 0 ∈{A · v, A · w} und es folgt ∡(A · v, A · w) = π 2 = ∡(v, w). (6.72) Fall 2: Es sei 0 ̸∈{v, w}. In diesem Fall gilt auch 0 ̸∈{A · v, A · w} und es folgt ∡(A · v, A · w) = arccos \u0012 ⟨A · v, A · w⟩ |A · v| · |A · w| \u0013 = arccos \u0012 ⟨v, w⟩ |v| · |w| \u0013 = ∡(v, w). (6.73) Damit haben wir alle Aussagen und den Satz bewiesen.",
                "page": 110
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die letzten beiden Invarianz-Eigenschaften aus Satz 6.9 werden auch Längentreue und Winkeltreue genannt. Orthogonale Abbildungen sind demnach Kongruenz-Abbildungen im Sinne der klassischen Geometrie. Das Umgekehrte gilt jedoch nicht, denn es gibt auch Kongruenz-Abbildungen die nicht linear sind und folglich auch nicht orthogonal sein kön- nen, z.B. Translationen. ii) Tatsächlich sind die Abbildungen in O(n) gerade die Spiegelungen und Drehungen in Rn sowie deren Verknüpfungen. II-34",
                "page": 110
              }
            ]
          },
          "6.3.3": {
            "title": "Spezielle orthogonale Matrizen",
            "page": 111,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 6.10",
                "details": "Householder-Formel Die Spiegelung wird beschrieben durch die Matrix S(ˆn) = 1 −2 · ˆn · ˆnT. (6.74)",
                "page": 111
              },
              {
                "type": "Beweis",
                "text": "Beweis: Um das Bild eines Vektors v ∈Rn unter der Spiegelung zu berechnen, zerlegen wir v",
                "details": "in seine Anteile parallel und senkrecht zu ˆn. Es sei also v = v∥+ v⊥ (6.75) mit v∥= ⟨v, ˆn⟩· ˆn und v⊥= v −v∥. (6.76) Für die Spiegelungsmatrix S(ˆn) gilt gemäss Skizze S(ˆn) · v = v −2 · v∥= v −2 · ⟨v, ˆn⟩· ˆn = v −2 · ˆn · ⟨v, ˆn⟩= v −2 · ˆn · ⟨ˆn, v⟩ = v −2 · ˆn · \u0000ˆnT · v \u0001 = 1 · v −2 · \u0000ˆn · ˆnT \u0001 · v = \u00001 −2 · ˆn · ˆnT \u0001 · v. (6.77) Dies impliziert (6.74) und wir haben den Satz bewiesen.",
                "page": 111
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Es gilt S(ˆn) ∈O(n). ii) In jedem Fall gilt S(−ˆn) = S(ˆn) (6.78) d.h. es spielt keine Rolle auf welche Seite man ˆn wählt. II-35",
                "page": 111
              },
              {
                "type": "Definition",
                "text": "Definition 6.17",
                "details": "Rotationsgenerator Für jedes w ∈R3 ist der Rotationsgenerator die Matrix J(w) :=   0 −w3 w2 w3 0 −w1 −w2 w1 0  . (6.82) Im folgenden Satz stellen wir die wichtigsten algebraischen Eigenschaften des Rotationsgenera- tors zusammen.",
                "page": 113
              },
              {
                "type": "Satz",
                "text": "Satz 6.11",
                "details": "Eigenschaften des Rotationsgenerators Seien v, w ∈R3 mit w = |w|, dann gilt folgendes. (a) J(w) ist schiefsymmetrisch (b) J2(w) ist symmetrisch (c) J(w) · v = w × v (d) JT(w) = −J(w) = J(−w) (e) J3(w) = −w2 · J(w) (f) J4(w) = −w2 · J2(w)",
                "page": 113
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Gemäss Eigenschaft (c) beschreibt J(w) gerade das Grassmann-Vektor-Produkt von links mit dem Vektor w. ii) Für alle v, w ∈R3 gilt die berühmte Drehimpuls-Kommutatonsrelation \u0002 J(v), J(w) \u0003 = J(v × w). (6.83) Mit Hilfe des Rotationsgenerators lässt sich die Abbildungsmatrix einer Rotation in 3D einfach ausdrücken.",
                "page": 113
              },
              {
                "type": "Satz",
                "text": "Satz 6.12",
                "details": "Rodrigues-Formel Die Rotation in R3 um den Winkel φ ∈R rechtshändig um die Drehachse in Richtung ˆφ ∈R3 wird beschrieben durch die Abbildungsmatrix R(φ) = 1 + \u00001 −cos(φ) \u0001 · J2( ˆφ) + sin(φ) · J( ˆφ). (6.84)",
                "page": 113
              },
              {
                "type": "Beweis",
                "text": "Beweis: Um das Bild eines Vektors v ∈R3 unter der Rotation zu berechnen, zerlegen wir",
                "details": "v in seine Anteile parallel und senkrecht zu ˆφ. Gemäss Skizze und den Eigenschaften des Grassmann-Vektor-Produkts gilt ˆφ × v = ˆφ × v⊥= | ˆφ| · |v⊥| · ˆa = 1 · v⊥· ˆa = v⊥· ˆa (6.85) ˆφ × \u0000ˆφ × v \u0001 = ˆφ × \u0000v⊥· ˆa \u0001 = v⊥· ˆφ × ˆa = v⊥· ˆb. (6.86) Mit Hilfe der Skizze und durch Einsetzen des Rotationsgenerators erhalten wir daraus R(φ) · v = v + v⊥· ˆb −v⊥· cos(φ) · ˆb + v⊥· sin(φ) · ˆa = v + \u00001 −cos(φ) \u0001 · v⊥· ˆb + sin(φ) · v⊥· ˆa = v + \u00001 −cos(φ) \u0001 · ˆφ × \u0000ˆφ × v \u0001 + sin(φ) · ˆφ × v II-37",
                "page": 113
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Es gilt R(φ) ∈O(n). ii) In jedem Fall gilt R−1(φ) = RT(φ) = R(−φ). (6.88) Wie geometrisch offensichtlich, ist die Rotation um den Winkel −φ die Inverse der Rota- tion um den Winkel φ. iii) In der Rodrigues-Formel (6.84) steht in beiden Termen jeweils J( ˆφ) und nicht J(φ). Die Verwechslung der beiden ist eine berüchtigte Fehlerquelle. iv) Beispiel-Codes zum Erzeugen von Rodrigues-Rotationsmatrizen gemäss (6.84) mit gän- giger Software. MATLAB/Octave J=@(w)[0,-w(3),w(2);w(3),0,-w(1);-w(2),w(1),0]; R=@(n,phi)eye(3)+(1-cos(phi))*J(n/norm(n))^2 +sin(phi)*J(n/norm(n)); Python/Numpy import numpy as np; def J(w): M=np.array([[0,-w[2],w[1]],[w[2],0,-w[0]], [-w[1],w[0],0]]); return M; def R(phi,n): nn=n/np.linalg.norm(n); M=np.eye(3)+(1-np.cos(phi))*J(nn)@J(nn) +np.sin(phi)*J(nn); return M; II-38",
                "page": 114
              }
            ]
          }
        }
      },
      "6.4": {
        "title": "Spur & Determinante",
        "page": 115,
        "subsections": {
          "6.4.1": {
            "title": "Einleitung",
            "page": 115,
            "content": []
          },
          "6.4.2": {
            "title": "Spur",
            "page": 115,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Für beliebige quadratische Matrizen machen wir folgende Definition.",
                "page": 115
              },
              {
                "type": "Definition",
                "text": "Definition 6.18",
                "details": "Spur Seien n ∈N+ und A ∈M(n, n, R). Die Spur der Matrix A ist die reelle Zahl tr(A) = A1 1 + A2 2 + . . . + An n. (6.89)",
                "page": 115
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Spur einer Matrix ist also ganz einfach die Summe ihrer Diagonalenelemente. Die Abkürzung tr kommt von der englischen Bezeichnung trace. ii) Offensichtlich gilt tr(0) = 0 + . . . + 0 = n · 0 = 0 (6.90) tr(1) = 1 + . . . + 1 = n · 1 = n. (6.91) iii) Die Spur einer diagonalen Matrix ist gerade die Summe ihrer Eigenwerte. Es gilt also tr(D) = λ1 + λ2 + . . . + λn. (6.92) iv) Weil die Diagonalenelemente einer schiefsymmetrischen Matrix alle verschwinden, muss gelten AT = −A ⇒tr(A) = 0 + . . . + 0 = n · 0 = 0. (6.93) v) Je nach Art der linearen Abbildung (Streckung, Spiegelung, Rotation, Projektion, etc..) die eine Abbildungsmatrix beschreibt, kann ihre Spur ganz unterschiedliche geometrische Bedeutungen haben. vi) Für eine Rotation in R3 um den Winkel φ ∈R rechtshändig um die Drehachse in Richtung ˆφ ∈R3 findet man aus der Rodrigues-Formel die Spur tr \u0000R(φ) \u0001 = 1 + 2 · cos(φ). (6.94) Man kann also aus der Spur den Drehwinkel φ ablesen. II-39",
                "page": 115
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• tr \u0012\u0014 1 2 3 4 \u0015\u0013 = 1 + 4 = 5 • tr      1 −5 9 8 2 7 −3 1 −3     = 1 + 2 −3 = 0 • tr      5 0 0 0 −9 0 0 0 8     = 5 −9 + 8 = 4",
                "page": 116
              },
              {
                "type": "Satz",
                "text": "Satz 6.13",
                "details": "Rechenregeln der Spur Seien n ∈N+, A, B ∈M(n, n, R) und a ∈R. Dann gelten folgende Rechenregeln. (a) tr \u0000AT\u0001 = tr(A) (b) tr(A + B) = tr(A) + tr(B) (c) tr(a · A) = a · tr(A) (d) tr(B · A) = tr(A · B)",
                "page": 116
              },
              {
                "type": "Beweis",
                "text": "Beweis: Die Matrizen A und AT haben die gleichen Diagonalenelemente und folglich auch die",
                "details": "gleiche Spur. Es gilt tr(A + B) = n X s=1 \u0000As s + Bs s \u0001 = n X s=1 As s + n X s=1 Bs s = tr(A) + tr(B). (6.95) Ebenso erhalten wir tr(a · A) = n X s=1 a · As s = a · n X s=1 As s = a · tr(A). (6.96) II-40",
                "page": 116
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Spur kann selbst als lineare Abbildung des Typs tr : M(n, n, R) →R aufgefasst werden. ii) Bei der Anwendung der Regel (d) aus Satz 6.13 auf Produkte von mehr als zwei Matrizen ist Vorsicht geboten. Für drei Matrizen gilt tr(A · B · C) = tr(C · A · B) = tr(B · C · A) (6.98) tr(A · C · B) = tr(B · A · C) = tr(C · B · A). (6.99) Die Gleichheit der Werte der beiden Zeilen muss jedoch nicht gelten. Die Spur bleibt im allgemeinen nur erhalten, wenn man die Faktoren eines Matrix-Produkts zyklisch ver- tauscht. Bei beliebigen Änderungen der Reihenfolge kann der Wert der Spur sich auch ändern.",
                "page": 117
              }
            ]
          },
          "6.4.3": {
            "title": "Determinante",
            "page": 117,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Die Definition der Determinante nach der bekannten Leibniz-Formel basiert auf dem Begriff der Permutationen. Dies benötigt ein paar Vorbereitungen.",
                "page": 117
              },
              {
                "type": "Definition",
                "text": "Definition 6.19",
                "details": "Permutation & symmetrische Gruppe Sei n ∈N+. Die symmetrische Gruppe vom Grad n ist die Menge der n-stelligen Permutationen, d.h. Sn := n p : {1, . . . , n} →{1, . . . , n} p ist bijektiv o (6.100)",
                "page": 117
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Eine Permutation p ∈Sn kann interpretiert werden als Umordnung bzw. Umsortierung der natürlichen Zahlen in {1, . . . , n}. ii) Permutationen haben ihre Hauptanwendung in der Kombinatorik, wenn es darum geht n unterscheidbare Objekte auf n unterscheidbare Plätze zu verteilen. S6 entspricht dabei z.B. der Menge aller Möglichkeiten um 6 Autos auf 6 Parkplätze zu verteilen. iii) Üblicherweise wird eine Permutation p ∈Sn als 2 × n-Matrix dargestellt gemäss \u0014 1 2 . . . n p(1) p(2) . . . p(n) \u0015 . (6.101)",
                "page": 117
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• S1 = \u001a\u0014 1 1 \u0015\u001b II-41",
                "page": 117
              },
              {
                "type": "Satz",
                "text": "Satz 6.14",
                "details": "Kardinalität der symmetrischen Gruppen Sei n ∈N+. Es gilt # Sn = n! = 1 · 2 · . . . · n. (6.102)",
                "page": 118
              },
              {
                "type": "Beweis",
                "text": "Beweis: Um ein p ∈Sn zu definieren, wählen wir für jedes k ∈{1, . . . , n} einen Funktionswert",
                "details": "p(k) ∈{1, . . . , n} aus. Weil p bijektiv ist, müssen wir dabei jedes Element von {1, . . . , n} genau einmal verwenden. Für p(1) haben wir also n Werte zur Auswahl, für p(2) dann nur noch (n−1), für p(3) nur noch (n −2) und immer so weiter, bis am Schluss für p(n) nur noch ein einziger Wert übrig ist. Durch Kombination erhalten wir insgesamt die Anzahl Möglichkeiten von N = n · (n −1) · (n −2) · . . . · 2 · 1 = n!. (6.103) Weil jede dieser N = n! Möglichkeiten genau eine der Permutationen aus Sn definiert, haben wir damit den Satz bewiesen. Manche Eigenschaften einer Permutation lassen sich am Wert von zwei Zahlen ablesen. Dazu machen wir folgende Definitionen.",
                "page": 118
              },
              {
                "type": "Definition",
                "text": "Definition 6.20",
                "details": "Inversionszahl & Vorzeichen Seien n ∈N+ und p ∈Sn. (a) Die Inversionszahl von p ist ρ(p) := # n \u0000i; j \u0001 ∈{1, . . . , n}2 \f\f\f i < j ∧p(i) > p(j) o . (6.104) (b) Das Vorzeichen von p ist σ(p) := (−1)ρ(p). (6.105)",
                "page": 118
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Inversionszahl einer Permutation ist also die Anzahl der Pärchen aus Zahlen in {1, . . . , n} für welche die Permutation die Reihenfolge umdreht. ii) Die Inversionszahl wird auch Fehlstandszahl genannt und für das Vorzeichen wird auch das lateinische Wort Signum verwendet. iii) In jedem Fall gilt ρ(p) ∈ \u001a 0, 1, 2, . . . , n · (n −1) 2 \u001b . (6.106) II-42",
                "page": 118
              },
              {
                "type": "Definition",
                "text": "Definition 6.21",
                "details": "Determinante Seien n ∈N+ und A ∈M(n, n, R). Die Determinante der Matrix A ist die reelle Zahl det(A) := X p∈Sn σ(p) · Ap(1) 1 · . . . · Ap(n) n. (6.108)",
                "page": 119
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Gemäss Leibniz-Formel (6.108) wird die Determinante einer quadratischen Matrix A ∈ M(n, n, R) durch folgende Schritte gebildet. S1 Man sucht sich alle Möglichkeiten, um n Komponenten aus A auszuwählen, so dass aus jeder Zeile und jeder Spalte genau eine Komponente vertreten ist. S2 Man berechnet für jede Möglichkeit aus Schritt S1 das Produkt der gefundenen Kom- ponenten. S3 Man multipliziert jedes dieser Produkte aus Schritt S2 mit dem Vorzeichen der Per- mutation zwischen Zeilen- und Spaltenindizes. S4 Man addiert alle Produkte mit den entsprechenden Vorzeichen. ii) Für n = 2 gibt es nur die folgenden n! = 2! = 1 · 2 = 2 Permutationen. k pk(1) pk(2) ρ(pk) σ(pk) 1 1 2 0 +1 2 2 1 1 −1 (6.109) Die Determinante einer 2 × 2-Matrix ist folglich det(A) = A1 1 · A2 2 −A2 1 · A1 2. (6.110) iii) Für n = 3 gibt es die folgenden n! = 3! = 1 · 2 · 3 = 6 Permutationen. k pk(1) pk(2) pk(3) ρ(pk) σ(pk) 1 1 2 3 0 +1 2 2 3 1 2 +1 3 3 1 2 2 +1 4 3 2 1 3 −1 5 1 3 2 1 −1 6 2 1 3 1 −1 (6.111) II-43",
                "page": 119
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• det \u0012\u0014 1 2 3 4 \u0015\u0013 = 1 · 4 −3 · 2 = 4 −6 = 2 • det \u0012\u0014 2 4 3 6 \u0015\u0013 = 2 · 6 −3 · 4 = 12 −12 = 0 • det \u0012\u0014 2 0 0 3 \u0015\u0013 = 2 · 3 −0 · 0 = 6 −0 = 6 II-44",
                "page": 120
              },
              {
                "type": "Satz",
                "text": "Satz 6.15",
                "details": "Rechenregeln der Determinante Seien n ∈N+, A, B ∈M(n, n, R) und a ∈R. Dann gelten folgende Rechenregeln. (a) det \u0000AT\u0001 = det(A) (b) det(a · A) = an · det(A) (c) det(A · B) = det(A) · det(B) (d) det \u0000A−1\u0001 = 1 det(A) falls A regulär",
                "page": 121
              },
              {
                "type": "Beweis",
                "text": "Beweis: Die Aussagen (a) und (b) sind klar, während (c) nur mit grossem Aufwand gezeigt",
                "details": "werden kann. Falls A regulär ist, dann hat sie eine Inverse A−1 ∈M(n, n, R) und es gilt A−1 · A = 1 det(. . .) (6.117) ⇒ det \u0000A−1 · A \u0001 = det(1) (6.118) ⇒ det \u0000A−1\u0001 · det(A) = 1 : det(A). (6.119) Daraus folgt det(A) ̸= 0 und nach der Division erhalten wir det \u0000A−1\u0001 = 1 det(A) . (6.120) Damit haben wir die Aussage (d) bewiesen.",
                "page": 121
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für die Determinante gibt es keine allgemeingültige Summen-Regel. Es gibt quadratische Matrizen A und B, für welche gilt det(A + B) = det(A) + det(B) aber auch solche für die wir det(A + B) ̸= det(A) + det(B) finden. ii) Die Rechenregel (c) aus Satz 6.15 ist eine äusserst wichtige Eigenschaft der Determinante. Sie hat unter anderem zur Folge, dass gilt det(B · A) = det(B) · det(A) = det(A) · det(B) = det(A · B). (6.121) Das heisst, man darf innerhalb einer Determinante die Faktoren eines Matrix-Produkts vertauschen. Im Gegensatz zur Situation bei der Spur gilt dies auch bei mehr als zwei Faktoren für beliebige Änderungen der Reihenfolge der Faktoren. Für drei Faktoren er- halten wir det(A · B · C) = det(C · A · B) = det(B · C · A) = det(A · C · B) = det(B · A · C) = det(C · B · A) = det(A) · det(B) · det(C). (6.122) II-45",
                "page": 121
              },
              {
                "type": "Satz",
                "text": "Satz 6.16",
                "details": "Modifikationsregeln der Determinante Sei n ∈N+, A ∈M(n, n, R) und a ∈R. Dann gelten folgende Modifikationsregeln. (a) Zeilentausch ⇒det(A) 7→−det(A). (b) Spaltentausch ⇒det(A) 7→−det(A). (c) Multiplikation einer Zeile mit a ⇒det(A) 7→a · det(A). (d) Multiplikation einer Spalte mit a ⇒det(A) 7→a · det(A). Besonders nützlich ist auch die folgende Modifikationsregel.",
                "page": 122
              },
              {
                "type": "Satz",
                "text": "Satz 6.17",
                "details": "Invarianz der Determinante unter einem Gauss-Schritt Subtrahiert man von einer Zeile einer n × n-Matrix ein beliebiges Vielfaches einer andern Zeile, dann ändert sich die Determinante der Matrix nicht. Die Modifikationsregeln ermöglichen es, Determinanten mit Hilfe des Gauss-Verfahrens zu berechnen. Als Beispiel berechnen wir die Determinante der Matrix A =   1 2 −3 2 −4 1 2 2 8  . (6.124) Wir erhalten det(A) = 1 2 −3 2 −4 1 2 2 8 = [1] 2 −3 2 2 −4 1 1 1 1 4 · 2 = [1] 2 −3 0 −8 7 0 −1 7 · 2 (6.125) = [1] 2 −3 0 [1] −7 8 0 8 −7 · 2 · (−1)3 = [1] 2 −3 0 [1] −7 0 0 [49] · 2 · (−1) = 1 · 1 · 49 · 2 · (−1) = −98. Eine der Hauptanwendungen von Determinanten ist die Prüfung einer quadratischen Matrix auf Singularität bzw. Regularität. Es gilt nämlich der folgende, bemerkenswerte Satz.",
                "page": 122
              },
              {
                "type": "Satz",
                "text": "Satz 6.18",
                "details": "Regularitätssatz Eine quadratische Matrix A ist genau dann regulär, wenn gilt det(A) ̸= 0.",
                "page": 122
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Gilt det(A) ̸= 0, dann ist die quadratische Matrix A regulär, d.h. sie hat eine Inverse A−1 und die zugehörige lineare Abbildung a ist bijektiv und hat eine Umkehrabbildung a−1. II-46",
                "page": 122
              },
              {
                "type": "Satz",
                "text": "Satz 6.19",
                "details": "Determinante einer orthogonalen Matrix Seien n ∈N+ und A ∈O(n), dann gilt det(A) ∈{−1, 1}.",
                "page": 123
              },
              {
                "type": "Beweis",
                "text": "Beweis: Für eine orthogonale Matrix A muss gelten",
                "details": "det(A) = det \u0000AT\u0001 = det \u0000A−1\u0001 = 1 det(A) · det(A) (6.126) ⇔ \u0000det(A) \u00012 = 1. (6.127) Daraus folgt det(A) ∈{−1, 1}. (6.128) Damit haben den Satz bewiesen.",
                "page": 123
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Umkehrung des Satzes 6.19 gilt nicht. Dazu betrachten wir z.B. die Matrix A = \" 1 2 0 0 2 # . (6.129) Wir berechnen leicht, dass zwar det(A) = 1 2 · 2 −0 · 0 = 1 −0 = 1, (6.130) aber deswegen ist A noch lange nicht orthogonal, denn es gilt A−1 = \" 2 0 0 1 2 # ̸= \" 1 2 0 0 2 # = AT. (6.131) ii) Die Determinante teilt die Menge O(n) in zwei Teile auf. Man definiert O±(n) := \b A ∈O(n) det(A) = ±1 }. (6.132) Ferner bezeichnet man SO(n) := O+(n) (6.133) als spezielle orthogonale Gruppe in n Dimensionen. iii) Man kann zeigen, dass O−(n) alle Spiegelungsmatrizen und O+(n) alle Rotationsmatrizen enthält. II-47",
                "page": 123
              }
            ]
          },
          "6.4.4": {
            "title": "Mass-Formeln",
            "page": 124,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.22",
                "details": "Gram-Matrix Seien m, n ∈N+ und v1, . . . , vm ∈Rn. Die Gram-Matrix dieser Vektoren ist G(v1; . . . ; vm) :=   ⟨v1 , v1⟩ ⟨v1 , v2⟩ . . . ⟨v1 , vm⟩ ⟨v2 , v1⟩ ⟨v2 , v2⟩ . . . ⟨v2 , vm⟩ ... ... ... ... ⟨vm , v1⟩ ⟨vm , v2⟩ . . . ⟨vm , vm⟩   . (6.134)",
                "page": 124
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Komponenten der Gram-Matrix sind gerade alle möglichen Skalar-Produkte, die sich aus den Vektoren v1, . . . , vm bilden lassen. Davon gibt es insgesamt m2 und konsequen- terweise gilt G ∈M(m, m, R). ii) Wegen der Symmetrie des Skalar-Produkts muss gelten GT = G, (6.135) d.h. G ist symmetrisch. iii) Wegen der positiven Definitheit des Skalar-Produkts muss gelten det(G) ≥0. (6.136) iv) Für die Standard-Einheitsvektoren gilt G(ˆe1; . . . ; ˆen) = 1. (6.137) v) Es sei A ∈M(n, m, R) die Matrix, deren Spalten gerade die Vektoren v1, . . . , vm sind, d.h. A = \u0002 v1 v2 . . . vm \u0003 . (6.138) Dann gilt AT · A =   vT 1 vT 2 ... vT m   · \u0002 v1 v2 . . . vm \u0003 =   vT 1 · v1 vT 1 · v2 . . . vT 1 · vm vT 2 · v1 vT 2 · v2 . . . vT 2 · vm ... ... ... ... vT m · v1 vT m · v2 . . . vT m · vm   =   ⟨v1 , v1⟩ ⟨v1 , v2⟩ . . . ⟨v1 , vm⟩ ⟨v2 , v1⟩ ⟨v2 , v2⟩ . . . ⟨v2 , vm⟩ ... ... ... ... ⟨vm , v1⟩ ⟨vm , v2⟩ . . . ⟨vm , vm⟩   = G. (6.139) II-48",
                "page": 124
              },
              {
                "type": "Definition",
                "text": "Definition 6.23",
                "details": "Mass Seien m, n ∈N+ und v1, . . . , vm ∈Rn mit Gram-Matrix G. Das Mass der Vektoren ist µ(v1; . . . ; vm) := p det(G) . (6.140)",
                "page": 125
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Wegen det(G) ≥0 kann die Wurzel immer in R gezogen werden. ii) Das Mass ist die Verallgemeinerung der Begriffe Länge, Fläche und Volumen auf beliebige Dimensionen. Insbesondere gilt folgendes. µ(v) = p ⟨v, v⟩= |v| ≡Länge von v (6.141) µ(v1; v2) ≡Fläche des von v1 und v2 aufgespannten Parallelogramms (6.142) µ(v1; v2; v3) ≡Volumen des von v1, v2 und v3 aufgespannten Spats (6.143) iii) Für die Standard-Einheitsvektoren gilt µ(ˆe1; . . . ; ˆen) = p det(1) = √ 1 = 1. (6.144) iv) Für m > n ist die Gram-Matrix G in jedem Fall singulär und es folgt µ(v1; . . . ; vm) = 0. (6.145) Falls die Anzahl Vektoren gerade der Dimension gleicht, dann lässt sich die Berechnung des Masses vereinfachen.",
                "page": 125
              },
              {
                "type": "Satz",
                "text": "Satz 6.20",
                "details": "Mass-Formel in voller Dimension Seien n ∈N+ und v1, . . . , vn ∈Rn gerade die Spalten der Matrix A = \u0002 v1 v2 . . . vn \u0003 ∈M(n, n, R). (6.146) Dann gilt µ(v1; . . . ; vn) := | det(A)|. (6.147)",
                "page": 125
              },
              {
                "type": "Beweis",
                "text": "Beweis: Weil A eine quadratische Matrix ist, folgt",
                "details": "µ(v1; . . . ; vn) = p det(G) = p det(AT · A) = p det(AT) · det(A) = p det(A) · det(A) = q det2(A) = | det(A)|. (6.148) Damit haben wir den Satz bewiesen. II-49",
                "page": 125
              }
            ]
          }
        }
      },
      "6.5": {
        "title": "Eigenwerte & Eigenvektoren",
        "page": 126,
        "subsections": {
          "6.5.1": {
            "title": "Einleitung",
            "page": 126,
            "content": []
          },
          "6.5.2": {
            "title": "Definition & Eigenschaften",
            "page": 126,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.24",
                "details": "Eigenwert & Eigenvektor Seien n ∈N+ und A ∈M(n, n, R). Ein Vektor E ∈Rn \\ {0} heisst Eigenvektor von A zum Eigenwert λ ∈R, falls gilt A · E = λ · E. (6.153)",
                "page": 126
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Weil A · 0 = 0 für jede Matrix A gilt, zählt 0 ∈Rn nicht als Eigenvektor und wird bei der",
                "page": 126
              },
              {
                "type": "Definition",
                "text": "Definition explizit ausgeschlossen. Die Zahl 0 ∈R kann jedoch als Eigenwert auftreten.",
                "details": "ii) Die Menge aller Eigenwerte einer Matrix A wird Spektrum von A genannt. Man schreibt Spec(A) := {λ1, . . . , λm}. (6.154) iii) Sind E1 und E2 Eigenvektoren von A zum gleichen Eigenwert λ und a, b ∈R, dann gilt A · (a · E1 + b · E2) = a · A · E1 + b · A · E2 = a · λ · E1 + b · λ · E2 = λ · (a · E1 + b · E2). (6.155) Das heisst auch jede Linearkombination der Form (a · E1 + b · E2) ist wieder Eigenvektor von A zum gleichen Eigenwert λ. Die Eigenvektoren zu einem Eigenwert bilden daher wieder einen Vektorraum, den sogenannten Eigenraum Ek zum Eigenwert λ. iv) Weil alle Vielfache eines Eigenvektors wieder Eigenvektoren zum gleichen Eigenwert sind, gibt es zu jedem Eigenwert λk einer Matrix auch einen Einheitseigenvektor ˆEk. II-50",
                "page": 126
              }
            ]
          },
          "6.5.3": {
            "title": "Charakteristisches Polynom",
            "page": 127,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 6.25",
                "details": "Charakteristisches Polynom Seien n ∈N+ und A ∈M(n, n, R). Die Funktion pA : R →R λ 7→pA(λ) := det \u0000λ · 1 −A \u0001 (6.156) heisst charakteristisches Polynom von A.",
                "page": 127
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Funktionsterm von pA wirkt zunächst irritierend. Setzt man jedoch die Komponenten von 1 und A ein und rechnet die Determinante aus, dann erhält man tatsächlich ein Polynom in λ. ii) Offensichtlich gilt p0(λ) = det \u0000λ · 1 −0 \u0001 = det \u0000λ · 1 \u0001 = λn · det(1) = λn · 1 = λn (6.157) p1(λ) = det \u0000λ · 1 −1 \u0001 = det \u0000(λ −1) · 1 \u0001 = (λ −1)n · det(1) = (λ −1)n · 1 = (λ −1)n. (6.158) Das charakteristische Polynom hat ein paar wichtige Eigenschaften.",
                "page": 127
              },
              {
                "type": "Satz",
                "text": "Satz 6.21",
                "details": "Eigenschaften des charakteristischen Polynoms Seien n ∈N+ und A ∈M(n, n, R). Dann ist pA ein Polynom vom Grad n der Form pA(λ) = an · λn + an−1 · λn−1 + . . . + a1 · λ + a0, (6.159) wobei in jedem Fall gilt (a) an = 1 (b) an−1 = −tr(A) (c) a0 = (−1)n · det(A)",
                "page": 127
              },
              {
                "type": "Beweis",
                "text": "Beweis: Es gilt",
                "details": "a0 = pA(0) = det \u00000 · 1 −A \u0001 = det(−A) = (−1)n · det(A). (6.160) Damit haben wir die Aussage (c) bewiesen.",
                "page": 127
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für eine singuläre Matrix gilt det(A) = 0 und somit a0 = 0. Das charakteristische Polynom hat dann die Form pA(λ) = λn −tr(A) · λn−1 + . . . + a1 · λ = λ · \u0000λn−1 −tr(A) · λn−2 + . . . + a1 \u0001 . (6.161) ii) Für n = 2 ist pA eine quadratische Funktion und es folgt pA(λ) = λ2 −tr(A) · λ + det(A). (6.162) II-51",
                "page": 127
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Wir betrachten die Matrix A = \u0014 7 2 3 8 \u0015 . (6.163) Es folgt tr(A) = 7 + 8 = 15 (6.164) det(A) = 7 · 8 −3 · 2 = 56 −6 = 50 (6.165) pA(λ) = λ2 −tr(A) · λ + det(A) = λ2 −15 λ + 50. (6.166) • A = \u0014 5 1 1 5 \u0015 ⇒. . . ⇒ pA(λ) = λ2 −10 λ + 24 • A = \u0014 0 1 1 0 \u0015 ⇒. . . ⇒ pA(λ) = λ2 −1",
                "page": 128
              }
            ]
          },
          "6.5.4": {
            "title": "Eigenwerte & Eigenvektoren berechnen",
            "page": 128,
            "content": [
              {
                "type": "Satz",
                "text": "Satz 6.22",
                "details": "Eigenwerte sind Nullstellen des charakteristischen Polynoms Seien n ∈N+, A ∈M(n, n, R) und λ ∈R. Dann gilt λ ∈Spec(A) ⇔pA(λ) = 0. (6.167)",
                "page": 128
              },
              {
                "type": "Beweis",
                "text": "Beweis: Für einen Eigenwert λ ∈R und einen zugehörigen Eigenvektor E ∈Rn \\ {0} gilt",
                "details": "A · E = λ · E −A · E (6.168) ⇔ λ · E −A · E = 0 (6.169) ⇔ \u0000λ · 1 −A \u0001 · E = 0. (6.170) Dies ist ein homogenes, lineares Gleichungssystem für E, das genau dann von 0 verschiedene Lösungen hat, wenn die Matrix λ · 1 −A singulär ist. Demnach muss gelten 0 = det \u0000λ · 1 −A \u0001 = pA(λ). (6.171) Damit haben wir den Satz bewiesen. II-52",
                "page": 128
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Eigenwerte sind gerade die Nullstellen des charakteristischen Polynoms. ii) Ein Polynom vom Grad n kann maximal n Nullstellen haben. Dementsprechend kann eine Matrix A ∈M(n, n, R) auch höchstens n Eigenwerte haben. iii) Die Nullstellen eines Polynoms lassen sich bekanntlich nur für n ∈{1, 2, 3, 4} direkt durch Formeln berechnen. Man kann beweisen(!), dass es für Polynome vom Grad fünf oder höher keine direkten Formeln für die Nullstellen geben kann. Somit ist die Berechnung der Eigenwerte für n ≥5 mit Hilfe des charakteristischen Polynoms sehr schwierig. iv) Für n = 2 kann die Mitternachtsformel für quadratische Gleichungen eingesetzt werden, um die Eigenwerte zu berechnen. Aus (6.162) folgt, dass eine Matrix A ∈M(2, 2, R) genau dann Eigenwerte hat, wenn gilt D = tr2(A) −4 · det(A) ≥0. (6.172) In diesem Fall erhält man λ1,2 = tr(A) ± √ D 2 . (6.173) v) Sind die Eigenwerte einer Matrix erst einmal bekannt, dann können die zugehörigen Ei- genvektoren durch lösen des linearen Gleichungssystems (6.170) gefunden werden. vi) Beispiel-Codes zur Berechnung der Eigenwerte und Eigenvektoren mit gängiger Software. MATLAB/Octave [E,D]=eig(A) Mathematica/WolframAlpha Eigenvalues[A] Eigenvectors[A] Eigensystem[A] Python/Numpy import numpy as np; [S,E]=np.linalg.eig(A) Python/Sympy import sympy as sp; S=A.eigenvals() E=A.eigenvects() [E,D]=A.diagonalize() Um die Eigenwerte einer Matrix A ∈M(n, n, R) zu berechnen, können wir also nach den fol- genden Schritten vorgehen. S1 Berechnen des charakteristischen Polynoms pA(λ) = det \u0000λ · 1 −A \u0001 . (6.174) S2 Bestimmen der Eigenwerte, d.h. der Nullstellen von pA(λ). S3 Für jeden Eigenwert λ ∈Spec(A) die Lösungen des linearen Gleichungssystems \u0000λ · 1 −A \u0001 · E = 0. (6.175) berechnen. II-53",
                "page": 129
              }
            ]
          },
          "6.5.5": {
            "title": "Spezielle Eigenwerte & Eigenvektoren",
            "page": 130,
            "content": []
          }
        }
      }
    }
  },
  "7": {
    "title": "Vektorräume",
    "page": 131,
    "sections": {
      "7.1": {
        "title": "Vektorraumstruktur",
        "page": 131,
        "subsections": {
          "7.1.1": {
            "title": "Definition",
            "page": 131,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.1",
                "details": "Vektorraum Ein Vektorraum ist ein Quadrupel (V, K, +, ·), bestehend aus eine Menge V , einem Zahlenkörper K und zwei Operationen + : V × V →V \u0000v; w \u0001 7→v + w und · : K × V →V \u0000a; v \u0001 7→a · v, (7.1) so dass für alle u, v, w ∈V und a, b ∈K die folgenden Axiome gelten. VR-1 (u + v) + w = u + (v + w) VR-2 Es gibt ein 0 ∈V mit 0 + v = v für alle v ∈V . VR-3 Für jedes v ∈V gibt es ein −v ∈V mit v + (−v) = 0. VR-4 w + v = v + w VR-5 a · (v + w) = a · v + a · w VR-6 (a + b) · v = a · v + b · v VR-7 (a · b) · v = a · (b · v) VR-8 1 · v = v Entwickelt man eine mathematische Theorie ausgehend von Axiomen, dann müssen auch Aussa- gen, deren Gültigkeit in praktischen Anwendungen “selbstverständlich” ist, sorgfältig aus diesen Axiomen bewiesen werden. Ein schönes Beispiel ist die sogenannte Null-Koinzidenz, welche in allen Vektorräumen gilt. II-55",
                "page": 131
              },
              {
                "type": "Satz",
                "text": "Satz 7.1",
                "details": "Null-Koinzidenz In jedem Vektorraum (V, K, +, ·) gilt für alle Vektoren v ∈V 0 · v = 0. (7.2)",
                "page": 132
              },
              {
                "type": "Beweis",
                "text": "Beweis: Gemäss VR-8, VR-6 und wieder VR-8 und dann VR-1 sowie VR-3 gilt",
                "details": "0 · v + v = 0 · v + 1 · v = (0 + 1) · v = 1 · v = v + (−v) (7.3) ⇔ (0 · v + v) + (−v) = v + (−v) (7.4) ⇔ 0 · v + \u0000v + (−v) \u0001 = 0 (7.5) ⇔ 0 · v + 0 = 0. (7.6) Aus VR-2 folgt schliesslich 0 · v = 0. (7.7) Damit haben wir (7.2) und den Satz bewiesen.",
                "page": 132
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Elemente des Zahlenkörpers K werden Skalare und die Elemente der Menge V werden Vektoren genannt. ii) Die Vektoren in einem Vektorraum erfüllen oft weitere Strukturen, sie können z.B. Punkte in der Geometrie oder Funktionen in der Analysis sein. Insbesondere bilden alle möglichen physikalischen Grössen einen Vektorraum. iii) Auch für die Struktur des Zahlenkörpers K gibt es ein System von Axiomen, die wir hier einfach stillschweigend anwenden. In diesem Kurs gilt fast immer K = R. In diesem Fall spricht man auch von einem reellen Vektorraum. Denkbar wären aber auch K ∈{Q, C}. iv) Wegen der Null-Koinzidenz ist es sinnvoll, 0 ∈K und 0 ∈V zu identifizieren. Wir schrei- ben von nun an einfach nur noch 0. v) Wenn in Anwendungen “klar” ist, welcher Zahlenkörper K und welche Operationen + bzw. · gemeint ist, dann wird der Vektorraum meist nur noch durch die Menge V der Vektoren bezeichnet und nicht mehr das ganze Quadrupel (V, K, +, ·) geschrieben. vi) Die 8 Axiome des Vektorraums zusammen mit ersten Folgerungen wie der Null-Koinzidenz sind das, was man gemeinhin unter den “üblichen Rechenregeln” für Vektoren versteht. vii) Aufgrund der Axiome lassen sich in jedem Vektorraum beliebige Linearkombinationen von Vektoren bilden. Es gelten dabei die “üblichen Rechenregeln” und insbesondere ist jede Linearkombination von Vektoren wieder ein Vektor, d.h. Vektorräume sind unter der Bildung von Linearkombinationen abgeschlossen.",
                "page": 132
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Der einfachste Vektorraum ist der triviale Vektorraum, der aus einem beliebigen Zahlenkörper aber nur einem einzigen Vektor besteht, nämlich 0, d.h. ({0}, K, +, ·). • Für n ∈N+ die bekannten Euklid-Räume (Rn, R, +, ·). II-56",
                "page": 132
              }
            ]
          },
          "7.1.2": {
            "title": "Linearkombinationen, Basis & Dimension",
            "page": 133,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.2",
                "details": "Linearkombination Seien (V, K, +, ·) ein Vektorraum, m ∈N+, {v1, . . . , vm} ⊆V und {x1, . . . , xm} ⊆K. Eine Linearkombination der Vektoren v1, . . . , vm ist eine Formel der Form w = m X k=1 xk · vk. (7.11) Sind Linearkombinationen erst einmal definiert, dann stellt sich die Frage, welche Teilmenge des Vektorraums durch Linearkombinieren von einigen Vektoren mit beliebigen Koeffizienten aus dem Zahlenkörper erzeugt wird.",
                "page": 133
              },
              {
                "type": "Definition",
                "text": "Definition 7.3",
                "details": "Lineare Hülle Seien (V, K, +, ·) ein Vektorraum und m ∈N+. Die lineare Hülle von {v1, . . . , vm} ⊆V ist span \u0000{v1, . . . , vm} \u0001 := ( m X k=1 xk · vk x1, . . . , xm ∈K ) . (7.12)",
                "page": 133
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) In der Literatur wird die lineare Hülle auch Spann oder Spannweite genannt. II-57",
                "page": 133
              },
              {
                "type": "Definition",
                "text": "Definition 7.4",
                "details": "linear unabhängig, erzeugend und Basis Seien (V, K, +, ·) ein Vektorraum, n ∈N+. (a) Die Vektoren in {v1, . . . , vn} ⊆V heissen linear unabhängig, falls 0 = n X k=1 xk · vk ⇔0 = x1 = . . . = xn. (7.14) (b) Die Vektoren in {v1, . . . , vn} ⊆V heissen erzeugend, falls span \u0000{v1, . . . , vn} \u0001 = V. (7.15) (c) Die Vektoren in {e1, . . . , en} ⊆V bilden eine Basis von V , falls sie linear unabhängig und erzeugend sind.",
                "page": 134
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Vektoren in {v1, . . . , vn} ⊆V heissen linear abhängig, genau dann wenn sie nicht linear unabhängig sind. ii) In einer Menge von linear unabhängigen Vektoren lässt sich keiner dieser Vektoren als Linearkombination der andern darstellen. Jeder Vektor trägt so etwas wie eine “neue Richtung” bei, welche durch eine Linearkombination der andern nicht “beschritten” wer- den kann. iii) Ist eine Menge von Vektoren erzeugend, dann lässt sich jeder Vektor im Vektorraum als Linearkombination von Vektoren aus dieser Menge darstellen. Bei einer Basis kommen die Eigenschaften linear unabhängig und erzeugend zusammen. Dies führt auf folgendes Ergebnis, das für die Praxis äusserst wertvoll ist.",
                "page": 134
              },
              {
                "type": "Satz",
                "text": "Satz 7.2",
                "details": "Eindeutigkeit der Basis-Darstellung Sei (V, K, +, ·) ein Vektorraum, n ∈N+, B = {e1, . . . , en} ⊆V eine Basis und v ∈V . Dann gibt es eindeutige Koeffizienten v1, . . . , vn ∈K, so dass v = n X k=1 vk · ek. (7.16)",
                "page": 134
              },
              {
                "type": "Beweis",
                "text": "Beweis: Weil die Vektoren in B eine Basis des Vektorraums bilden, sind sie nach Definition 7.4",
                "details": "erzeugend. Somit gibt es Koeffizienten v1, . . . , vn ∈K, so dass v = n X k=1 vk · ek. (7.17) II-58",
                "page": 134
              },
              {
                "type": "Satz",
                "text": "Satz 7.3",
                "details": "Existenz einer Basis In jedem nichttrivialen Vektorraum existiert eine Basis entweder aus endlich oder unendlich vielen Vektoren. Von besonderem Interesse ist der folgende Satz über die Anzahl Vektoren in einer Basis.",
                "page": 135
              },
              {
                "type": "Satz",
                "text": "Satz 7.4",
                "details": "Eindeutigkeit der Anzahl Basis-Vektoren Jede Basis eines Vektorraums besteht aus der gleichen Anzahl Basis-Vektoren. Die Tatsache, dass jede Basis eines Vektorraums aus gleich vielen Vektoren besteht, macht diese Anzahl zu einer wichtigen Kenngrösse, die einen eigenen Namen verdient.",
                "page": 135
              },
              {
                "type": "Definition",
                "text": "Definition 7.5",
                "details": "Dimension Die Anzahl Basis-Vektoren in jeder Basis eines Vektorraums heisst Dimension des Vektorraums.",
                "page": 135
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Insbesondere Funktionenräume können oft nicht endlich erzeugt werden und haben somit unendliche Dimension. ii) Bemerkenswert ist die Tatsache, dass der Begriff Dimension hier rein algebraisch definiert wird. Es wird dafür keinerlei Geometrie oder gar geometrische Anschauung benötigt. iii) Ist n ∈N+ die Dimension eines Vektorraums (V, K, +, ·), dann schreibt man formell dim(V ) = n. (7.22) II-59",
                "page": 135
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Für jedes n ∈N+ bilden die Standard-Einheitsvektoren                ˆe1 =   1 0 0 ... 0   , ˆe2 =   0 1 0 ... 0   , . . . , ˆen =   0 0 ... 0 1                  (7.23) eine Basis von Kn, die sogenannte Standard-Basis. Somit folgt dim(Kn) = n. (7.24) • Für jedes n ∈N+ bilden die Monome \b 1, x, x2, x3, . . . , xn} (7.25) eine Basis des Polynomraums Pn(R). Somit folgt dim(Pn(R)) = n + 1. (7.26) • Die Funktionenräume C(R) und L2(R) können nicht endlich erzeugt werden und haben daher unendliche Dimension. Ist in einem Vektorraum (V, K, +, ·) eine Basis B = {e1, . . . , en} gewählt, dann lässt sich jeder Vektor eindeutig Linearkombination des Basis-Vektoren schreiben gemäss v = n X k=1 vk · ek. (7.27) Die Koeffizienten v1, . . . , vn ∈K können wie im Falle der Euklid-Räume Rn in eine Spalten- Matrix geschrieben werden, d.h. man identifiziert v =   v1 ... vn  . (7.28) Die Operationen + und · im Vektorraum lassen sich dann wieder durch die gewohnten Opera- tionen in den Komponenten realisieren. Beispiel: • Wir betrachten den Vektorraum P2(R) der quadratischen Funktionen mit reellen Koeffizienten und wählen die Basis {1, x, x2}. Dann identifizieren wir f(x) = 3 x2 + 5 x + 7 7→f =   7 5 3  . (7.29) II-60",
                "page": 136
              }
            ]
          },
          "7.1.3": {
            "title": "Unterräume",
            "page": 137,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.6",
                "details": "Unterraum Sei (V, K, +, ·) ein Vektorraum. Eine Teilmenge W ⊆V heisst Unterraum von V , falls (W, K, +, ·) ebenfalls ein Vektorraum ist.",
                "page": 137
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) In der Literatur werden Unterräume auch Teilräume genannt. ii) Um kompakt auszudrücken, dass W ⊆V nicht nur eine Teilmenge sondern ein Unterraum von V ist, verwendet man die Schreibweise W ≤V. (7.30) iii) Jeder Unterraum eines Vektorraums V muss mindestens 0 enthalten. iv) Jeder Vektorraum hat zumindest sich selbst und den trivialen Vektorraum als Unterraum. Für jeden Vektorraum V gilt also {0} ≤V und V ≤V. (7.31) Mit Hilfe des folgenden Satzes kann sehr einfach getestet werden, ob eine Teilmenge eines Vektorraums ein Unterraum ist.",
                "page": 137
              },
              {
                "type": "Satz",
                "text": "Satz 7.5",
                "details": "Test auf Unterraum Sei (V, K, +, ·) ein Vektorraum und W ⊆V . Dann gilt W ≤V ⇔span(W) = W. (7.32)",
                "page": 137
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Eine Teilmenge eines Vektorraums ist also genau dann ein Unterraum, wenn sie abge- schlossen ist unter der Bildung von Linearkombinationen. ii) Um nachzuweisen, das W ≤V muss man also zeigen, dass w1, w2 ∈W, x1, x2 ∈K ⇒x1 · w1 + x2 · w2 ∈W. (7.33)",
                "page": 137
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Für jedes m, n ∈N+ mit m ≤n gilt Km ≤Kn. • Für jedes m, n ∈N+ mit m ≤n gilt Pm(R) ≤Pn(R). • Jede Gerade in der Ebene kann als Unterraum der Ebene aufgefasst werden. • Jede Gerade oder Ebene im Raum kann als Unterraum des Raumes aufgefasst werden. II-61",
                "page": 137
              }
            ]
          }
        }
      },
      "7.2": {
        "title": "Lineare Abbildungen",
        "page": 138,
        "subsections": {
          "7.2.1": {
            "title": "Definition",
            "page": 138,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.7",
                "details": "Lineare Abbildung Seien (V, K, +, ·) und (W, K, +, ·) zwei Vektorräume über dem gleichen Zahlenkörper K. Eine Abbildung der Form a : V →W (7.34) heisst lineare Abbildung, falls für alle u, v ∈V und x, y ∈K gilt a(x · u + y · v) = x · a(u) + y · a(v). (7.35)",
                "page": 138
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für diese Definition ist es sehr wichtig, dass die Vektorräume V und W über dem gleichen Zahlenkörper K definiert sind. ii) Diese Definition entspricht der Definition 6.14 aus Abschnitt 6.2.1. iii) Eine lineare Abbildung erkennt man daran, dass sie die Struktur einer Linearkombination respektiert. iv) Für alle linearen Abbildungen gilt offensichtlich a(0) = a(0 · 0) = 0 · a(0) = 0. (7.36)",
                "page": 138
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Die bereits bekannten geometrisch definierten linearen Abbildungen in Rn wie Spiegelungen, Drehungen, Projektionen etc... • Die Ableitung d : Pn(R) →Pn(R) oder d : Pn(R) →Pn−1(R). • Die Orthogonal-Projektion in L2(R).",
                "page": 138
              }
            ]
          },
          "7.2.2": {
            "title": "Matrix-Darstellung",
            "page": 138,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.8",
                "details": "Abbildungsmatrix Seien (V, K, +, ·) und (W, K, +, ·) zwei Vektorräume über dem gleichen Zahlenkörper K mit den endlichen Dimensionen dim(V ) = n ∈N+ bzw. dim(W) = m ∈N+ und Basen {e1, . . . , en} ⊆ V bzw. {E1, . . . , Em} ⊆W sowie a : V →W eine lineare Abbildung. Die Abbildungsmatrix von a bezüglich der gewählten Basen ist die Matrix A ∈M(m, n, K) mit den Komponenten Aij ∈K, so dass für alle j ∈{1, . . . , n} gilt a(ej) = m X i=1 Ai j · Ei. (7.37) II-62",
                "page": 138
              },
              {
                "type": "Satz",
                "text": "Satz 7.6",
                "details": "Berechnung mit der Abbildungsmatrix Seien (V, K, +, ·) und (W, K, +, ·) zwei Vektorräume über dem gleichen Zahlenkörper K mit den endlichen Dimensionen dim(V ) = n ∈N+ bzw. dim(W) = m ∈N+ und Basen {e1, . . . , en} ⊆ V bzw. {E1, . . . , Em} ⊆W sowie a : V →W eine lineare Abbildung mit Abbildungsmatrix A ∈M(m, n, K). Ferner seien v = n X j=1 vj · ej ∈V und w = m X i=1 wi · Ei ∈W, (7.38) für welche gilt w = a(v). (7.39) Für die Komponenten von v und w gilt dann die Beziehung   w1 ... wm  =   A11 . . . A1n ... ... ... Am1 . . . Amn  ·   v1 ... vn  . (7.40)",
                "page": 139
              },
              {
                "type": "Beweis",
                "text": "Beweis: Durch Einsetzen der Basis-Darstellung von v und weil a eine lineare Abbildung ist,",
                "details": "erhalten wir m X i=1 wi · Ei = w = a(v) = a n X j=1 vj · ej ! = n X j=1 vj · a(ej) = n X j=1 vj · m X i=1 Ai j · Ei = m X i=1 n X j=1 Ai j · vj | {z } = wi ·Ei. (7.41) Wegen der Eindeutigkeit der Basis-Darstellung folgt aus einem Koeffizientenvergleich für alle i ∈{1, . . . , m}, dass wi = n X j=1 Ai j · vj. (7.42) In Matrix-Schreibweise entspricht dies genau (7.40) und wir haben den Satz bewiesen.",
                "page": 139
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Sind in den Vektorräumen V und W jeweils Basen gewählt, dann reduziert sich die An- wendung einer linearen Abbildung auf eine Matrix-Multiplikation analog zur Situation für eine lineare Abbildung des Typs a : Rn →Rm. ii) Die Eigenschaften einer linearen Abbildung können aus den Eigenschaften ihrer Abbil- dungsmatrix abgelesen werden. iii) Analog zur Situation für eine lineare Abbildung des Typs a : Rn →Rm gelten auch hier der Verknüpfungssatz und der Inversionssatz für bijektive, lineare Abbildungen iv) Analog zur Situation für eine lineare Abbildung des Typs a : Rn →Rm kann die Abbil- dungsmatrix mit Hilfe des Spalten-Vektor-Konstruktionsverfahrens gefunden werden. v) Wählt man in V bzw. W eine andere Basis, dann wird die gleiche lineare Abbildung durch eine andere Abbildungsmatrix beschrieben. II-63",
                "page": 139
              }
            ]
          },
          "7.2.3": {
            "title": "Bild & Kern",
            "page": 140,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.9",
                "details": "Bild & Kern Seien (V, K, +, ·) und (W, K, +, ·) zwei Vektorräume über dem gleichen Zahlenkörper K und a : V →W eine lineare Abbildung. (a) Das Bild von a ist die Menge img(a) := a(V ) := \b w ∈W Es gibt ein v ∈V mit a(v) = w. . (7.43) (b) Der Kern von a ist die Menge ker(a) := \b v ∈V a(v) = 0 . (7.44)",
                "page": 140
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Der Begriff des Bildes in der linearen Algebra stimmt überein mit dem entsprechenden Begriff aus der allgemeinen Theorie der Funktionen. ii) Der Kern einer linearen Abbildung besteht gerade aus jenen Vektoren, die auf 0 abgebildet werden. iii) Um Verwechslungen vorzubeugen, sei nochmals betont, dass gilt img(a) ⊆W aber ker(a) ⊆V. (7.45) iv) In jedem Fall gilt 0 ∈ker(a). v) Gilt ker(a) = {0}, dann sagt man, a hat einen trivialen Kern. Charakteristisch für lineare Abbildungen ist der folgende Satz.",
                "page": 140
              },
              {
                "type": "Satz",
                "text": "Satz 7.7",
                "details": "Dimensionssatz Seien (V, K, +, ·) und (W, K, +, ·) zwei Vektorräume über dem gleichen Zahlenkörper K und a : V →W eine lineare Abbildung. Dann gilt img(a) ≤W und ker(a) ≤V sowie dim \u0000img(a) \u0001 + dim \u0000ker(a) \u0001 = dim(V ). (7.46)",
                "page": 140
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Bild und Kern sind demnach nicht nur Teilmengen sondern Unterräume von W bzw. V . ii) Der Dimensionssatz ist eine Art “Erhaltungssatz” für Dimensionen unter der Wirkung einer linearen Abbildung. Die Dimension von V wird aufgeteilt auf Bild und Kern.",
                "page": 140
              },
              {
                "type": "Satz",
                "text": "Satz 7.8",
                "details": "Umkehrbarkeitssatz Seien (V, K, +, ·) ein Vektorraum und a : V →V eine lineare Abbildung. Dann gilt a bijektiv ⇔ker(a) = {0}. (7.47) II-64",
                "page": 140
              }
            ]
          }
        }
      },
      "7.3": {
        "title": "Skalar-Produkt & Metrik",
        "page": 141,
        "subsections": {
          "7.3.1": {
            "title": "Skalar-Produkt",
            "page": 141,
            "content": [
              {
                "type": "Definition",
                "text": "Definition",
                "details": "Wir betrachten die folgende Definition.",
                "page": 141
              },
              {
                "type": "Definition",
                "text": "Definition 7.10",
                "details": "Skalar-Produkt Sei (V, K, +, ·) ein Vektorraum über dem Zahlenkörper K. Ein Skalar-Produkt auf V ist eine Operation der Form V × V →K \u0000v; w \u0001 7→⟨v, w⟩, (7.48) so dass für alle u, v, w ∈V und a, b ∈K die folgenden Axiome gelten. SP-1 Linearität im 2. Argument: ⟨u, a · v + b · w⟩= a · ⟨u, v⟩+ b · ⟨u, w⟩ (7.49) SP-2 Symmetrie: ⟨w, v⟩= ⟨v, w⟩∗ (7.50) SP-3 Nicht-Degeneriertheit: ⟨v, p⟩= 0 für alle p ∈V ⇔v = 0 (7.51) Wir betrachten die folgende Definition.",
                "page": 141
              },
              {
                "type": "Definition",
                "text": "Definition 7.11",
                "details": "Positive Definitheit Sei (V, K, +, ·) ein Vektorraum über dem Zahlenkörper K ∈{R, C}, dann heisst ein Skalar- Produkt ⟨., .⟩auf V positiv definit, falls für alle v ∈V gilt ⟨v, v⟩≥0 und ⟨v, v⟩= 0 ⇔v = 0. (7.52)",
                "page": 141
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) In der Literatur sind die Begriffe Skalar-Produkt und inneres Produkt synonym. ii) Aus der positiven Definitheit folgt sofort SP-3. Deshalb wird bei positiv definiten Skalar- Produkten das Axiom SP-3 durch die Eigenschaft der positiven Definitheit ersetzt. iii) Je nach Wahl von K ∈{R, C} vereinfacht sich SP-2. Es gilt K = R ⇒⟨w, v⟩= ⟨v, w⟩ (7.53) K = C ⇒⟨w, v⟩= ⟨v, w⟩∗. (7.54) II-65",
                "page": 141
              },
              {
                "type": "Beispiele",
                "text": "Beispiele:",
                "details": "• Gram-Riemann-Skalar-Produkt auf Kn (positiv definit): auf V = Rn: ⟨v, w⟩:= v1 · w1 + v2 · w2 + . . . + vn · wn (7.57) auf V = Cn: ⟨v, w⟩:= v∗ 1 · w1 + v∗ 2 · w2 + . . . + v∗ n · wn. (7.58)",
                "page": 142
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Geometrie, Datenanalyse",
                "details": "• Lorentz-Minkowski-Skalar-Produkt auf R1+3 (nicht positiv definit): ⟨v, w⟩:= v0 · w0 −v1 · w1 −v2 · w2 −v3 · w3 (7.59)",
                "page": 142
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Relativitätstheorie",
                "details": "• Schur-Skalar-Produkt auf M(n, n, R) (positiv definit): ⟨A, B⟩:= tr \u0000AT · B \u0001 . (7.60)",
                "page": 142
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Gruppen-Theorie, Datenanalyse",
                "details": "• Wir betrachten den Funktionenraum der komplexen, integrierbaren, periodischen Funktionen auf R mit Periode T > 0 gemäss V = \b f : R →C f ist integrierbar ∧f(t + T) = f(t) für alle t ∈R . (7.61) L2-Skalar-Produkt auf V (positiv definit): (f , g) := 1 T Z T f ∗(t) · g(t) dt. (7.62)",
                "page": 142
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Fourier-Entwicklungen, Signalverarbeitung",
                "details": "• L2-Skalar-Produkt auf den Lebesgue-Funktionenräumen L2(R, K) (positiv definit): auf V = L2(R, R): (f , g) := Z ∞ −∞ f(t) · g(t) dt (7.63) auf V = L2(R, C): (f , g) := Z ∞ −∞ f ∗(t) · g(t) dt. (7.64)",
                "page": 142
              },
              {
                "type": "Anwendungen",
                "text": "Anwendungen: Fourier-Transformation, Laplace-Transformation, Signalverarbeitung, Va-",
                "details": "riationsrechnung, FEM-Simulationen, Quantenphysik II-66",
                "page": 142
              },
              {
                "type": "Definition",
                "text": "Definition 7.12",
                "details": "Gram-Matrix Seien (V, K, +, ·) ein Vektorraum über dem Zahlenkörper K, m ∈N+ und v1, . . . , vm ∈V . Die Gram-Matrix dieser Vektoren ist G(v1; . . . ; vm) :=   ⟨v1 , v1⟩ ⟨v1 , v2⟩ . . . ⟨v1 , vm⟩ ⟨v2 , v1⟩ ⟨v2 , v2⟩ . . . ⟨v2 , vm⟩ ... ... ... ... ⟨vm , v1⟩ ⟨vm , v2⟩ . . . ⟨vm , vm⟩   . (7.65)",
                "page": 143
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Komponenten der Gram-Matrix sind gerade alle möglichen Skalar-Produkte, die sich aus den Vektoren v1, . . . , vm bilden lassen. Davon gibt es insgesamt m2 und konsequen- terweise gilt G ∈M(m, m, K). ii) Wegen SP-2 muss gelten GT = G∗. (7.66) iii) Je nach Wahl von K ∈{R, C} ergeben sich daraus unterschiedliche Eigenschaften der Gram-Matrix. Es gilt K = R ⇒GT = G (symmetrisch) (7.67) K = C ⇒GT = G∗ (hermitesch). (7.68) iv) Für K ∈{R, C} und ein positiv definites Skalar-Produkt muss gelten det(G) ≥0. (7.69) Wir betrachten die folgende Definition.",
                "page": 143
              },
              {
                "type": "Definition",
                "text": "Definition 7.13",
                "details": "Mass Seien (V, K, +, ·) ein Vektorraum über dem Zahlenkörper K ∈{R, C}, m ∈N+ und v1, . . . , vm ∈ V . Das Mass der Vektoren ist µ(v1; . . . ; vm) := p | det(G)| . (7.70) Wir betrachten den folgenden Satz.",
                "page": 143
              },
              {
                "type": "Satz",
                "text": "Satz 7.9",
                "details": "Regularität des Masses Seien (V, K, +, ·) ein Vektorraum über dem Zahlenkörper K ∈{R, C}, m ∈N+ und v1, . . . , vm ∈ V . Dann gilt µ(v1; . . . ; vm) = 0 ⇔G(v1; . . . ; vm) singulär ⇔{v1, . . . , vm} linear abhängig. (7.71) II-67",
                "page": 143
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) In jedem Fall gilt µ(v1; . . . ; vm) ≥0. (7.72) ii) Weil für ein positiv definites Skalar-Produkt gilt det(G) ≥0, kann der Betrag in diesem Fall weggelassen werden. iii) Das Mass ist die Verallgemeinerung der Begriffe Länge, Fläche und Volumen auf beliebige reelle und komplexe Vektorräume mit Skalar-Produkt. Insbesondere gilt folgendes. µ(v) = p | ⟨v, v⟩| = |v| ≡Länge von v (7.73) µ(v1; v2) ≡Fläche des von v1 und v2 aufgespannten Parallelogramms (7.74) µ(v1; v2; v3) ≡Volumen des von v1, v2 und v3 aufgespannten Spats (7.75) iv) Für m > dim(V ) ist die Gram-Matrix G in jedem Fall singulär und es folgt µ(v1; . . . ; vm) = 0. (7.76) v) Anhand ihres Masses lässt sich beurteilen, ob eine Menge von Vektoren linear abhängig oder linear unabhängig ist.",
                "page": 144
              },
              {
                "type": "Satz",
                "text": "Satz 7.10",
                "details": "Binomische Formeln Seien (V, R, +, ·) ein reeller Vektorraum mit Skalar-Produkt ⟨., .⟩und v, w ∈V , dann gelten die folgenden binomischen Formeln. (a) ⟨v + w, v + w⟩= ⟨v, v⟩+ 2 · ⟨v, w⟩+ ⟨w, w⟩ (b) ⟨v −w, v −w⟩= ⟨v, v⟩−2 · ⟨v, w⟩+ ⟨w, w⟩ (c) ⟨v + w, v −w⟩= ⟨v, v⟩−⟨w, w⟩",
                "page": 144
              },
              {
                "type": "Beweis",
                "text": "Beweis: Übung.",
                "details": "Wir betrachten den folgenden Satz.",
                "page": 144
              },
              {
                "type": "Satz",
                "text": "Satz 7.11",
                "details": "Cauchy-Schwarz-Ungleichung Seien (V, R, +, ·) ein reeller Vektorraum mit positiv definitem Skalar-Produkt ⟨., .⟩und v, w ∈ V , dann gilt die Cauchy-Schwarz-Ungleichung ⟨v, w⟩ ≤|v| · |w|. (7.77) II-68",
                "page": 144
              },
              {
                "type": "Beweis",
                "text": "Beweis: Für alle x ∈R betrachten wir den Vektor",
                "details": "u(x) := x · v + w. (7.78) Wegen der positiven Definitheit des Skalar-Produkts gilt 0 ≤⟨u(x), u(x)⟩= ⟨x · v + w, x · v + w⟩ (7.79) 0 ≤⟨x · v, x · v⟩+ 2 · ⟨x · v, w⟩+ ⟨w, w⟩ (7.80) 0 ≤x2 · ⟨v, v⟩+ 2 · x · ⟨v, w⟩+ ⟨w, w⟩ (7.81) 0 ≤⟨v, v⟩· x2 + 2 · ⟨v, w⟩· x + ⟨w, w⟩=: f(x). (7.82) Offensichtlich ist f(x) eine quadratische Funktion mit Grund-Form-Parameter a = ⟨v, v⟩, b = 2 · ⟨v, w⟩ und c = ⟨w, w⟩. (7.83) Für die Diskriminante von f muss gelten 0 ≥D = b2 −4 · a · c (7.84) 0 ≥ \u00002 · ⟨v, w⟩ \u00012 −4 · ⟨v, v⟩· ⟨w, w⟩ (7.85) 0 ≥4 · ⟨v, w⟩2 −4 · ⟨v, v⟩· ⟨w, w⟩ : 4 (7.86) 0 ≥⟨v, w⟩2 −⟨v, v⟩· ⟨w, w⟩ + ⟨v, v⟩· ⟨w, w⟩ (7.87) ⟨v, v⟩· ⟨w, w⟩≥⟨v, w⟩2 √. . . . (7.88) Daraus folgt ⟨v, w⟩ ≤ p ⟨v, v⟩· ⟨w, w⟩= p ⟨v, v⟩· p ⟨w, w⟩= |v| · |w|. (7.89) Damit haben wir den Satz bewiesen.",
                "page": 145
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Cauchy-Schwarz-Ungleichung gilt nur für positiv definite Skalar-Produkte. ii) Die Cauchy-Schwarz-Ungleichung gilt auch für positiv definite Skalar-Produkte in kom- plexen Vektorräumen, d.h. für K = C. iii) Im deutschsprachigen Raum ausserhalb Bayerns wird die Cauchy-Schwarz-Ungleichung üblicherweise abgekürzt durch CSU. Wir betrachten die folgende Definition.",
                "page": 145
              },
              {
                "type": "Definition",
                "text": "Definition 7.14",
                "details": "Winkel zwischen Vektoren Seien (V, R, +, ·) ein reeller Vektorraum mit positiv definitem Skalar-Produkt ⟨., .⟩und v, w ∈ V . Der Winkel zwischen v und w ist ∡(v; w) :=        arccos \u0012 ⟨v, w⟩ |v| · |w| \u0013 0 ̸∈{v, w} π 2 0 ∈{v, w}. (7.90) II-69",
                "page": 145
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Für alle Skalar-Produkte und alle v, w ∈V gilt die wichtige Konvention v ⊥w ⇔⟨v, w⟩= 0. (7.91) ii) Für positiv definite Skalar-Produkte kann die Formel (7.90) in jeden Fall angewendet werden, denn aus der Cauchy-Schwarz-Ungleichung folgt für alle v, w ∈V \\ {0} ⟨v, w⟩ |v| · |w| ∈[−1, 1]. (7.92) iii) Für nicht positiv definite Skalar-Produkte lässt sich im allgemeinen keine universell gültige Formel für den Winkel zwischen zwei Vektoren finden.",
                "page": 146
              }
            ]
          },
          "7.3.2": {
            "title": "Metrik",
            "page": 146,
            "content": [
              {
                "type": "Definition",
                "text": "Definition 7.15",
                "details": "Metrik Seien (V, R, +, ·) ein reeller Vektorraum mit endlicher Dimension n ∈N+ und Skalar-Produkt ⟨., .⟩und B = {e1, . . . , en} ⊂V eine Basis von V . Die Metrik g ∈M(n, n, R) ist die Gram- Matrix der Basis-Vektoren in B, d.h. g = G(e1; . . . ; en) :=   ⟨e1 , e1⟩ . . . ⟨e1 , en⟩ ... ... ... ⟨en , e1⟩ . . . ⟨en , en⟩  . (7.93)",
                "page": 146
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Die Komponenten der Metrik werden auch metrische Koeffizienten genannt. Für alle i, j ∈ {1, . . . , n} gilt gij = ⟨ei , ej ⟩. (7.94) ii) Das Symbol g wird sowohl für die Metrik als auch für deren Determinante verwendet. Welche Bedeutung gerade gemeint ist, muss aus dem Kontext abgelesen werden. iii) Die Metrik ist in jedem Fall regulär, weil die Basis-Vektoren nach Definition linear unab- hängig sein müssen. iv) Die Metrik ist genau dann diagonal, wenn die Basis-Vektoren paarweise senkrecht aufein- ander stehen. v) In Rn mit Gram-Riemann-Skalar-Produkt haben die Standard-Einheitsvektoren {ˆe1, . . . ,ˆen} die Metrik ˆg = 1 bzw. gij = δij. (7.95) II-70",
                "page": 146
              },
              {
                "type": "Satz",
                "text": "Satz 7.12",
                "details": "Metrische Skalar-Produkt-Formel Seien (V, R, +, ·) ein reeller Vektorraum mit endlicher Dimension n ∈N+ und Skalar-Produkt ⟨., .⟩und B = {e1, . . . , en} ⊂V eine Basis von V mit Metrik g ∈M(n, n, R) und v, w ∈V mit Basis-Darstellungen v = n X r=1 vr · er bzw. w = n X s=1 ws · es (7.96) Dann gilt ⟨v, w⟩= \u0002 v1 . . . vn \u0003 ·   g11 . . . g1n ... ... ... gn1 . . . gnn  ·   w1 ... wn  = vT · g · w. (7.97)",
                "page": 147
              },
              {
                "type": "Beweis",
                "text": "Beweis: Durch Einsetzen der Basis-Darstellungen und mit Hilfe der Bilinearität des Skalar-",
                "details": "Produkts erhalten wir ⟨v, w⟩= * n X r=1 vr · er , n X s=1 ws · es + = n X r=1 n X s=1 vr · ws · ⟨er , es⟩= n X r=1 n X s=1 vr · ws · grs = n X r=1 vr · n X s=1 grs · ws = \u0002 v1 . . . vn \u0003 ·   g11 · w1 + g12 · w2 + . . . + g1n · wn ... gn1 · w1 + gn2 · w2 + . . . + gnn · wn   = \u0002 v1 . . . vn \u0003 ·   g11 . . . g1n ... ... ... gn1 . . . gnn  ·   w1 ... wn  = vT · g · w. (7.98) Damit haben wir den Satz bewiesen.",
                "page": 147
              },
              {
                "type": "Bemerkungen",
                "text": "Bemerkungen:",
                "details": "i) Durch die metrische Skalar-Produkt-Formel kann das Skalar-Produkt in einem beliebi- gen Vektorraum mit fix gewählter Basis aus den Komponenten der Vektoren als Matrix- Produkt mit drei Faktoren berechnet werden. ii) In einem Vektorraum kann ein Skalar-Produkt definiert werden durch Angabe einer Basis und deren Metrik. iii) In Rn mit Gram-Riemann-Skalar-Produkt folgt ⟨v, w⟩= vT · g · w = vT · 1 · w = vT · w. (7.99) II-71",
                "page": 147
              }
            ]
          }
        }
      }
    }
  }
}